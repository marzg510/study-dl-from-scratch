{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ゼロから作るDeep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4章 ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 損失関数(loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 二乗和誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = \\frac{1}{2} \\sum_k(y_k-t_k)^2\n",
    "$$\n",
    "\n",
    "ここで $ y_k $ はニューラルネットワークの出力、$ t_k $は教師データ、$ k $はデータの次元数を表す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 「２」を正解とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例１：「２」の確率が最も高い場合（０．６）\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例２：「７」の確率が最も高い場合（０．６）\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例2のほうが例1より高い＝＞例１の損失関数のほうが小さい→例１のほうが結果が教師に適合している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 交差エントロピー誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = -\\sum_k{t_k\\log{y_k}}\n",
    "$$\n",
    "\n",
    "ここで $ \\log $ 自然対数 $ \\log_e $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 「２」を正解とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例１：「２」の確率が最も高い場合（０．６）\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302584092994546"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例２：「７」の確率が最も高い場合（０．６）\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3 ミニバッチ学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 訓練データを学習する＝訓練データに対する損失関数を求め、その値をできるだけ小さくするようなパラメータを探し出すこと\n",
    "- そのため、損失関数は、すべての訓練データを対象として求める必要がある。\n",
    "- 今まではひとつの訓練データの損失関数を考えていた。\n",
    "  - 交差エントロピーならこれ\n",
    "\n",
    "$$\n",
    "E = -\\sum_k{t_k\\log{y_k}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 訓練データすべての損失関数の和を求めたいとすると\n",
    "  - 交差エントロピーならこれ\n",
    "\n",
    "$$\n",
    "E = -\\frac{1}{N}\\sum_n\\sum_k{t_{nk}\\log{y_{nk}}}\n",
    "$$\n",
    "\n",
    "- \"$ \\frac{1}{N} $\"の意味は？\n",
    "  - 正規化が目的\n",
    "  - １個あたりの「平均の損失関数」を求めることになる\n",
    "  - 平均化すれば、訓練データの数に関係なく、いつでも統一した指標が得られる。\n",
    "  \n",
    "- 復習：正規化とは？\n",
    "  - データをある決まった範囲に変換する処理を「正規化」(normalization)と言う\n",
    "    - P.77 3.6 手書き数字認識 参照\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ミニバッチ学習とは\n",
    "  - たとえば、60,000枚の訓練データの中から100枚を無作為に選び出して、その100枚を使って学習を行う。\n",
    "  - このような学習手法をミニバッチ学習と言う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../deep-learning-from-scratch/ch04'\n",
      "/mnt/wd500/gotowork/workspace/study-dl-from-scratch/deep-learning-from-scratch/ch03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd ../deep-learning-from-scratch/ch04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "import numpy as np\n",
    "# それぞれのデータの形状を出力\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24663  4368 56242 36678 32575 39313 50768 54569  1389 31266]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 訓練データの中からランダムに10枚だけ抜き出す\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = x_train[batch_mask]\n",
    "\n",
    "print(batch_mask)\n",
    "print(x_batch)\n",
    "print(t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52912, 47676, 58752, 54521,   479,  2944, 29844, 41498, 10874,\n",
       "       50951])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- カラスマークによれば\n",
    "  - ミニバッチの損失関数は「テレビの視聴率」のようなもの"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 [バッチ対応版] 交差エントロピー誤差の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 単体データでもバッチデータでも対応できるように\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 「２」を正解とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例１：「２」の確率が最も高い場合（０．６）\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))\n",
    "\n",
    "# この結果はミニバッチでないときと同じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 教師データtがone-hot表現でなくラベルとして与えられた時の交差エントロピー誤差\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 「２」を正解とする\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.718987110506905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 例１：「２」の確率が最も高い場合（０．６）\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))\n",
    "\n",
    "# この結果は、正解をラベルでなくone-hotで与えているので、当然、間違い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 「２」を正解とするのを、ラベルで表現する(のを、試してみた。)\n",
    "t = [2]\n",
    "\n",
    "# 例１：「２」の確率が最も高い場合（０．６）\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# この結果は、合っている!!\n",
    "# なぜだ ｔとyの次元数があってなくても良いのか(あってなくても良いように作ってあるということか?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- こう書いてある\n",
    "  * 実装のポイントは、one-hot表現でtが0の要素は、交差エントロピー誤差も0であるから、その計算は無視しても良いということです。\n",
    "  * 言い換えれば、正解ラベルに対してニューラルネットワークの出力を得ることができれば、交差エントロピー誤差を計算することができるのです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ひとつずつ、確認する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. one-hot表現でtが0の要素\n",
    " - one-hot表現とは\n",
    "  - 正解ラベルを１として、それ以外は０で表す表記法\n",
    "2. 「正解ラベルを１として、それ以外は０で表すという表記」で、tが０の要素\n",
    "3. すなわち「不正解の要素」ということだ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つまり\n",
    "\n",
    "「実装のポイントは、one-hot表現でtが0の要素は、交差エントロピー誤差も0であるから、その計算は無視しても良いということです。」\n",
    "\n",
    "\n",
    "ここで言いたいことは、こういうことではないだろうか。\n",
    "\n",
    "- 実装のポイントは、不正解の要素は、誤差もゼロであるから、無視して良いということ。\n",
    "\n",
    "- 不正解とわかった時点で、以降の計算もしなくていいはずだ、ということ。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "言い換えれば\n",
    "\n",
    "- 正解ラベルに対してニューラルネットワークの出力を得ることができる  \n",
    "  - = 誤差があることがわかる\n",
    "    - = 誤差を計算する必要がある\n",
    "\n",
    "本書ではこういう言い方はしてないようだが、自分はこのように理解した。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.log(y[np.arange(batch_size),t])の説明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.arange(batch_size) => 0からbatch_size-1までの配列を生成する\n",
    "np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = [2, 7, 0, 9, 4]  # ラベルが格納されている\n",
    "# batch_size=5なら\n",
    "# y[np.arange(batch_size,t)] は [y[0,2], y[1,7], y[2,0], y[3,9], y[4,4]]のNumpy配列を返す。\n",
    "# np.log(y[np.arange(batch_size),t])\n",
    "# = np.log(  [ y[0,2],y[1,7],y[2,0]... ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
      "yy [0.1  0.05 0.6  0.   0.05 0.1  0.   0.1  0.   0.  ] (10,) 1\n",
      "yyy [[0.1  0.05 0.6  0.   0.05 0.1  0.   0.1  0.   0.  ]] 1\n",
      "[0]\n",
      "[0.6  0.1  0.1  0.   0.05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1 , 0.05, 0.6 , 0.  , 0.05, 0.1 , 0.  , 0.1 , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"y\",y)\n",
    "yy = np.array(y)\n",
    "print(\"yy\", yy,yy.shape, yy.ndim)\n",
    "yyy = yy.reshape(1, yy.size)\n",
    "batch_size = yyy.shape[0]\n",
    "print(\"yyy\", yyy, batch_size)\n",
    "print(np.arange(batch_size))\n",
    "#yyy[np.arange(batch_size),t]\n",
    "print(yyy[[0],t])\n",
    "yyy[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpyに、arrangeを使って、配列を生成させる、というところが\n",
    "\n",
    "「ミニバッチ」ということなのだろう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
