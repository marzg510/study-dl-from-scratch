{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ゼロから作るDeep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4章 ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 学習アルゴリズムの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 2層ニューラルネットワークのクラス\n",
    "\n",
    "2層のニューラルネットワーク（隠れ層が1層のニューラルネットワーク）を対象に、MNISTデータセットを使って学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/wd500/gotowork/workspace/study-dl-from-scratch/deep-learning-from-scratch/ch04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd ../deep-learning-from-scratch/ch04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    # このクラスで使用する変数\n",
    "    ## params : ニューラルネットワークのパラメータを保持するディクショナリ変数（インスタンス変数）\n",
    "    ##          params['W1']は1層目の重み、params['b1']は1層目のバイアス。\n",
    "    ##          params['W2']は2層目の重み、params['b2']は2層目のバイアス。\n",
    "    #\n",
    "    ## grads : 勾配を保持するディクショナリ変数（numerical_gradient()メソッドの返り値）\n",
    "    ##         grads['W1']は1層目の重みの勾配、grads['b1']は1層目のバイアスの勾配。\n",
    "    ##         grads['W2']は2層目の重みの勾配、grads['b2']は2層目のバイアスの勾配。\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y,t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一つ例を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape) # 今の層（入力層）のニューロン数×次の層（隠れ層）ニューロン数の行列になる\n",
    "print(net.params['b1'].shape) # 次の層（隠れ層）のニューロン数の行列になる\n",
    "print(net.params['W2'].shape) # 今の層（隠れ層）のニューロン数×次の層（出力層）のニューロン数の行列になる\n",
    "print(net.params['b2'].shape) # 次の層（出力層）のニューロン数の行列になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推論処理の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) # ダミーの入力データ（１００枚分）\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05656624, 0.19617819, 0.10486648, ..., 0.42354662, 0.35273118,\n",
       "        0.87174438],\n",
       "       [0.57755882, 0.48298945, 0.21353107, ..., 0.38059549, 0.23743903,\n",
       "        0.33146339],\n",
       "       [0.46275798, 0.02757556, 0.42526475, ..., 0.39976671, 0.15884461,\n",
       "        0.55388627],\n",
       "       ...,\n",
       "       [0.13981253, 0.78022038, 0.24436076, ..., 0.94848046, 0.21790573,\n",
       "        0.32274977],\n",
       "       [0.39965894, 0.56755264, 0.24788565, ..., 0.28554599, 0.77706347,\n",
       "        0.87499767],\n",
       "       [0.50886433, 0.67234244, 0.37372261, ..., 0.51165776, 0.82388759,\n",
       "        0.78253123]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0959692 , 0.09629166, 0.09979841, 0.09871939, 0.11098569,\n",
       "        0.101662  , 0.09740745, 0.10014477, 0.10529902, 0.09372241],\n",
       "       [0.0960181 , 0.09635296, 0.09954321, 0.09883072, 0.11141286,\n",
       "        0.10196294, 0.09756556, 0.09961232, 0.10519653, 0.09350482],\n",
       "       [0.09610602, 0.09622185, 0.09965249, 0.09874341, 0.111017  ,\n",
       "        0.10171183, 0.09757746, 0.10022934, 0.10529124, 0.09344936],\n",
       "       [0.0960031 , 0.09620877, 0.09979786, 0.09865434, 0.11064326,\n",
       "        0.10164532, 0.09758329, 0.10009401, 0.10551626, 0.0938538 ],\n",
       "       [0.09573872, 0.09627769, 0.09979617, 0.09875095, 0.11092637,\n",
       "        0.10193495, 0.09753129, 0.10013841, 0.10541893, 0.09348653],\n",
       "       [0.09608266, 0.09623521, 0.09996819, 0.09863595, 0.11083231,\n",
       "        0.10199436, 0.09737278, 0.10024432, 0.10516339, 0.09347084],\n",
       "       [0.0962095 , 0.09621766, 0.0997767 , 0.09886011, 0.11125865,\n",
       "        0.10178827, 0.09723453, 0.100102  , 0.10513272, 0.09341986],\n",
       "       [0.09611028, 0.09621453, 0.09931993, 0.09852109, 0.11102311,\n",
       "        0.10186059, 0.09778156, 0.10014316, 0.10544091, 0.09358486],\n",
       "       [0.09614926, 0.09617313, 0.09965823, 0.09842515, 0.11089886,\n",
       "        0.10188489, 0.09768633, 0.0999343 , 0.10542004, 0.09376982],\n",
       "       [0.09622079, 0.09641348, 0.09994284, 0.09831357, 0.11068983,\n",
       "        0.10183874, 0.09771748, 0.10004215, 0.10545106, 0.09337006],\n",
       "       [0.09597318, 0.09619068, 0.09959599, 0.09850834, 0.11121816,\n",
       "        0.10168085, 0.09765469, 0.10020872, 0.10554742, 0.09342196],\n",
       "       [0.09593744, 0.09607142, 0.09974204, 0.09864149, 0.1109025 ,\n",
       "        0.10172469, 0.09765638, 0.10019478, 0.1055715 , 0.09355776],\n",
       "       [0.09561446, 0.09594464, 0.0995904 , 0.09851793, 0.11102418,\n",
       "        0.10173884, 0.09777992, 0.10027942, 0.10584145, 0.09366876],\n",
       "       [0.09558378, 0.0958398 , 0.10004239, 0.09863142, 0.11137283,\n",
       "        0.10194819, 0.09718729, 0.10037185, 0.1055093 , 0.09351316],\n",
       "       [0.09585444, 0.09627405, 0.09958736, 0.09934802, 0.1112339 ,\n",
       "        0.10209414, 0.09727784, 0.09997786, 0.10480145, 0.09355094],\n",
       "       [0.09611598, 0.09613269, 0.09995682, 0.09870592, 0.11099764,\n",
       "        0.10186484, 0.09753594, 0.09985947, 0.10525992, 0.09357077],\n",
       "       [0.09604281, 0.09615939, 0.09980191, 0.09871553, 0.11078038,\n",
       "        0.10194442, 0.09730491, 0.09983538, 0.10562679, 0.09378848],\n",
       "       [0.09619551, 0.09632717, 0.09959315, 0.09861105, 0.11075337,\n",
       "        0.1016708 , 0.09776394, 0.10036016, 0.10515977, 0.0935651 ],\n",
       "       [0.09551494, 0.09584579, 0.09961565, 0.09887012, 0.11066842,\n",
       "        0.10153649, 0.09833531, 0.10029537, 0.10579424, 0.09352367],\n",
       "       [0.09591568, 0.09587945, 0.09990013, 0.09857249, 0.11098718,\n",
       "        0.10183507, 0.09753802, 0.10014086, 0.10563296, 0.09359817],\n",
       "       [0.09629656, 0.09647731, 0.09950417, 0.09859348, 0.11098733,\n",
       "        0.10181913, 0.09742704, 0.10033922, 0.10527937, 0.0932764 ],\n",
       "       [0.09562757, 0.09609371, 0.09985753, 0.09882521, 0.11105402,\n",
       "        0.1019724 , 0.09796424, 0.10004377, 0.10501743, 0.09354412],\n",
       "       [0.09596794, 0.09639043, 0.09975831, 0.09870121, 0.11134237,\n",
       "        0.10195358, 0.09734183, 0.09988719, 0.10497292, 0.09368422],\n",
       "       [0.0956564 , 0.09600067, 0.10014795, 0.09892562, 0.11085386,\n",
       "        0.10191743, 0.09729664, 0.10018645, 0.1056187 , 0.09339627],\n",
       "       [0.09619236, 0.09614339, 0.09975819, 0.09848814, 0.11107975,\n",
       "        0.10162632, 0.09744223, 0.09976957, 0.10563783, 0.09386222],\n",
       "       [0.09595962, 0.09622195, 0.09966432, 0.09842423, 0.11111064,\n",
       "        0.10186266, 0.09747285, 0.10037959, 0.10523325, 0.09367089],\n",
       "       [0.09611353, 0.09613726, 0.09962854, 0.09847807, 0.1108223 ,\n",
       "        0.10154539, 0.09775637, 0.10009913, 0.10574838, 0.09367102],\n",
       "       [0.09577227, 0.09656172, 0.09985729, 0.09830164, 0.11106193,\n",
       "        0.10220295, 0.09732817, 0.10006921, 0.10533653, 0.09350828],\n",
       "       [0.09639014, 0.09640208, 0.09987472, 0.09868489, 0.11088305,\n",
       "        0.10173901, 0.09732782, 0.09991419, 0.10541862, 0.09336547],\n",
       "       [0.09642533, 0.0963643 , 0.0994125 , 0.0988011 , 0.11097859,\n",
       "        0.10189693, 0.09741494, 0.10003662, 0.10517313, 0.09349655],\n",
       "       [0.09587946, 0.09618479, 0.0999441 , 0.09869959, 0.11110515,\n",
       "        0.10169749, 0.09732329, 0.10032891, 0.10521602, 0.09362118],\n",
       "       [0.09585156, 0.09629584, 0.09966101, 0.09873037, 0.11129734,\n",
       "        0.10143278, 0.09765847, 0.09996351, 0.10546251, 0.0936466 ],\n",
       "       [0.0963045 , 0.09604901, 0.09965888, 0.09919298, 0.11100481,\n",
       "        0.10226653, 0.09740773, 0.09991793, 0.10477093, 0.0934267 ],\n",
       "       [0.09597218, 0.09606379, 0.09988107, 0.09874731, 0.11120515,\n",
       "        0.10204365, 0.09751483, 0.09982527, 0.10508043, 0.09366633],\n",
       "       [0.09564994, 0.09638073, 0.09975319, 0.09866704, 0.11095188,\n",
       "        0.10162285, 0.09764271, 0.09988113, 0.10583416, 0.09361637],\n",
       "       [0.0960714 , 0.09616274, 0.09971743, 0.09873967, 0.11077833,\n",
       "        0.10173065, 0.09751468, 0.10002157, 0.10557509, 0.09368845],\n",
       "       [0.09591351, 0.09602994, 0.0997883 , 0.09900773, 0.11100361,\n",
       "        0.1016857 , 0.09782368, 0.10001057, 0.10524548, 0.09349147],\n",
       "       [0.09575948, 0.09619735, 0.09995307, 0.09856651, 0.11083112,\n",
       "        0.10208079, 0.09732594, 0.10032523, 0.10513687, 0.09382366],\n",
       "       [0.09593226, 0.0958754 , 0.09982686, 0.09894719, 0.11104408,\n",
       "        0.10161886, 0.0974529 , 0.09995244, 0.10529527, 0.09405474],\n",
       "       [0.09600949, 0.09599296, 0.09991827, 0.09846342, 0.11074667,\n",
       "        0.10168184, 0.09756665, 0.10047349, 0.10573367, 0.09341354],\n",
       "       [0.09551225, 0.0964067 , 0.09983276, 0.09878427, 0.11114087,\n",
       "        0.10181035, 0.09755692, 0.09999985, 0.10540853, 0.09354749],\n",
       "       [0.09595942, 0.09639741, 0.09965684, 0.09852249, 0.11125039,\n",
       "        0.10169324, 0.09755049, 0.0999535 , 0.10523696, 0.09377925],\n",
       "       [0.09630512, 0.09623516, 0.09962648, 0.09863856, 0.11092567,\n",
       "        0.10197526, 0.09740109, 0.09990799, 0.10520089, 0.09378376],\n",
       "       [0.09593943, 0.09655643, 0.09970342, 0.09905646, 0.11100398,\n",
       "        0.10130208, 0.09744531, 0.10018302, 0.10541311, 0.09339674],\n",
       "       [0.09586339, 0.09617716, 0.09993608, 0.09874457, 0.11113064,\n",
       "        0.10196628, 0.09738623, 0.09976139, 0.1052455 , 0.09378876],\n",
       "       [0.09604316, 0.09615492, 0.09944163, 0.09882359, 0.11119039,\n",
       "        0.10158807, 0.09771865, 0.10013618, 0.1052975 , 0.09360593],\n",
       "       [0.09621977, 0.09623311, 0.09992595, 0.09865599, 0.11080075,\n",
       "        0.1018366 , 0.09726607, 0.09994133, 0.10551131, 0.09360912],\n",
       "       [0.09594845, 0.09618489, 0.09997101, 0.09873228, 0.11134442,\n",
       "        0.10166269, 0.09748855, 0.09992027, 0.10545548, 0.09329197],\n",
       "       [0.09617423, 0.09622339, 0.09951929, 0.09847342, 0.11084342,\n",
       "        0.10192741, 0.09733217, 0.10051157, 0.10549119, 0.09350391],\n",
       "       [0.09577971, 0.09623908, 0.09960197, 0.09864614, 0.11096381,\n",
       "        0.10192435, 0.09766114, 0.10020329, 0.10521445, 0.09376607],\n",
       "       [0.09574732, 0.09630806, 0.09982754, 0.09902074, 0.11119162,\n",
       "        0.10218052, 0.09746193, 0.09990964, 0.10499104, 0.09336158],\n",
       "       [0.09588224, 0.09619503, 0.09958083, 0.09886137, 0.11131654,\n",
       "        0.10183295, 0.09756421, 0.09975106, 0.10551789, 0.09349788],\n",
       "       [0.09591547, 0.09634194, 0.09956196, 0.09852636, 0.1112336 ,\n",
       "        0.10226705, 0.09716613, 0.10010677, 0.10519185, 0.09368887],\n",
       "       [0.09613906, 0.09644332, 0.09964142, 0.09849939, 0.11110193,\n",
       "        0.10221863, 0.09718   , 0.10005325, 0.10504661, 0.0936764 ],\n",
       "       [0.09617023, 0.09614729, 0.09948524, 0.0988765 , 0.11092752,\n",
       "        0.10182013, 0.09748872, 0.1000653 , 0.1051984 , 0.09382066],\n",
       "       [0.09628841, 0.09614128, 0.09981148, 0.09846597, 0.11099233,\n",
       "        0.10200859, 0.09757742, 0.10022679, 0.10491554, 0.09357219],\n",
       "       [0.09624812, 0.09608092, 0.09978021, 0.09888986, 0.11101392,\n",
       "        0.10141606, 0.09744648, 0.0999648 , 0.10549908, 0.09366056],\n",
       "       [0.09612788, 0.09617321, 0.09979876, 0.09851248, 0.11084235,\n",
       "        0.10173602, 0.09756745, 0.10000673, 0.10557197, 0.09366316],\n",
       "       [0.09608066, 0.09592758, 0.09963166, 0.09838022, 0.11103924,\n",
       "        0.10176775, 0.09779032, 0.10011133, 0.1055994 , 0.09367183],\n",
       "       [0.09576639, 0.09640968, 0.09986296, 0.09865183, 0.11097761,\n",
       "        0.10204347, 0.09759733, 0.099781  , 0.10543918, 0.09347055],\n",
       "       [0.09611668, 0.09618735, 0.09987659, 0.09871632, 0.111551  ,\n",
       "        0.10185465, 0.09733139, 0.0998784 , 0.10483254, 0.09365509],\n",
       "       [0.09587411, 0.09626807, 0.09974226, 0.09830615, 0.11108832,\n",
       "        0.10186275, 0.09765392, 0.09976791, 0.10568225, 0.09375427],\n",
       "       [0.09588592, 0.09624839, 0.09998731, 0.0986826 , 0.11077398,\n",
       "        0.10197011, 0.09742418, 0.10011909, 0.10508722, 0.09382119],\n",
       "       [0.09577591, 0.09617699, 0.09985242, 0.09865513, 0.11069324,\n",
       "        0.10190734, 0.09755767, 0.10022129, 0.10568887, 0.09347113],\n",
       "       [0.09621318, 0.09640523, 0.09985663, 0.0987986 , 0.11109411,\n",
       "        0.10182506, 0.09741464, 0.10005779, 0.10468319, 0.09365157],\n",
       "       [0.09588692, 0.09613942, 0.09980551, 0.09862747, 0.11126195,\n",
       "        0.10200466, 0.09723405, 0.09998976, 0.10550452, 0.09354574],\n",
       "       [0.0963479 , 0.0961992 , 0.09957045, 0.09875137, 0.11093252,\n",
       "        0.10192219, 0.09750028, 0.09963736, 0.10567582, 0.09346291],\n",
       "       [0.09641038, 0.09609182, 0.09953667, 0.09863412, 0.11094224,\n",
       "        0.10163398, 0.09773974, 0.10000238, 0.10525131, 0.09375736],\n",
       "       [0.09568886, 0.09593676, 0.09976838, 0.09897146, 0.11071434,\n",
       "        0.10187656, 0.09757746, 0.10055464, 0.1054813 , 0.09343026],\n",
       "       [0.0962238 , 0.09632207, 0.09975295, 0.09874316, 0.11091222,\n",
       "        0.10187447, 0.09746639, 0.10006846, 0.10490486, 0.09373161],\n",
       "       [0.09575009, 0.09593964, 0.09998492, 0.09849795, 0.11112385,\n",
       "        0.10194387, 0.09744108, 0.10017127, 0.1057039 , 0.09344342],\n",
       "       [0.09606853, 0.09626977, 0.0995117 , 0.09885307, 0.1109335 ,\n",
       "        0.10181582, 0.09760264, 0.09976276, 0.10511655, 0.09406567],\n",
       "       [0.09622892, 0.09629022, 0.09959835, 0.09892026, 0.11073164,\n",
       "        0.10171589, 0.09756932, 0.1002753 , 0.1052946 , 0.09337549],\n",
       "       [0.09621132, 0.09620799, 0.09988799, 0.09883982, 0.11076891,\n",
       "        0.10175303, 0.09735267, 0.09974943, 0.10556563, 0.09366322],\n",
       "       [0.09576891, 0.09622808, 0.09997449, 0.09893943, 0.1110525 ,\n",
       "        0.10180829, 0.09750273, 0.09985717, 0.10530795, 0.09356046],\n",
       "       [0.09581071, 0.09639519, 0.10012862, 0.09859991, 0.11081749,\n",
       "        0.10186339, 0.09758646, 0.10002974, 0.10515888, 0.09360962],\n",
       "       [0.09576023, 0.0960468 , 0.09990674, 0.09844915, 0.1113436 ,\n",
       "        0.1020685 , 0.09739623, 0.10019066, 0.10528092, 0.09355717],\n",
       "       [0.09572702, 0.09616294, 0.09948493, 0.09843627, 0.11133733,\n",
       "        0.10220862, 0.09772605, 0.10033372, 0.10524938, 0.09333373],\n",
       "       [0.09581926, 0.09620407, 0.09985984, 0.09853571, 0.11138071,\n",
       "        0.10216415, 0.09724673, 0.09986658, 0.10525323, 0.09366971],\n",
       "       [0.09593372, 0.096125  , 0.09974212, 0.09841762, 0.11122464,\n",
       "        0.10222837, 0.09750907, 0.10006518, 0.10529989, 0.09345439],\n",
       "       [0.09619508, 0.09605397, 0.09937364, 0.09894881, 0.11129101,\n",
       "        0.10192522, 0.09748676, 0.09999369, 0.10507723, 0.09365459],\n",
       "       [0.09591542, 0.09636114, 0.09974533, 0.09860237, 0.1108729 ,\n",
       "        0.1017096 , 0.09719279, 0.10041907, 0.10577316, 0.09340823],\n",
       "       [0.09597519, 0.09630167, 0.09950432, 0.09886203, 0.11125281,\n",
       "        0.10186432, 0.09764473, 0.10003014, 0.10509777, 0.09346701],\n",
       "       [0.0962975 , 0.09622433, 0.09965193, 0.09923195, 0.11060296,\n",
       "        0.10186859, 0.0974391 , 0.09989941, 0.10508185, 0.09370239],\n",
       "       [0.0960298 , 0.09602968, 0.09963566, 0.09897457, 0.11098152,\n",
       "        0.10168309, 0.09756286, 0.10018564, 0.10522942, 0.09368777],\n",
       "       [0.09600608, 0.09629267, 0.09960432, 0.09888634, 0.11060774,\n",
       "        0.10161853, 0.09743798, 0.10022827, 0.10559135, 0.09372672],\n",
       "       [0.09582744, 0.09596211, 0.09971266, 0.09840012, 0.11110791,\n",
       "        0.10215819, 0.09753896, 0.10022353, 0.10549875, 0.09357033],\n",
       "       [0.09612411, 0.09622035, 0.09977143, 0.09889156, 0.11047664,\n",
       "        0.10178785, 0.09762319, 0.1002547 , 0.1052313 , 0.09361886],\n",
       "       [0.09581433, 0.0964081 , 0.09990218, 0.09861881, 0.11053758,\n",
       "        0.10180183, 0.09755601, 0.10010584, 0.10552015, 0.09373518],\n",
       "       [0.09615046, 0.09615196, 0.09967084, 0.09835665, 0.11099785,\n",
       "        0.10177727, 0.0975824 , 0.10016867, 0.10548201, 0.09366188],\n",
       "       [0.09598095, 0.0965306 , 0.09960996, 0.09874885, 0.11107181,\n",
       "        0.10202809, 0.09733709, 0.100125  , 0.10527189, 0.09329575],\n",
       "       [0.09604919, 0.09635225, 0.09956817, 0.09881708, 0.11100591,\n",
       "        0.10182116, 0.09723394, 0.10008735, 0.10526369, 0.09380125],\n",
       "       [0.09612284, 0.09624661, 0.09977362, 0.09890767, 0.11100021,\n",
       "        0.10175283, 0.09755021, 0.09994896, 0.10542041, 0.09327665],\n",
       "       [0.09568215, 0.09632025, 0.09997645, 0.09864465, 0.11089796,\n",
       "        0.10226295, 0.09741572, 0.09972396, 0.1053496 , 0.09372633],\n",
       "       [0.09618972, 0.09606458, 0.09968181, 0.09862565, 0.1112052 ,\n",
       "        0.10197746, 0.09743656, 0.10036784, 0.10512887, 0.0933223 ],\n",
       "       [0.09591073, 0.09630492, 0.09986521, 0.09878901, 0.11094529,\n",
       "        0.10154904, 0.097426  , 0.10001367, 0.10563931, 0.09355683],\n",
       "       [0.09634713, 0.09656626, 0.09933924, 0.09862792, 0.11080047,\n",
       "        0.10164949, 0.09745106, 0.1000676 , 0.10532938, 0.09382144],\n",
       "       [0.09600502, 0.09642282, 0.09950595, 0.09856637, 0.11094733,\n",
       "        0.10175128, 0.09789744, 0.09983289, 0.1052835 , 0.0937874 ],\n",
       "       [0.09607425, 0.09606096, 0.09973196, 0.09860913, 0.11106252,\n",
       "        0.10197555, 0.09767738, 0.09959455, 0.10562941, 0.09358427],\n",
       "       [0.09587773, 0.09615984, 0.09971067, 0.09892123, 0.11109082,\n",
       "        0.10188533, 0.09755802, 0.09994944, 0.10531556, 0.09353136]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) # ダミーの入力データ(100枚分)\n",
    "t = np.random.rand(100, 10)  # ダミーの正解ラベル(100枚分)\n",
    "\n",
    "grads = net.numerical_gradient(x, t) # 勾配を計算  5分くらいかかった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['W1'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['b1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['W2'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['b2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 ミニバッチ学習の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "#iters_num = 10000\n",
    "iters_num = 10\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-17 11:57:03.417784 0 start\n",
      "2021-11-17 11:57:03.588130 0 calculating gradient..\n",
      "2021-11-17 11:57:38.746525 0 updating params..\n",
      "2021-11-17 11:57:38.748177 0 recording loss..\n",
      "2021-11-17 11:57:38.750788 1 start\n",
      "2021-11-17 11:57:38.751992 1 calculating gradient..\n",
      "2021-11-17 11:58:18.206202 1 updating params..\n",
      "2021-11-17 11:58:18.207569 1 recording loss..\n",
      "2021-11-17 11:58:18.209202 2 start\n",
      "2021-11-17 11:58:18.210329 2 calculating gradient..\n",
      "2021-11-17 11:58:56.034166 2 updating params..\n",
      "2021-11-17 11:58:56.035545 2 recording loss..\n",
      "2021-11-17 11:58:56.036913 3 start\n",
      "2021-11-17 11:58:56.038012 3 calculating gradient..\n",
      "2021-11-17 11:59:32.658367 3 updating params..\n",
      "2021-11-17 11:59:32.659685 3 recording loss..\n",
      "2021-11-17 11:59:32.661057 4 start\n",
      "2021-11-17 11:59:32.662023 4 calculating gradient..\n",
      "2021-11-17 12:00:10.456674 4 updating params..\n",
      "2021-11-17 12:00:10.458641 4 recording loss..\n",
      "2021-11-17 12:00:10.461041 5 start\n",
      "2021-11-17 12:00:10.462192 5 calculating gradient..\n",
      "2021-11-17 12:00:52.089463 5 updating params..\n",
      "2021-11-17 12:00:52.091182 5 recording loss..\n",
      "2021-11-17 12:00:52.092817 6 start\n",
      "2021-11-17 12:00:52.094166 6 calculating gradient..\n",
      "2021-11-17 12:01:33.940131 6 updating params..\n",
      "2021-11-17 12:01:33.941644 6 recording loss..\n",
      "2021-11-17 12:01:33.943214 7 start\n",
      "2021-11-17 12:01:33.944571 7 calculating gradient..\n",
      "2021-11-17 12:02:18.428286 7 updating params..\n",
      "2021-11-17 12:02:18.430072 7 recording loss..\n",
      "2021-11-17 12:02:18.434629 8 start\n",
      "2021-11-17 12:02:18.436376 8 calculating gradient..\n",
      "2021-11-17 12:03:03.007136 8 updating params..\n",
      "2021-11-17 12:03:03.008710 8 recording loss..\n",
      "2021-11-17 12:03:03.010525 9 start\n",
      "2021-11-17 12:03:03.011872 9 calculating gradient..\n",
      "2021-11-17 12:03:46.873806 9 updating params..\n",
      "2021-11-17 12:03:46.875267 9 recording loss..\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for i in range(iters_num):\n",
    "    print(datetime.now(),i,\"start\")\n",
    "    # ミニバッチの取得\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    print(datetime.now(),i, \"calculating gradient..\")\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = nework.gradient(..) # 高速版\n",
    "    \n",
    "    # パラメータの更新\n",
    "    print(datetime.now(),i, \"updating params..\")\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 学習経過の記録\n",
    "    print(datetime.now(),i,\"recording loss..\")\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "# 10時間以上経っても終わらず。\n",
    "# 10ループなら11.5分程度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0:01:15 / loop\n",
    "- 75sec / loop\n",
    "- 10,000 loopだと\n",
    "  - 750,000 sec\n",
    "  - 10,250 min\n",
    "  - 170.8 hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "#iters_num = 10000\n",
    "iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 100 10\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc__list = []\n",
    "# 1エポックあたりの繰り返し数\n",
    "#iter_per_epoch = max(train_size / batch_size, 1)\n",
    "iter_per_epoch = 10\n",
    "\n",
    "print(train_size, batch_size, iter_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-19 19:26:35.675188 start 0\n",
      "2021-11-19 19:26:35.677078 calculating gradient.. 0\n",
      "2021-11-19 19:27:42.661685 updating params.. 0\n",
      "2021-11-19 19:27:42.662618 recording loss.. 0\n",
      "train acc, test acc | 0.0993,0.1032\n",
      "2021-11-19 19:27:43.508162 start 1\n",
      "2021-11-19 19:27:43.509223 calculating gradient.. 1\n",
      "2021-11-19 19:28:50.279328 updating params.. 1\n",
      "2021-11-19 19:28:50.280270 recording loss.. 1\n",
      "2021-11-19 19:28:50.281650 start 2\n",
      "2021-11-19 19:28:50.282083 calculating gradient.. 2\n",
      "2021-11-19 19:29:58.052645 updating params.. 2\n",
      "2021-11-19 19:29:58.053744 recording loss.. 2\n",
      "2021-11-19 19:29:58.054959 start 3\n",
      "2021-11-19 19:29:58.055618 calculating gradient.. 3\n",
      "2021-11-19 19:31:00.187560 updating params.. 3\n",
      "2021-11-19 19:31:00.188711 recording loss.. 3\n",
      "2021-11-19 19:31:00.190033 start 4\n",
      "2021-11-19 19:31:00.190760 calculating gradient.. 4\n",
      "2021-11-19 19:32:02.687492 updating params.. 4\n",
      "2021-11-19 19:32:02.689126 recording loss.. 4\n",
      "2021-11-19 19:32:02.690848 start 5\n",
      "2021-11-19 19:32:02.691595 calculating gradient.. 5\n",
      "2021-11-19 19:33:05.368358 updating params.. 5\n",
      "2021-11-19 19:33:05.369338 recording loss.. 5\n",
      "2021-11-19 19:33:05.370621 start 6\n",
      "2021-11-19 19:33:05.371323 calculating gradient.. 6\n",
      "2021-11-19 19:34:07.660181 updating params.. 6\n",
      "2021-11-19 19:34:07.661201 recording loss.. 6\n",
      "2021-11-19 19:34:07.662871 start 7\n",
      "2021-11-19 19:34:07.663278 calculating gradient.. 7\n",
      "2021-11-19 19:35:11.096193 updating params.. 7\n",
      "2021-11-19 19:35:11.097587 recording loss.. 7\n",
      "2021-11-19 19:35:11.099080 start 8\n",
      "2021-11-19 19:35:11.099817 calculating gradient.. 8\n",
      "2021-11-19 19:36:13.622724 updating params.. 8\n",
      "2021-11-19 19:36:13.623693 recording loss.. 8\n",
      "2021-11-19 19:36:13.624982 start 9\n",
      "2021-11-19 19:36:13.625706 calculating gradient.. 9\n",
      "2021-11-19 19:37:16.242512 updating params.. 9\n",
      "2021-11-19 19:37:16.243458 recording loss.. 9\n",
      "2021-11-19 19:37:16.244933 start 10\n",
      "2021-11-19 19:37:16.245635 calculating gradient.. 10\n",
      "2021-11-19 19:38:19.294615 updating params.. 10\n",
      "2021-11-19 19:38:19.295546 recording loss.. 10\n",
      "train acc, test acc | 0.11236666666666667,0.1135\n",
      "2021-11-19 19:38:20.284454 start 11\n",
      "2021-11-19 19:38:20.285587 calculating gradient.. 11\n",
      "2021-11-19 19:39:22.713859 updating params.. 11\n",
      "2021-11-19 19:39:22.714808 recording loss.. 11\n",
      "2021-11-19 19:39:22.716168 start 12\n",
      "2021-11-19 19:39:22.716905 calculating gradient.. 12\n",
      "2021-11-19 19:40:25.843503 updating params.. 12\n",
      "2021-11-19 19:40:25.844415 recording loss.. 12\n",
      "2021-11-19 19:40:25.845640 start 13\n",
      "2021-11-19 19:40:25.846339 calculating gradient.. 13\n",
      "2021-11-19 19:41:28.503906 updating params.. 13\n",
      "2021-11-19 19:41:28.504953 recording loss.. 13\n",
      "2021-11-19 19:41:28.506229 start 14\n",
      "2021-11-19 19:41:28.507081 calculating gradient.. 14\n",
      "2021-11-19 19:42:30.995542 updating params.. 14\n",
      "2021-11-19 19:42:30.996563 recording loss.. 14\n",
      "2021-11-19 19:42:30.997898 start 15\n",
      "2021-11-19 19:42:30.998607 calculating gradient.. 15\n",
      "2021-11-19 19:43:33.761004 updating params.. 15\n",
      "2021-11-19 19:43:33.761958 recording loss.. 15\n",
      "2021-11-19 19:43:33.763266 start 16\n",
      "2021-11-19 19:43:33.763981 calculating gradient.. 16\n",
      "2021-11-19 19:44:37.189716 updating params.. 16\n",
      "2021-11-19 19:44:37.190770 recording loss.. 16\n",
      "2021-11-19 19:44:37.192457 start 17\n",
      "2021-11-19 19:44:37.193248 calculating gradient.. 17\n",
      "2021-11-19 19:45:40.030328 updating params.. 17\n",
      "2021-11-19 19:45:40.031409 recording loss.. 17\n",
      "2021-11-19 19:45:40.033106 start 18\n",
      "2021-11-19 19:45:40.033975 calculating gradient.. 18\n",
      "2021-11-19 19:46:42.545009 updating params.. 18\n",
      "2021-11-19 19:46:42.546024 recording loss.. 18\n",
      "2021-11-19 19:46:42.547507 start 19\n",
      "2021-11-19 19:46:42.548352 calculating gradient.. 19\n",
      "2021-11-19 19:47:45.368357 updating params.. 19\n",
      "2021-11-19 19:47:45.369301 recording loss.. 19\n",
      "2021-11-19 19:47:45.370545 start 20\n",
      "2021-11-19 19:47:45.371299 calculating gradient.. 20\n",
      "2021-11-19 19:48:48.276725 updating params.. 20\n",
      "2021-11-19 19:48:48.277696 recording loss.. 20\n",
      "train acc, test acc | 0.09736666666666667,0.0982\n",
      "2021-11-19 19:48:48.835784 start 21\n",
      "2021-11-19 19:48:48.836516 calculating gradient.. 21\n",
      "2021-11-19 19:49:52.038737 updating params.. 21\n",
      "2021-11-19 19:49:52.039747 recording loss.. 21\n",
      "2021-11-19 19:49:52.040953 start 22\n",
      "2021-11-19 19:49:52.041669 calculating gradient.. 22\n",
      "2021-11-19 19:50:54.810153 updating params.. 22\n",
      "2021-11-19 19:50:54.811173 recording loss.. 22\n",
      "2021-11-19 19:50:54.812411 start 23\n",
      "2021-11-19 19:50:54.813137 calculating gradient.. 23\n",
      "2021-11-19 19:51:57.521898 updating params.. 23\n",
      "2021-11-19 19:51:57.522786 recording loss.. 23\n",
      "2021-11-19 19:51:57.523989 start 24\n",
      "2021-11-19 19:51:57.524636 calculating gradient.. 24\n",
      "2021-11-19 19:53:00.621578 updating params.. 24\n",
      "2021-11-19 19:53:00.622478 recording loss.. 24\n",
      "2021-11-19 19:53:00.623745 start 25\n",
      "2021-11-19 19:53:00.624484 calculating gradient.. 25\n",
      "2021-11-19 19:54:03.433082 updating params.. 25\n",
      "2021-11-19 19:54:03.434104 recording loss.. 25\n",
      "2021-11-19 19:54:03.435576 start 26\n",
      "2021-11-19 19:54:03.436008 calculating gradient.. 26\n",
      "2021-11-19 19:55:11.561077 updating params.. 26\n",
      "2021-11-19 19:55:11.562077 recording loss.. 26\n",
      "2021-11-19 19:55:11.563327 start 27\n",
      "2021-11-19 19:55:11.564052 calculating gradient.. 27\n",
      "2021-11-19 19:56:15.084364 updating params.. 27\n",
      "2021-11-19 19:56:15.085342 recording loss.. 27\n",
      "2021-11-19 19:56:15.086852 start 28\n",
      "2021-11-19 19:56:15.087671 calculating gradient.. 28\n",
      "2021-11-19 19:57:18.174442 updating params.. 28\n",
      "2021-11-19 19:57:18.175372 recording loss.. 28\n",
      "2021-11-19 19:57:18.176587 start 29\n",
      "2021-11-19 19:57:18.177272 calculating gradient.. 29\n",
      "2021-11-19 19:58:20.609689 updating params.. 29\n",
      "2021-11-19 19:58:20.610649 recording loss.. 29\n",
      "2021-11-19 19:58:20.611939 start 30\n",
      "2021-11-19 19:58:20.612637 calculating gradient.. 30\n",
      "2021-11-19 19:59:23.751248 updating params.. 30\n",
      "2021-11-19 19:59:23.752193 recording loss.. 30\n",
      "train acc, test acc | 0.0993,0.1032\n",
      "2021-11-19 19:59:24.313995 start 31\n",
      "2021-11-19 19:59:24.315073 calculating gradient.. 31\n",
      "2021-11-19 20:00:27.476657 updating params.. 31\n",
      "2021-11-19 20:00:27.477828 recording loss.. 31\n",
      "2021-11-19 20:00:27.479184 start 32\n",
      "2021-11-19 20:00:27.479904 calculating gradient.. 32\n",
      "2021-11-19 20:01:30.050788 updating params.. 32\n",
      "2021-11-19 20:01:30.051809 recording loss.. 32\n",
      "2021-11-19 20:01:30.053090 start 33\n",
      "2021-11-19 20:01:30.053810 calculating gradient.. 33\n",
      "2021-11-19 20:02:52.913936 updating params.. 33\n",
      "2021-11-19 20:02:52.914973 recording loss.. 33\n",
      "2021-11-19 20:02:52.916536 start 34\n",
      "2021-11-19 20:02:52.917310 calculating gradient.. 34\n",
      "2021-11-19 20:04:01.805122 updating params.. 34\n",
      "2021-11-19 20:04:01.806155 recording loss.. 34\n",
      "2021-11-19 20:04:01.807374 start 35\n",
      "2021-11-19 20:04:01.808105 calculating gradient.. 35\n",
      "2021-11-19 20:05:05.739562 updating params.. 35\n",
      "2021-11-19 20:05:05.740502 recording loss.. 35\n",
      "2021-11-19 20:05:05.741826 start 36\n",
      "2021-11-19 20:05:05.742631 calculating gradient.. 36\n",
      "2021-11-19 20:06:08.783295 updating params.. 36\n",
      "2021-11-19 20:06:08.784233 recording loss.. 36\n",
      "2021-11-19 20:06:08.785618 start 37\n",
      "2021-11-19 20:06:08.786401 calculating gradient.. 37\n",
      "2021-11-19 20:07:11.182679 updating params.. 37\n",
      "2021-11-19 20:07:11.183634 recording loss.. 37\n",
      "2021-11-19 20:07:11.184923 start 38\n",
      "2021-11-19 20:07:11.185658 calculating gradient.. 38\n",
      "2021-11-19 20:08:14.469562 updating params.. 38\n",
      "2021-11-19 20:08:14.470479 recording loss.. 38\n",
      "2021-11-19 20:08:14.471669 start 39\n",
      "2021-11-19 20:08:14.472333 calculating gradient.. 39\n",
      "2021-11-19 20:09:17.062499 updating params.. 39\n",
      "2021-11-19 20:09:17.063423 recording loss.. 39\n",
      "2021-11-19 20:09:17.064668 start 40\n",
      "2021-11-19 20:09:17.065349 calculating gradient.. 40\n",
      "2021-11-19 20:10:19.829161 updating params.. 40\n",
      "2021-11-19 20:10:19.830129 recording loss.. 40\n",
      "train acc, test acc | 0.10218333333333333,0.101\n",
      "2021-11-19 20:10:20.401139 start 41\n",
      "2021-11-19 20:10:20.402182 calculating gradient.. 41\n",
      "2021-11-19 20:11:23.612985 updating params.. 41\n",
      "2021-11-19 20:11:23.614006 recording loss.. 41\n",
      "2021-11-19 20:11:23.615048 start 42\n",
      "2021-11-19 20:11:23.615692 calculating gradient.. 42\n",
      "2021-11-19 20:12:26.078209 updating params.. 42\n",
      "2021-11-19 20:12:26.079160 recording loss.. 42\n",
      "2021-11-19 20:12:26.080454 start 43\n",
      "2021-11-19 20:12:26.081154 calculating gradient.. 43\n",
      "2021-11-19 20:13:28.781815 updating params.. 43\n",
      "2021-11-19 20:13:28.782822 recording loss.. 43\n",
      "2021-11-19 20:13:28.784079 start 44\n",
      "2021-11-19 20:13:28.784722 calculating gradient.. 44\n",
      "2021-11-19 20:14:32.213008 updating params.. 44\n",
      "2021-11-19 20:14:32.214000 recording loss.. 44\n",
      "2021-11-19 20:14:32.215352 start 45\n",
      "2021-11-19 20:14:32.216054 calculating gradient.. 45\n",
      "2021-11-19 20:15:34.614505 updating params.. 45\n",
      "2021-11-19 20:15:34.615450 recording loss.. 45\n",
      "2021-11-19 20:15:34.616687 start 46\n",
      "2021-11-19 20:15:34.617378 calculating gradient.. 46\n",
      "2021-11-19 20:16:37.228852 updating params.. 46\n",
      "2021-11-19 20:16:37.229817 recording loss.. 46\n",
      "2021-11-19 20:16:37.231118 start 47\n",
      "2021-11-19 20:16:37.231829 calculating gradient.. 47\n",
      "2021-11-19 20:17:40.282451 updating params.. 47\n",
      "2021-11-19 20:17:40.283375 recording loss.. 47\n",
      "2021-11-19 20:17:40.284603 start 48\n",
      "2021-11-19 20:17:40.285276 calculating gradient.. 48\n",
      "2021-11-19 20:18:42.977083 updating params.. 48\n",
      "2021-11-19 20:18:42.978026 recording loss.. 48\n",
      "2021-11-19 20:18:42.979245 start 49\n",
      "2021-11-19 20:18:42.979886 calculating gradient.. 49\n",
      "2021-11-19 20:19:45.678826 updating params.. 49\n",
      "2021-11-19 20:19:45.679798 recording loss.. 49\n",
      "2021-11-19 20:19:45.681339 start 50\n",
      "2021-11-19 20:19:45.682130 calculating gradient.. 50\n",
      "2021-11-19 20:20:49.140572 updating params.. 50\n",
      "2021-11-19 20:20:49.141612 recording loss.. 50\n",
      "train acc, test acc | 0.09915,0.1009\n",
      "2021-11-19 20:20:49.701344 start 51\n",
      "2021-11-19 20:20:49.702372 calculating gradient.. 51\n",
      "2021-11-19 20:21:52.061572 updating params.. 51\n",
      "2021-11-19 20:21:52.062563 recording loss.. 51\n",
      "2021-11-19 20:21:52.064248 start 52\n",
      "2021-11-19 20:21:52.064924 calculating gradient.. 52\n",
      "2021-11-19 20:22:54.923131 updating params.. 52\n",
      "2021-11-19 20:22:54.924123 recording loss.. 52\n",
      "2021-11-19 20:22:54.925462 start 53\n",
      "2021-11-19 20:22:54.926164 calculating gradient.. 53\n",
      "2021-11-19 20:23:57.984773 updating params.. 53\n",
      "2021-11-19 20:23:57.985706 recording loss.. 53\n",
      "2021-11-19 20:23:57.987132 start 54\n",
      "2021-11-19 20:23:57.988001 calculating gradient.. 54\n",
      "2021-11-19 20:25:02.057153 updating params.. 54\n",
      "2021-11-19 20:25:02.058126 recording loss.. 54\n",
      "2021-11-19 20:25:02.059405 start 55\n",
      "2021-11-19 20:25:02.060066 calculating gradient.. 55\n",
      "2021-11-19 20:26:04.770815 updating params.. 55\n",
      "2021-11-19 20:26:04.771798 recording loss.. 55\n",
      "2021-11-19 20:26:04.773409 start 56\n",
      "2021-11-19 20:26:04.774313 calculating gradient.. 56\n",
      "2021-11-19 20:27:07.804305 updating params.. 56\n",
      "2021-11-19 20:27:07.805262 recording loss.. 56\n",
      "2021-11-19 20:27:07.806556 start 57\n",
      "2021-11-19 20:27:07.807432 calculating gradient.. 57\n",
      "2021-11-19 20:28:10.573766 updating params.. 57\n",
      "2021-11-19 20:28:10.574686 recording loss.. 57\n",
      "2021-11-19 20:28:10.575800 start 58\n",
      "2021-11-19 20:28:10.576458 calculating gradient.. 58\n",
      "2021-11-19 20:29:13.178160 updating params.. 58\n",
      "2021-11-19 20:29:13.179106 recording loss.. 58\n",
      "2021-11-19 20:29:13.180387 start 59\n",
      "2021-11-19 20:29:13.181108 calculating gradient.. 59\n",
      "2021-11-19 20:30:16.158117 updating params.. 59\n",
      "2021-11-19 20:30:16.159056 recording loss.. 59\n",
      "2021-11-19 20:30:16.160386 start 60\n",
      "2021-11-19 20:30:16.161098 calculating gradient.. 60\n",
      "2021-11-19 20:31:18.955425 updating params.. 60\n",
      "2021-11-19 20:31:18.956378 recording loss.. 60\n",
      "train acc, test acc | 0.18336666666666668,0.187\n",
      "2021-11-19 20:31:19.514404 start 61\n",
      "2021-11-19 20:31:19.515173 calculating gradient.. 61\n",
      "2021-11-19 20:32:22.083493 updating params.. 61\n",
      "2021-11-19 20:32:22.084702 recording loss.. 61\n",
      "2021-11-19 20:32:22.086617 start 62\n",
      "2021-11-19 20:32:22.087398 calculating gradient.. 62\n",
      "2021-11-19 20:33:24.755852 updating params.. 62\n",
      "2021-11-19 20:33:24.756788 recording loss.. 62\n",
      "2021-11-19 20:33:24.757921 start 63\n",
      "2021-11-19 20:33:24.758580 calculating gradient.. 63\n",
      "2021-11-19 20:34:27.487892 updating params.. 63\n",
      "2021-11-19 20:34:27.488845 recording loss.. 63\n",
      "2021-11-19 20:34:27.490173 start 64\n",
      "2021-11-19 20:34:27.490827 calculating gradient.. 64\n",
      "2021-11-19 20:35:30.744436 updating params.. 64\n",
      "2021-11-19 20:35:30.745356 recording loss.. 64\n",
      "2021-11-19 20:35:30.746560 start 65\n",
      "2021-11-19 20:35:30.747281 calculating gradient.. 65\n",
      "2021-11-19 20:36:33.587228 updating params.. 65\n",
      "2021-11-19 20:36:33.588161 recording loss.. 65\n",
      "2021-11-19 20:36:33.589401 start 66\n",
      "2021-11-19 20:36:33.590139 calculating gradient.. 66\n",
      "2021-11-19 20:37:36.063077 updating params.. 66\n",
      "2021-11-19 20:37:36.064013 recording loss.. 66\n",
      "2021-11-19 20:37:36.065271 start 67\n",
      "2021-11-19 20:37:36.066008 calculating gradient.. 67\n",
      "2021-11-19 20:38:39.594871 updating params.. 67\n",
      "2021-11-19 20:38:39.595848 recording loss.. 67\n",
      "2021-11-19 20:38:39.597193 start 68\n",
      "2021-11-19 20:38:39.597919 calculating gradient.. 68\n",
      "2021-11-19 20:39:42.394926 updating params.. 68\n",
      "2021-11-19 20:39:42.396046 recording loss.. 68\n",
      "2021-11-19 20:39:42.397788 start 69\n",
      "2021-11-19 20:39:42.398616 calculating gradient.. 69\n",
      "2021-11-19 20:40:45.180632 updating params.. 69\n",
      "2021-11-19 20:40:45.181707 recording loss.. 69\n",
      "2021-11-19 20:40:45.183095 start 70\n",
      "2021-11-19 20:40:45.183809 calculating gradient.. 70\n",
      "2021-11-19 20:41:48.524576 updating params.. 70\n",
      "2021-11-19 20:41:48.525519 recording loss.. 70\n",
      "train acc, test acc | 0.09871666666666666,0.098\n",
      "2021-11-19 20:41:49.078587 start 71\n",
      "2021-11-19 20:41:49.079676 calculating gradient.. 71\n",
      "2021-11-19 20:42:51.581942 updating params.. 71\n",
      "2021-11-19 20:42:51.582877 recording loss.. 71\n",
      "2021-11-19 20:42:51.584154 start 72\n",
      "2021-11-19 20:42:51.584861 calculating gradient.. 72\n",
      "2021-11-19 20:43:54.189561 updating params.. 72\n",
      "2021-11-19 20:43:54.190556 recording loss.. 72\n",
      "2021-11-19 20:43:54.191848 start 73\n",
      "2021-11-19 20:43:54.192548 calculating gradient.. 73\n",
      "2021-11-19 20:44:59.570125 updating params.. 73\n",
      "2021-11-19 20:44:59.571111 recording loss.. 73\n",
      "2021-11-19 20:44:59.572302 start 74\n",
      "2021-11-19 20:44:59.573008 calculating gradient.. 74\n",
      "2021-11-19 20:46:02.592965 updating params.. 74\n",
      "2021-11-19 20:46:02.593540 recording loss.. 74\n",
      "2021-11-19 20:46:02.596427 start 75\n",
      "2021-11-19 20:46:02.599944 calculating gradient.. 75\n",
      "2021-11-19 20:47:13.305684 updating params.. 75\n",
      "2021-11-19 20:47:13.306618 recording loss.. 75\n",
      "2021-11-19 20:47:13.307939 start 76\n",
      "2021-11-19 20:47:13.308619 calculating gradient.. 76\n",
      "2021-11-19 20:48:41.901155 updating params.. 76\n",
      "2021-11-19 20:48:41.902064 recording loss.. 76\n",
      "2021-11-19 20:48:41.903108 start 77\n",
      "2021-11-19 20:48:41.903843 calculating gradient.. 77\n",
      "2021-11-19 20:49:50.097903 updating params.. 77\n",
      "2021-11-19 20:49:50.099159 recording loss.. 77\n",
      "2021-11-19 20:49:50.100514 start 78\n",
      "2021-11-19 20:49:50.101254 calculating gradient.. 78\n",
      "2021-11-19 20:50:59.216147 updating params.. 78\n",
      "2021-11-19 20:50:59.217086 recording loss.. 78\n",
      "2021-11-19 20:50:59.218316 start 79\n",
      "2021-11-19 20:50:59.218977 calculating gradient.. 79\n",
      "2021-11-19 20:52:02.664341 updating params.. 79\n",
      "2021-11-19 20:52:02.665301 recording loss.. 79\n",
      "2021-11-19 20:52:02.666510 start 80\n",
      "2021-11-19 20:52:02.667161 calculating gradient.. 80\n",
      "2021-11-19 20:53:06.181271 updating params.. 80\n",
      "2021-11-19 20:53:06.182213 recording loss.. 80\n",
      "train acc, test acc | 0.10441666666666667,0.1028\n",
      "2021-11-19 20:53:06.895027 start 81\n",
      "2021-11-19 20:53:06.895781 calculating gradient.. 81\n",
      "2021-11-19 20:54:10.006306 updating params.. 81\n",
      "2021-11-19 20:54:10.007245 recording loss.. 81\n",
      "2021-11-19 20:54:10.008480 start 82\n",
      "2021-11-19 20:54:10.009135 calculating gradient.. 82\n",
      "2021-11-19 20:55:13.931754 updating params.. 82\n",
      "2021-11-19 20:55:13.932673 recording loss.. 82\n",
      "2021-11-19 20:55:13.933994 start 83\n",
      "2021-11-19 20:55:13.934664 calculating gradient.. 83\n",
      "2021-11-19 20:56:23.894056 updating params.. 83\n",
      "2021-11-19 20:56:23.894491 recording loss.. 83\n",
      "2021-11-19 20:56:23.896070 start 84\n",
      "2021-11-19 20:56:23.896494 calculating gradient.. 84\n",
      "2021-11-19 20:57:28.734327 updating params.. 84\n",
      "2021-11-19 20:57:28.735278 recording loss.. 84\n",
      "2021-11-19 20:57:28.736575 start 85\n",
      "2021-11-19 20:57:28.737236 calculating gradient.. 85\n",
      "2021-11-19 20:58:37.944454 updating params.. 85\n",
      "2021-11-19 20:58:37.945683 recording loss.. 85\n",
      "2021-11-19 20:58:37.947397 start 86\n",
      "2021-11-19 20:58:37.948099 calculating gradient.. 86\n",
      "2021-11-19 20:59:43.196571 updating params.. 86\n",
      "2021-11-19 20:59:43.197538 recording loss.. 86\n",
      "2021-11-19 20:59:43.198899 start 87\n",
      "2021-11-19 20:59:43.199562 calculating gradient.. 87\n",
      "2021-11-19 21:00:46.962210 updating params.. 87\n",
      "2021-11-19 21:00:46.963202 recording loss.. 87\n",
      "2021-11-19 21:00:46.964986 start 88\n",
      "2021-11-19 21:00:46.965858 calculating gradient.. 88\n",
      "2021-11-19 21:01:50.115120 updating params.. 88\n",
      "2021-11-19 21:01:50.116075 recording loss.. 88\n",
      "2021-11-19 21:01:50.117399 start 89\n",
      "2021-11-19 21:01:50.118107 calculating gradient.. 89\n",
      "2021-11-19 21:03:24.886261 updating params.. 89\n",
      "2021-11-19 21:03:24.887218 recording loss.. 89\n",
      "2021-11-19 21:03:24.888441 start 90\n",
      "2021-11-19 21:03:24.889100 calculating gradient.. 90\n",
      "2021-11-19 21:04:28.300702 updating params.. 90\n",
      "2021-11-19 21:04:28.301768 recording loss.. 90\n",
      "train acc, test acc | 0.11246666666666667,0.1137\n",
      "2021-11-19 21:04:29.182764 start 91\n",
      "2021-11-19 21:04:29.183522 calculating gradient.. 91\n",
      "2021-11-19 21:05:32.644929 updating params.. 91\n",
      "2021-11-19 21:05:32.645902 recording loss.. 91\n",
      "2021-11-19 21:05:32.647432 start 92\n",
      "2021-11-19 21:05:32.648206 calculating gradient.. 92\n",
      "2021-11-19 21:06:36.002262 updating params.. 92\n",
      "2021-11-19 21:06:36.003206 recording loss.. 92\n",
      "2021-11-19 21:06:36.004246 start 93\n",
      "2021-11-19 21:06:36.004901 calculating gradient.. 93\n",
      "2021-11-19 21:07:38.689868 updating params.. 93\n",
      "2021-11-19 21:07:38.690895 recording loss.. 93\n",
      "2021-11-19 21:07:38.692169 start 94\n",
      "2021-11-19 21:07:38.692827 calculating gradient.. 94\n",
      "2021-11-19 21:08:41.849053 updating params.. 94\n",
      "2021-11-19 21:08:41.849998 recording loss.. 94\n",
      "2021-11-19 21:08:41.851244 start 95\n",
      "2021-11-19 21:08:41.851974 calculating gradient.. 95\n",
      "2021-11-19 21:09:45.874519 updating params.. 95\n",
      "2021-11-19 21:09:45.875536 recording loss.. 95\n",
      "2021-11-19 21:09:45.877393 start 96\n",
      "2021-11-19 21:09:45.878250 calculating gradient.. 96\n",
      "2021-11-19 21:10:48.626097 updating params.. 96\n",
      "2021-11-19 21:10:48.627021 recording loss.. 96\n",
      "2021-11-19 21:10:48.628256 start 97\n",
      "2021-11-19 21:10:48.628991 calculating gradient.. 97\n",
      "2021-11-19 21:11:51.496065 updating params.. 97\n",
      "2021-11-19 21:11:51.497024 recording loss.. 97\n",
      "2021-11-19 21:11:51.498302 start 98\n",
      "2021-11-19 21:11:51.498962 calculating gradient.. 98\n",
      "2021-11-19 21:12:55.077568 updating params.. 98\n",
      "2021-11-19 21:12:55.078682 recording loss.. 98\n",
      "2021-11-19 21:12:55.080136 start 99\n",
      "2021-11-19 21:12:55.080865 calculating gradient.. 99\n",
      "2021-11-19 21:13:58.113740 updating params.. 99\n",
      "2021-11-19 21:13:58.114765 recording loss.. 99\n",
      "2021-11-19 21:13:58.115971 start 100\n",
      "2021-11-19 21:13:58.116726 calculating gradient.. 100\n",
      "2021-11-19 21:15:01.805651 updating params.. 100\n",
      "2021-11-19 21:15:01.806596 recording loss.. 100\n",
      "train acc, test acc | 0.20355,0.2068\n",
      "2021-11-19 21:15:02.404354 start 101\n",
      "2021-11-19 21:15:02.405594 calculating gradient.. 101\n",
      "2021-11-19 21:16:05.620835 updating params.. 101\n",
      "2021-11-19 21:16:05.621867 recording loss.. 101\n",
      "2021-11-19 21:16:05.623127 start 102\n",
      "2021-11-19 21:16:05.623836 calculating gradient.. 102\n",
      "2021-11-19 21:17:08.657560 updating params.. 102\n",
      "2021-11-19 21:17:08.658518 recording loss.. 102\n",
      "2021-11-19 21:17:08.660113 start 103\n",
      "2021-11-19 21:17:08.661085 calculating gradient.. 103\n",
      "2021-11-19 21:18:11.917367 updating params.. 103\n",
      "2021-11-19 21:18:11.918367 recording loss.. 103\n",
      "2021-11-19 21:18:11.919841 start 104\n",
      "2021-11-19 21:18:11.920549 calculating gradient.. 104\n",
      "2021-11-19 21:19:15.314131 updating params.. 104\n",
      "2021-11-19 21:19:15.315141 recording loss.. 104\n",
      "2021-11-19 21:19:15.316347 start 105\n",
      "2021-11-19 21:19:15.316990 calculating gradient.. 105\n",
      "2021-11-19 21:20:18.573341 updating params.. 105\n",
      "2021-11-19 21:20:18.574267 recording loss.. 105\n",
      "2021-11-19 21:20:18.575482 start 106\n",
      "2021-11-19 21:20:18.576180 calculating gradient.. 106\n",
      "2021-11-19 21:21:22.344608 updating params.. 106\n",
      "2021-11-19 21:21:22.345594 recording loss.. 106\n",
      "2021-11-19 21:21:22.346814 start 107\n",
      "2021-11-19 21:21:22.347459 calculating gradient.. 107\n",
      "2021-11-19 21:22:24.969430 updating params.. 107\n",
      "2021-11-19 21:22:24.970334 recording loss.. 107\n",
      "2021-11-19 21:22:24.971539 start 108\n",
      "2021-11-19 21:22:24.972178 calculating gradient.. 108\n",
      "2021-11-19 21:23:28.433359 updating params.. 108\n",
      "2021-11-19 21:23:28.434302 recording loss.. 108\n",
      "2021-11-19 21:23:28.435582 start 109\n",
      "2021-11-19 21:23:28.436286 calculating gradient.. 109\n",
      "2021-11-19 21:24:32.587490 updating params.. 109\n",
      "2021-11-19 21:24:32.588437 recording loss.. 109\n",
      "2021-11-19 21:24:32.589977 start 110\n",
      "2021-11-19 21:24:32.591735 calculating gradient.. 110\n",
      "2021-11-19 21:25:35.939476 updating params.. 110\n",
      "2021-11-19 21:25:35.940591 recording loss.. 110\n",
      "train acc, test acc | 0.19503333333333334,0.1976\n",
      "2021-11-19 21:25:36.775947 start 111\n",
      "2021-11-19 21:25:36.776798 calculating gradient.. 111\n",
      "2021-11-19 21:26:39.699715 updating params.. 111\n",
      "2021-11-19 21:26:39.700649 recording loss.. 111\n",
      "2021-11-19 21:26:39.701918 start 112\n",
      "2021-11-19 21:26:39.702593 calculating gradient.. 112\n",
      "2021-11-19 21:27:42.839463 updating params.. 112\n",
      "2021-11-19 21:27:42.840432 recording loss.. 112\n",
      "2021-11-19 21:27:42.841778 start 113\n",
      "2021-11-19 21:27:42.842580 calculating gradient.. 113\n",
      "2021-11-19 21:28:45.792752 updating params.. 113\n",
      "2021-11-19 21:28:45.793709 recording loss.. 113\n",
      "2021-11-19 21:28:45.795045 start 114\n",
      "2021-11-19 21:28:45.795905 calculating gradient.. 114\n",
      "2021-11-19 21:29:50.036317 updating params.. 114\n",
      "2021-11-19 21:29:50.037301 recording loss.. 114\n",
      "2021-11-19 21:29:50.038572 start 115\n",
      "2021-11-19 21:29:50.039221 calculating gradient.. 115\n",
      "2021-11-19 21:30:53.305512 updating params.. 115\n",
      "2021-11-19 21:30:53.306460 recording loss.. 115\n",
      "2021-11-19 21:30:53.307763 start 116\n",
      "2021-11-19 21:30:53.308499 calculating gradient.. 116\n",
      "2021-11-19 21:31:56.410238 updating params.. 116\n",
      "2021-11-19 21:31:56.411251 recording loss.. 116\n",
      "2021-11-19 21:31:56.412843 start 117\n",
      "2021-11-19 21:31:56.413683 calculating gradient.. 117\n",
      "2021-11-19 21:32:59.692205 updating params.. 117\n",
      "2021-11-19 21:32:59.693165 recording loss.. 117\n",
      "2021-11-19 21:32:59.694479 start 118\n",
      "2021-11-19 21:32:59.695183 calculating gradient.. 118\n",
      "2021-11-19 21:34:02.890014 updating params.. 118\n",
      "2021-11-19 21:34:02.891048 recording loss.. 118\n",
      "2021-11-19 21:34:02.892366 start 119\n",
      "2021-11-19 21:34:02.893100 calculating gradient.. 119\n",
      "2021-11-19 21:35:06.617417 updating params.. 119\n",
      "2021-11-19 21:35:06.618302 recording loss.. 119\n",
      "2021-11-19 21:35:06.619659 start 120\n",
      "2021-11-19 21:35:06.620357 calculating gradient.. 120\n",
      "2021-11-19 21:36:09.807850 updating params.. 120\n",
      "2021-11-19 21:36:09.808876 recording loss.. 120\n",
      "train acc, test acc | 0.21626666666666666,0.2193\n",
      "2021-11-19 21:36:10.376568 start 121\n",
      "2021-11-19 21:36:10.377612 calculating gradient.. 121\n",
      "2021-11-19 21:37:13.211039 updating params.. 121\n",
      "2021-11-19 21:37:13.212028 recording loss.. 121\n",
      "2021-11-19 21:37:13.213320 start 122\n",
      "2021-11-19 21:37:13.213971 calculating gradient.. 122\n",
      "2021-11-19 21:38:16.398973 updating params.. 122\n",
      "2021-11-19 21:38:16.399896 recording loss.. 122\n",
      "2021-11-19 21:38:16.401241 start 123\n",
      "2021-11-19 21:38:16.401970 calculating gradient.. 123\n",
      "2021-11-19 21:39:19.382480 updating params.. 123\n",
      "2021-11-19 21:39:19.383789 recording loss.. 123\n",
      "2021-11-19 21:39:19.385597 start 124\n",
      "2021-11-19 21:39:19.386464 calculating gradient.. 124\n",
      "2021-11-19 21:40:22.536864 updating params.. 124\n",
      "2021-11-19 21:40:22.537889 recording loss.. 124\n",
      "2021-11-19 21:40:22.539210 start 125\n",
      "2021-11-19 21:40:22.539920 calculating gradient.. 125\n",
      "2021-11-19 21:41:25.505661 updating params.. 125\n",
      "2021-11-19 21:41:25.506578 recording loss.. 125\n",
      "2021-11-19 21:41:25.508228 start 126\n",
      "2021-11-19 21:41:25.509102 calculating gradient.. 126\n",
      "2021-11-19 21:42:28.880552 updating params.. 126\n",
      "2021-11-19 21:42:28.881543 recording loss.. 126\n",
      "2021-11-19 21:42:28.883165 start 127\n",
      "2021-11-19 21:42:28.883908 calculating gradient.. 127\n",
      "2021-11-19 21:43:32.266704 updating params.. 127\n",
      "2021-11-19 21:43:32.267664 recording loss.. 127\n",
      "2021-11-19 21:43:32.268938 start 128\n",
      "2021-11-19 21:43:32.269677 calculating gradient.. 128\n",
      "2021-11-19 21:44:35.862163 updating params.. 128\n",
      "2021-11-19 21:44:35.863133 recording loss.. 128\n",
      "2021-11-19 21:44:35.864809 start 129\n",
      "2021-11-19 21:44:35.865655 calculating gradient.. 129\n",
      "2021-11-19 21:45:39.190467 updating params.. 129\n",
      "2021-11-19 21:45:39.191394 recording loss.. 129\n",
      "2021-11-19 21:45:39.192759 start 130\n",
      "2021-11-19 21:45:39.193465 calculating gradient.. 130\n",
      "2021-11-19 21:46:42.218752 updating params.. 130\n",
      "2021-11-19 21:46:42.219688 recording loss.. 130\n",
      "train acc, test acc | 0.18788333333333335,0.1889\n",
      "2021-11-19 21:46:42.796787 start 131\n",
      "2021-11-19 21:46:42.797836 calculating gradient.. 131\n",
      "2021-11-19 21:47:45.864227 updating params.. 131\n",
      "2021-11-19 21:47:45.865169 recording loss.. 131\n",
      "2021-11-19 21:47:45.866476 start 132\n",
      "2021-11-19 21:47:45.867202 calculating gradient.. 132\n",
      "2021-11-19 21:48:49.213938 updating params.. 132\n",
      "2021-11-19 21:48:49.214899 recording loss.. 132\n",
      "2021-11-19 21:48:49.216269 start 133\n",
      "2021-11-19 21:48:49.217080 calculating gradient.. 133\n",
      "2021-11-19 21:49:52.592521 updating params.. 133\n",
      "2021-11-19 21:49:52.593493 recording loss.. 133\n",
      "2021-11-19 21:49:52.594813 start 134\n",
      "2021-11-19 21:49:52.595554 calculating gradient.. 134\n",
      "2021-11-19 21:50:55.438069 updating params.. 134\n",
      "2021-11-19 21:50:55.439020 recording loss.. 134\n",
      "2021-11-19 21:50:55.440359 start 135\n",
      "2021-11-19 21:50:55.441080 calculating gradient.. 135\n",
      "2021-11-19 21:51:58.474965 updating params.. 135\n",
      "2021-11-19 21:51:58.475955 recording loss.. 135\n",
      "2021-11-19 21:51:58.477352 start 136\n",
      "2021-11-19 21:51:58.478034 calculating gradient.. 136\n",
      "2021-11-19 21:53:00.328733 updating params.. 136\n",
      "2021-11-19 21:53:00.329715 recording loss.. 136\n",
      "2021-11-19 21:53:00.330974 start 137\n",
      "2021-11-19 21:53:00.331683 calculating gradient.. 137\n",
      "2021-11-19 21:54:02.903658 updating params.. 137\n",
      "2021-11-19 21:54:02.904655 recording loss.. 137\n",
      "2021-11-19 21:54:02.906367 start 138\n",
      "2021-11-19 21:54:02.907063 calculating gradient.. 138\n",
      "2021-11-19 21:55:05.290586 updating params.. 138\n",
      "2021-11-19 21:55:05.291610 recording loss.. 138\n",
      "2021-11-19 21:55:05.292823 start 139\n",
      "2021-11-19 21:55:05.293324 calculating gradient.. 139\n",
      "2021-11-19 21:56:08.046775 updating params.. 139\n",
      "2021-11-19 21:56:08.047772 recording loss.. 139\n",
      "2021-11-19 21:56:08.049055 start 140\n",
      "2021-11-19 21:56:08.049813 calculating gradient.. 140\n",
      "2021-11-19 21:57:10.716530 updating params.. 140\n",
      "2021-11-19 21:57:10.717439 recording loss.. 140\n",
      "train acc, test acc | 0.21296666666666667,0.2152\n",
      "2021-11-19 21:57:11.269813 start 141\n",
      "2021-11-19 21:57:11.270751 calculating gradient.. 141\n",
      "2021-11-19 21:58:13.332679 updating params.. 141\n",
      "2021-11-19 21:58:13.333648 recording loss.. 141\n",
      "2021-11-19 21:58:13.334951 start 142\n",
      "2021-11-19 21:58:13.335673 calculating gradient.. 142\n",
      "2021-11-19 21:59:15.500928 updating params.. 142\n",
      "2021-11-19 21:59:15.501874 recording loss.. 142\n",
      "2021-11-19 21:59:15.503156 start 143\n",
      "2021-11-19 21:59:15.503872 calculating gradient.. 143\n",
      "2021-11-19 22:00:18.749593 updating params.. 143\n",
      "2021-11-19 22:00:18.750541 recording loss.. 143\n",
      "2021-11-19 22:00:18.751905 start 144\n",
      "2021-11-19 22:00:18.752628 calculating gradient.. 144\n",
      "2021-11-19 22:01:21.112662 updating params.. 144\n",
      "2021-11-19 22:01:21.113700 recording loss.. 144\n",
      "2021-11-19 22:01:21.115248 start 145\n",
      "2021-11-19 22:01:21.116048 calculating gradient.. 145\n",
      "2021-11-19 22:02:36.468312 updating params.. 145\n",
      "2021-11-19 22:02:36.469504 recording loss.. 145\n",
      "2021-11-19 22:02:36.471592 start 146\n",
      "2021-11-19 22:02:36.472587 calculating gradient.. 146\n",
      "2021-11-19 22:03:51.923084 updating params.. 146\n",
      "2021-11-19 22:03:51.924000 recording loss.. 146\n",
      "2021-11-19 22:03:51.925215 start 147\n",
      "2021-11-19 22:03:51.925931 calculating gradient.. 147\n",
      "2021-11-19 22:04:55.347422 updating params.. 147\n",
      "2021-11-19 22:04:55.348352 recording loss.. 147\n",
      "2021-11-19 22:04:55.349666 start 148\n",
      "2021-11-19 22:04:55.350322 calculating gradient.. 148\n",
      "2021-11-19 22:05:59.867074 updating params.. 148\n",
      "2021-11-19 22:05:59.868357 recording loss.. 148\n",
      "2021-11-19 22:05:59.878643 start 149\n",
      "2021-11-19 22:05:59.879926 calculating gradient.. 149\n",
      "2021-11-19 22:07:05.196033 updating params.. 149\n",
      "2021-11-19 22:07:05.196997 recording loss.. 149\n",
      "2021-11-19 22:07:05.198317 start 150\n",
      "2021-11-19 22:07:05.199029 calculating gradient.. 150\n",
      "2021-11-19 22:08:07.392748 updating params.. 150\n",
      "2021-11-19 22:08:07.393746 recording loss.. 150\n",
      "train acc, test acc | 0.36905,0.3722\n",
      "2021-11-19 22:08:07.945097 start 151\n",
      "2021-11-19 22:08:07.946127 calculating gradient.. 151\n",
      "2021-11-19 22:09:10.135050 updating params.. 151\n",
      "2021-11-19 22:09:10.135968 recording loss.. 151\n",
      "2021-11-19 22:09:10.136991 start 152\n",
      "2021-11-19 22:09:10.137653 calculating gradient.. 152\n",
      "2021-11-19 22:10:12.668389 updating params.. 152\n",
      "2021-11-19 22:10:12.669369 recording loss.. 152\n",
      "2021-11-19 22:10:12.670516 start 153\n",
      "2021-11-19 22:10:12.671205 calculating gradient.. 153\n",
      "2021-11-19 22:11:14.876434 updating params.. 153\n",
      "2021-11-19 22:11:14.877367 recording loss.. 153\n",
      "2021-11-19 22:11:14.878568 start 154\n",
      "2021-11-19 22:11:14.879221 calculating gradient.. 154\n",
      "2021-11-19 22:12:16.950052 updating params.. 154\n",
      "2021-11-19 22:12:16.950967 recording loss.. 154\n",
      "2021-11-19 22:12:16.952230 start 155\n",
      "2021-11-19 22:12:16.952912 calculating gradient.. 155\n",
      "2021-11-19 22:13:19.206303 updating params.. 155\n",
      "2021-11-19 22:13:19.207262 recording loss.. 155\n",
      "2021-11-19 22:13:19.208795 start 156\n",
      "2021-11-19 22:13:19.209721 calculating gradient.. 156\n",
      "2021-11-19 22:14:21.379704 updating params.. 156\n",
      "2021-11-19 22:14:21.380614 recording loss.. 156\n",
      "2021-11-19 22:14:21.381875 start 157\n",
      "2021-11-19 22:14:21.382541 calculating gradient.. 157\n",
      "2021-11-19 22:15:24.377196 updating params.. 157\n",
      "2021-11-19 22:15:24.378126 recording loss.. 157\n",
      "2021-11-19 22:15:24.379341 start 158\n",
      "2021-11-19 22:15:24.380006 calculating gradient.. 158\n",
      "2021-11-19 22:16:26.599235 updating params.. 158\n",
      "2021-11-19 22:16:26.600208 recording loss.. 158\n",
      "2021-11-19 22:16:26.601609 start 159\n",
      "2021-11-19 22:16:26.602320 calculating gradient.. 159\n",
      "2021-11-19 22:17:28.582035 updating params.. 159\n",
      "2021-11-19 22:17:28.583049 recording loss.. 159\n",
      "2021-11-19 22:17:28.584719 start 160\n",
      "2021-11-19 22:17:28.585649 calculating gradient.. 160\n",
      "2021-11-19 22:18:30.771225 updating params.. 160\n",
      "2021-11-19 22:18:30.771597 recording loss.. 160\n",
      "train acc, test acc | 0.20296666666666666,0.213\n",
      "2021-11-19 22:18:31.325870 start 161\n",
      "2021-11-19 22:18:31.326714 calculating gradient.. 161\n",
      "2021-11-19 22:19:34.107239 updating params.. 161\n",
      "2021-11-19 22:19:34.108188 recording loss.. 161\n",
      "2021-11-19 22:19:34.109955 start 162\n",
      "2021-11-19 22:19:34.110827 calculating gradient.. 162\n",
      "2021-11-19 22:20:37.445873 updating params.. 162\n",
      "2021-11-19 22:20:37.446819 recording loss.. 162\n",
      "2021-11-19 22:20:37.448048 start 163\n",
      "2021-11-19 22:20:37.448704 calculating gradient.. 163\n",
      "2021-11-19 22:21:39.735461 updating params.. 163\n",
      "2021-11-19 22:21:39.736390 recording loss.. 163\n",
      "2021-11-19 22:21:39.737606 start 164\n",
      "2021-11-19 22:21:39.738280 calculating gradient.. 164\n",
      "2021-11-19 22:22:41.876208 updating params.. 164\n",
      "2021-11-19 22:22:41.877261 recording loss.. 164\n",
      "2021-11-19 22:22:41.878477 start 165\n",
      "2021-11-19 22:22:41.879132 calculating gradient.. 165\n",
      "2021-11-19 22:23:44.594149 updating params.. 165\n",
      "2021-11-19 22:23:44.595095 recording loss.. 165\n",
      "2021-11-19 22:23:44.596379 start 166\n",
      "2021-11-19 22:23:44.597125 calculating gradient.. 166\n",
      "2021-11-19 22:24:47.184529 updating params.. 166\n",
      "2021-11-19 22:24:47.185488 recording loss.. 166\n",
      "2021-11-19 22:24:47.186810 start 167\n",
      "2021-11-19 22:24:47.187475 calculating gradient.. 167\n",
      "2021-11-19 22:25:49.658468 updating params.. 167\n",
      "2021-11-19 22:25:49.659429 recording loss.. 167\n",
      "2021-11-19 22:25:49.660717 start 168\n",
      "2021-11-19 22:25:49.661601 calculating gradient.. 168\n",
      "2021-11-19 22:26:51.997138 updating params.. 168\n",
      "2021-11-19 22:26:51.998091 recording loss.. 168\n",
      "2021-11-19 22:26:51.999372 start 169\n",
      "2021-11-19 22:26:52.000075 calculating gradient.. 169\n",
      "2021-11-19 22:27:54.191512 updating params.. 169\n",
      "2021-11-19 22:27:54.192460 recording loss.. 169\n",
      "2021-11-19 22:27:54.193764 start 170\n",
      "2021-11-19 22:27:54.194471 calculating gradient.. 170\n",
      "2021-11-19 22:28:56.623589 updating params.. 170\n",
      "2021-11-19 22:28:56.624567 recording loss.. 170\n",
      "train acc, test acc | 0.23095,0.2412\n",
      "2021-11-19 22:28:57.178674 start 171\n",
      "2021-11-19 22:28:57.179784 calculating gradient.. 171\n",
      "2021-11-19 22:29:59.730377 updating params.. 171\n",
      "2021-11-19 22:29:59.731309 recording loss.. 171\n",
      "2021-11-19 22:29:59.732633 start 172\n",
      "2021-11-19 22:29:59.733322 calculating gradient.. 172\n",
      "2021-11-19 22:31:01.865867 updating params.. 172\n",
      "2021-11-19 22:31:01.866774 recording loss.. 172\n",
      "2021-11-19 22:31:01.868016 start 173\n",
      "2021-11-19 22:31:01.868671 calculating gradient.. 173\n",
      "2021-11-19 22:32:04.253203 updating params.. 173\n",
      "2021-11-19 22:32:04.254275 recording loss.. 173\n",
      "2021-11-19 22:32:04.255557 start 174\n",
      "2021-11-19 22:32:04.256355 calculating gradient.. 174\n",
      "2021-11-19 22:33:06.545537 updating params.. 174\n",
      "2021-11-19 22:33:06.546518 recording loss.. 174\n",
      "2021-11-19 22:33:06.548229 start 175\n",
      "2021-11-19 22:33:06.549035 calculating gradient.. 175\n",
      "2021-11-19 22:34:09.090894 updating params.. 175\n",
      "2021-11-19 22:34:09.091986 recording loss.. 175\n",
      "2021-11-19 22:34:09.093815 start 176\n",
      "2021-11-19 22:34:09.094524 calculating gradient.. 176\n",
      "2021-11-19 22:35:11.777745 updating params.. 176\n",
      "2021-11-19 22:35:11.778647 recording loss.. 176\n",
      "2021-11-19 22:35:11.779935 start 177\n",
      "2021-11-19 22:35:11.780601 calculating gradient.. 177\n",
      "2021-11-19 22:36:14.173589 updating params.. 177\n",
      "2021-11-19 22:36:14.174498 recording loss.. 177\n",
      "2021-11-19 22:36:14.175591 start 178\n",
      "2021-11-19 22:36:14.176226 calculating gradient.. 178\n",
      "2021-11-19 22:37:16.315820 updating params.. 178\n",
      "2021-11-19 22:37:16.316837 recording loss.. 178\n",
      "2021-11-19 22:37:16.318450 start 179\n",
      "2021-11-19 22:37:16.319187 calculating gradient.. 179\n",
      "2021-11-19 22:38:18.786921 updating params.. 179\n",
      "2021-11-19 22:38:18.787959 recording loss.. 179\n",
      "2021-11-19 22:38:18.789284 start 180\n",
      "2021-11-19 22:38:18.789959 calculating gradient.. 180\n",
      "2021-11-19 22:39:20.902671 updating params.. 180\n",
      "2021-11-19 22:39:20.903612 recording loss.. 180\n",
      "train acc, test acc | 0.33973333333333333,0.3508\n",
      "2021-11-19 22:39:21.456162 start 181\n",
      "2021-11-19 22:39:21.457325 calculating gradient.. 181\n",
      "2021-11-19 22:40:24.861716 updating params.. 181\n",
      "2021-11-19 22:40:24.862751 recording loss.. 181\n",
      "2021-11-19 22:40:24.863896 start 182\n",
      "2021-11-19 22:40:24.864632 calculating gradient.. 182\n",
      "2021-11-19 22:41:27.336329 updating params.. 182\n",
      "2021-11-19 22:41:27.337479 recording loss.. 182\n",
      "2021-11-19 22:41:27.338587 start 183\n",
      "2021-11-19 22:41:27.339240 calculating gradient.. 183\n",
      "2021-11-19 22:42:29.253655 updating params.. 183\n",
      "2021-11-19 22:42:29.254607 recording loss.. 183\n",
      "2021-11-19 22:42:29.255923 start 184\n",
      "2021-11-19 22:42:29.256638 calculating gradient.. 184\n",
      "2021-11-19 22:43:31.746280 updating params.. 184\n",
      "2021-11-19 22:43:31.747190 recording loss.. 184\n",
      "2021-11-19 22:43:31.748384 start 185\n",
      "2021-11-19 22:43:31.749019 calculating gradient.. 185\n",
      "2021-11-19 22:44:34.018994 updating params.. 185\n",
      "2021-11-19 22:44:34.019920 recording loss.. 185\n",
      "2021-11-19 22:44:34.021209 start 186\n",
      "2021-11-19 22:44:34.021905 calculating gradient.. 186\n",
      "2021-11-19 22:45:36.628921 updating params.. 186\n",
      "2021-11-19 22:45:36.629869 recording loss.. 186\n",
      "2021-11-19 22:45:36.631401 start 187\n",
      "2021-11-19 22:45:36.632265 calculating gradient.. 187\n",
      "2021-11-19 22:46:39.061440 updating params.. 187\n",
      "2021-11-19 22:46:39.062410 recording loss.. 187\n",
      "2021-11-19 22:46:39.063722 start 188\n",
      "2021-11-19 22:46:39.064419 calculating gradient.. 188\n",
      "2021-11-19 22:47:41.129213 updating params.. 188\n",
      "2021-11-19 22:47:41.130137 recording loss.. 188\n",
      "2021-11-19 22:47:41.131353 start 189\n",
      "2021-11-19 22:47:41.132028 calculating gradient.. 189\n",
      "2021-11-19 22:48:43.425514 updating params.. 189\n",
      "2021-11-19 22:48:43.426449 recording loss.. 189\n",
      "2021-11-19 22:48:43.427722 start 190\n",
      "2021-11-19 22:48:43.428420 calculating gradient.. 190\n",
      "2021-11-19 22:49:46.141137 updating params.. 190\n",
      "2021-11-19 22:49:46.142148 recording loss.. 190\n",
      "train acc, test acc | 0.30665,0.3144\n",
      "2021-11-19 22:49:46.702240 start 191\n",
      "2021-11-19 22:49:46.703338 calculating gradient.. 191\n",
      "2021-11-19 22:50:49.108822 updating params.. 191\n",
      "2021-11-19 22:50:49.109969 recording loss.. 191\n",
      "2021-11-19 22:50:49.111474 start 192\n",
      "2021-11-19 22:50:49.112198 calculating gradient.. 192\n",
      "2021-11-19 22:51:51.422789 updating params.. 192\n",
      "2021-11-19 22:51:51.423746 recording loss.. 192\n",
      "2021-11-19 22:51:51.425039 start 193\n",
      "2021-11-19 22:51:51.425801 calculating gradient.. 193\n",
      "2021-11-19 22:52:54.019705 updating params.. 193\n",
      "2021-11-19 22:52:54.020687 recording loss.. 193\n",
      "2021-11-19 22:52:54.021918 start 194\n",
      "2021-11-19 22:52:54.022522 calculating gradient.. 194\n",
      "2021-11-19 22:53:56.391329 updating params.. 194\n",
      "2021-11-19 22:53:56.392359 recording loss.. 194\n",
      "2021-11-19 22:53:56.393761 start 195\n",
      "2021-11-19 22:53:56.394684 calculating gradient.. 195\n",
      "2021-11-19 22:54:58.826068 updating params.. 195\n",
      "2021-11-19 22:54:58.827078 recording loss.. 195\n",
      "2021-11-19 22:54:58.828476 start 196\n",
      "2021-11-19 22:54:58.829444 calculating gradient.. 196\n",
      "2021-11-19 22:56:01.487716 updating params.. 196\n",
      "2021-11-19 22:56:01.488717 recording loss.. 196\n",
      "2021-11-19 22:56:01.490096 start 197\n",
      "2021-11-19 22:56:01.490840 calculating gradient.. 197\n",
      "2021-11-19 22:57:04.449052 updating params.. 197\n",
      "2021-11-19 22:57:04.450009 recording loss.. 197\n",
      "2021-11-19 22:57:04.451866 start 198\n",
      "2021-11-19 22:57:04.452754 calculating gradient.. 198\n",
      "2021-11-19 22:58:06.998331 updating params.. 198\n",
      "2021-11-19 22:58:06.999247 recording loss.. 198\n",
      "2021-11-19 22:58:07.000619 start 199\n",
      "2021-11-19 22:58:07.001402 calculating gradient.. 199\n",
      "2021-11-19 22:59:09.537293 updating params.. 199\n",
      "2021-11-19 22:59:09.538301 recording loss.. 199\n",
      "2021-11-19 22:59:09.539432 start 200\n",
      "2021-11-19 22:59:09.540135 calculating gradient.. 200\n",
      "2021-11-19 23:00:13.016743 updating params.. 200\n",
      "2021-11-19 23:00:13.017776 recording loss.. 200\n",
      "train acc, test acc | 0.31883333333333336,0.3238\n",
      "2021-11-19 23:00:13.832960 start 201\n",
      "2021-11-19 23:00:13.833808 calculating gradient.. 201\n",
      "2021-11-19 23:01:15.686317 updating params.. 201\n",
      "2021-11-19 23:01:15.687435 recording loss.. 201\n",
      "2021-11-19 23:01:15.688699 start 202\n",
      "2021-11-19 23:01:15.689376 calculating gradient.. 202\n",
      "2021-11-19 23:02:27.928300 updating params.. 202\n",
      "2021-11-19 23:02:27.929449 recording loss.. 202\n",
      "2021-11-19 23:02:27.931645 start 203\n",
      "2021-11-19 23:02:27.932627 calculating gradient.. 203\n",
      "2021-11-19 23:03:46.627055 updating params.. 203\n",
      "2021-11-19 23:03:46.628068 recording loss.. 203\n",
      "2021-11-19 23:03:46.629662 start 204\n",
      "2021-11-19 23:03:46.630461 calculating gradient.. 204\n",
      "2021-11-19 23:04:49.112734 updating params.. 204\n",
      "2021-11-19 23:04:49.113741 recording loss.. 204\n",
      "2021-11-19 23:04:49.114960 start 205\n",
      "2021-11-19 23:04:49.115616 calculating gradient.. 205\n",
      "2021-11-19 23:05:51.364792 updating params.. 205\n",
      "2021-11-19 23:05:51.365787 recording loss.. 205\n",
      "2021-11-19 23:05:51.367175 start 206\n",
      "2021-11-19 23:05:51.367919 calculating gradient.. 206\n",
      "2021-11-19 23:06:53.757372 updating params.. 206\n",
      "2021-11-19 23:06:53.758309 recording loss.. 206\n",
      "2021-11-19 23:06:53.759552 start 207\n",
      "2021-11-19 23:06:53.760216 calculating gradient.. 207\n",
      "2021-11-19 23:07:55.830039 updating params.. 207\n",
      "2021-11-19 23:07:55.830946 recording loss.. 207\n",
      "2021-11-19 23:07:55.832243 start 208\n",
      "2021-11-19 23:07:55.832899 calculating gradient.. 208\n",
      "2021-11-19 23:08:58.069054 updating params.. 208\n",
      "2021-11-19 23:08:58.070009 recording loss.. 208\n",
      "2021-11-19 23:08:58.071292 start 209\n",
      "2021-11-19 23:08:58.071992 calculating gradient.. 209\n",
      "2021-11-19 23:10:00.849968 updating params.. 209\n",
      "2021-11-19 23:10:00.850894 recording loss.. 209\n",
      "2021-11-19 23:10:00.852541 start 210\n",
      "2021-11-19 23:10:00.853480 calculating gradient.. 210\n",
      "2021-11-19 23:11:02.848764 updating params.. 210\n",
      "2021-11-19 23:11:02.849716 recording loss.. 210\n",
      "train acc, test acc | 0.24103333333333332,0.2448\n",
      "2021-11-19 23:11:03.419888 start 211\n",
      "2021-11-19 23:11:03.421049 calculating gradient.. 211\n",
      "2021-11-19 23:12:05.783177 updating params.. 211\n",
      "2021-11-19 23:12:05.784187 recording loss.. 211\n",
      "2021-11-19 23:12:05.785306 start 212\n",
      "2021-11-19 23:12:05.785975 calculating gradient.. 212\n",
      "2021-11-19 23:13:08.116566 updating params.. 212\n",
      "2021-11-19 23:13:08.117518 recording loss.. 212\n",
      "2021-11-19 23:13:08.118796 start 213\n",
      "2021-11-19 23:13:08.119492 calculating gradient.. 213\n",
      "2021-11-19 23:14:10.578301 updating params.. 213\n",
      "2021-11-19 23:14:10.579347 recording loss.. 213\n",
      "2021-11-19 23:14:10.581133 start 214\n",
      "2021-11-19 23:14:10.582110 calculating gradient.. 214\n",
      "2021-11-19 23:15:13.516460 updating params.. 214\n",
      "2021-11-19 23:15:13.517413 recording loss.. 214\n",
      "2021-11-19 23:15:13.518612 start 215\n",
      "2021-11-19 23:15:13.519256 calculating gradient.. 215\n",
      "2021-11-19 23:16:16.046305 updating params.. 215\n",
      "2021-11-19 23:16:16.047223 recording loss.. 215\n",
      "2021-11-19 23:16:16.048433 start 216\n",
      "2021-11-19 23:16:16.049105 calculating gradient.. 216\n",
      "2021-11-19 23:17:18.279792 updating params.. 216\n",
      "2021-11-19 23:17:18.280726 recording loss.. 216\n",
      "2021-11-19 23:17:18.282046 start 217\n",
      "2021-11-19 23:17:18.282832 calculating gradient.. 217\n",
      "2021-11-19 23:18:20.523102 updating params.. 217\n",
      "2021-11-19 23:18:20.524037 recording loss.. 217\n",
      "2021-11-19 23:18:20.525330 start 218\n",
      "2021-11-19 23:18:20.525997 calculating gradient.. 218\n",
      "2021-11-19 23:19:22.944320 updating params.. 218\n",
      "2021-11-19 23:19:22.945462 recording loss.. 218\n",
      "2021-11-19 23:19:22.946720 start 219\n",
      "2021-11-19 23:19:22.947395 calculating gradient.. 219\n",
      "2021-11-19 23:20:26.040015 updating params.. 219\n",
      "2021-11-19 23:20:26.040978 recording loss.. 219\n",
      "2021-11-19 23:20:26.042282 start 220\n",
      "2021-11-19 23:20:26.043005 calculating gradient.. 220\n",
      "2021-11-19 23:21:28.381612 updating params.. 220\n",
      "2021-11-19 23:21:28.382562 recording loss.. 220\n",
      "train acc, test acc | 0.3343333333333333,0.3397\n",
      "2021-11-19 23:21:28.941211 start 221\n",
      "2021-11-19 23:21:28.942243 calculating gradient.. 221\n",
      "2021-11-19 23:22:31.472925 updating params.. 221\n",
      "2021-11-19 23:22:31.473877 recording loss.. 221\n",
      "2021-11-19 23:22:31.475158 start 222\n",
      "2021-11-19 23:22:31.475903 calculating gradient.. 222\n",
      "2021-11-19 23:23:33.891297 updating params.. 222\n",
      "2021-11-19 23:23:33.892249 recording loss.. 222\n",
      "2021-11-19 23:23:33.893562 start 223\n",
      "2021-11-19 23:23:33.894263 calculating gradient.. 223\n",
      "2021-11-19 23:24:36.367560 updating params.. 223\n",
      "2021-11-19 23:24:36.368540 recording loss.. 223\n",
      "2021-11-19 23:24:36.370788 start 224\n",
      "2021-11-19 23:24:36.371640 calculating gradient.. 224\n",
      "2021-11-19 23:25:38.579473 updating params.. 224\n",
      "2021-11-19 23:25:38.580403 recording loss.. 224\n",
      "2021-11-19 23:25:38.581648 start 225\n",
      "2021-11-19 23:25:38.582318 calculating gradient.. 225\n",
      "2021-11-19 23:26:41.035689 updating params.. 225\n",
      "2021-11-19 23:26:41.036637 recording loss.. 225\n",
      "2021-11-19 23:26:41.037938 start 226\n",
      "2021-11-19 23:26:41.038646 calculating gradient.. 226\n",
      "2021-11-19 23:27:43.380243 updating params.. 226\n",
      "2021-11-19 23:27:43.381170 recording loss.. 226\n",
      "2021-11-19 23:27:43.382356 start 227\n",
      "2021-11-19 23:27:43.383065 calculating gradient.. 227\n",
      "2021-11-19 23:28:45.848930 updating params.. 227\n",
      "2021-11-19 23:28:45.850001 recording loss.. 227\n",
      "2021-11-19 23:28:45.851786 start 228\n",
      "2021-11-19 23:28:45.852229 calculating gradient.. 228\n",
      "2021-11-19 23:29:48.422112 updating params.. 228\n",
      "2021-11-19 23:29:48.423057 recording loss.. 228\n",
      "2021-11-19 23:29:48.424721 start 229\n",
      "2021-11-19 23:29:48.425526 calculating gradient.. 229\n",
      "2021-11-19 23:30:50.770020 updating params.. 229\n",
      "2021-11-19 23:30:50.770934 recording loss.. 229\n",
      "2021-11-19 23:30:50.772204 start 230\n",
      "2021-11-19 23:30:50.772990 calculating gradient.. 230\n",
      "2021-11-19 23:31:53.535595 updating params.. 230\n",
      "2021-11-19 23:31:53.536668 recording loss.. 230\n",
      "train acc, test acc | 0.4003833333333333,0.4032\n",
      "2021-11-19 23:31:54.097780 start 231\n",
      "2021-11-19 23:31:54.098590 calculating gradient.. 231\n",
      "2021-11-19 23:32:56.429742 updating params.. 231\n",
      "2021-11-19 23:32:56.430682 recording loss.. 231\n",
      "2021-11-19 23:32:56.431986 start 232\n",
      "2021-11-19 23:32:56.432695 calculating gradient.. 232\n",
      "2021-11-19 23:33:58.709068 updating params.. 232\n",
      "2021-11-19 23:33:58.710019 recording loss.. 232\n",
      "2021-11-19 23:33:58.711230 start 233\n",
      "2021-11-19 23:33:58.711875 calculating gradient.. 233\n",
      "2021-11-19 23:35:01.409739 updating params.. 233\n",
      "2021-11-19 23:35:01.410854 recording loss.. 233\n",
      "2021-11-19 23:35:01.412142 start 234\n",
      "2021-11-19 23:35:01.412523 calculating gradient.. 234\n",
      "2021-11-19 23:36:03.729583 updating params.. 234\n",
      "2021-11-19 23:36:03.730627 recording loss.. 234\n",
      "2021-11-19 23:36:03.732040 start 235\n",
      "2021-11-19 23:36:03.732937 calculating gradient.. 235\n",
      "2021-11-19 23:37:06.361527 updating params.. 235\n",
      "2021-11-19 23:37:06.362471 recording loss.. 235\n",
      "2021-11-19 23:37:06.363571 start 236\n",
      "2021-11-19 23:37:06.364204 calculating gradient.. 236\n",
      "2021-11-19 23:38:08.718817 updating params.. 236\n",
      "2021-11-19 23:38:08.719755 recording loss.. 236\n",
      "2021-11-19 23:38:08.721091 start 237\n",
      "2021-11-19 23:38:08.722002 calculating gradient.. 237\n",
      "2021-11-19 23:39:11.434871 updating params.. 237\n",
      "2021-11-19 23:39:11.436044 recording loss.. 237\n",
      "2021-11-19 23:39:11.437881 start 238\n",
      "2021-11-19 23:39:11.438831 calculating gradient.. 238\n",
      "2021-11-19 23:40:14.893903 updating params.. 238\n",
      "2021-11-19 23:40:14.894791 recording loss.. 238\n",
      "2021-11-19 23:40:14.896180 start 239\n",
      "2021-11-19 23:40:14.896846 calculating gradient.. 239\n",
      "2021-11-19 23:41:17.524687 updating params.. 239\n",
      "2021-11-19 23:41:17.525654 recording loss.. 239\n",
      "2021-11-19 23:41:17.526962 start 240\n",
      "2021-11-19 23:41:17.527673 calculating gradient.. 240\n",
      "2021-11-19 23:42:20.030137 updating params.. 240\n",
      "2021-11-19 23:42:20.031021 recording loss.. 240\n",
      "train acc, test acc | 0.39908333333333335,0.4051\n",
      "2021-11-19 23:42:20.673966 start 241\n",
      "2021-11-19 23:42:20.675070 calculating gradient.. 241\n",
      "2021-11-19 23:43:22.987568 updating params.. 241\n",
      "2021-11-19 23:43:22.988534 recording loss.. 241\n",
      "2021-11-19 23:43:22.989834 start 242\n",
      "2021-11-19 23:43:22.990564 calculating gradient.. 242\n",
      "2021-11-19 23:44:25.794314 updating params.. 242\n",
      "2021-11-19 23:44:25.795215 recording loss.. 242\n",
      "2021-11-19 23:44:25.796424 start 243\n",
      "2021-11-19 23:44:25.797070 calculating gradient.. 243\n",
      "2021-11-19 23:45:28.326459 updating params.. 243\n",
      "2021-11-19 23:45:28.327437 recording loss.. 243\n",
      "2021-11-19 23:45:28.328660 start 244\n",
      "2021-11-19 23:45:28.329324 calculating gradient.. 244\n",
      "2021-11-19 23:46:30.941016 updating params.. 244\n",
      "2021-11-19 23:46:30.942198 recording loss.. 244\n",
      "2021-11-19 23:46:30.944747 start 245\n",
      "2021-11-19 23:46:30.945596 calculating gradient.. 245\n",
      "2021-11-19 23:47:33.124490 updating params.. 245\n",
      "2021-11-19 23:47:33.125461 recording loss.. 245\n",
      "2021-11-19 23:47:33.126746 start 246\n",
      "2021-11-19 23:47:33.127519 calculating gradient.. 246\n",
      "2021-11-19 23:48:35.571834 updating params.. 246\n",
      "2021-11-19 23:48:35.572789 recording loss.. 246\n",
      "2021-11-19 23:48:35.574088 start 247\n",
      "2021-11-19 23:48:35.574733 calculating gradient.. 247\n",
      "2021-11-19 23:49:38.618379 updating params.. 247\n",
      "2021-11-19 23:49:38.619406 recording loss.. 247\n",
      "2021-11-19 23:49:38.620616 start 248\n",
      "2021-11-19 23:49:38.621281 calculating gradient.. 248\n",
      "2021-11-19 23:50:41.440075 updating params.. 248\n",
      "2021-11-19 23:50:41.441129 recording loss.. 248\n",
      "2021-11-19 23:50:41.442668 start 249\n",
      "2021-11-19 23:50:41.443398 calculating gradient.. 249\n",
      "2021-11-19 23:51:43.868768 updating params.. 249\n",
      "2021-11-19 23:51:43.869746 recording loss.. 249\n",
      "2021-11-19 23:51:43.871033 start 250\n",
      "2021-11-19 23:51:43.871821 calculating gradient.. 250\n",
      "2021-11-19 23:52:46.452909 updating params.. 250\n",
      "2021-11-19 23:52:46.453915 recording loss.. 250\n",
      "train acc, test acc | 0.42211666666666664,0.4191\n",
      "2021-11-19 23:52:47.012076 start 251\n",
      "2021-11-19 23:52:47.012887 calculating gradient.. 251\n",
      "2021-11-19 23:53:49.776495 updating params.. 251\n",
      "2021-11-19 23:53:49.777460 recording loss.. 251\n",
      "2021-11-19 23:53:49.778751 start 252\n",
      "2021-11-19 23:53:49.779451 calculating gradient.. 252\n",
      "2021-11-19 23:54:54.929093 updating params.. 252\n",
      "2021-11-19 23:54:54.930007 recording loss.. 252\n",
      "2021-11-19 23:54:54.931722 start 253\n",
      "2021-11-19 23:54:54.932629 calculating gradient.. 253\n",
      "2021-11-19 23:55:57.340660 updating params.. 253\n",
      "2021-11-19 23:55:57.341609 recording loss.. 253\n",
      "2021-11-19 23:55:57.342896 start 254\n",
      "2021-11-19 23:55:57.343612 calculating gradient.. 254\n",
      "2021-11-19 23:57:00.414553 updating params.. 254\n",
      "2021-11-19 23:57:00.415552 recording loss.. 254\n",
      "2021-11-19 23:57:00.416777 start 255\n",
      "2021-11-19 23:57:00.417529 calculating gradient.. 255\n",
      "2021-11-19 23:58:02.898639 updating params.. 255\n",
      "2021-11-19 23:58:02.899421 recording loss.. 255\n",
      "2021-11-19 23:58:02.900822 start 256\n",
      "2021-11-19 23:58:02.901489 calculating gradient.. 256\n",
      "2021-11-19 23:59:06.222813 updating params.. 256\n",
      "2021-11-19 23:59:06.223751 recording loss.. 256\n",
      "2021-11-19 23:59:06.225027 start 257\n",
      "2021-11-19 23:59:06.225761 calculating gradient.. 257\n",
      "2021-11-20 00:00:09.178097 updating params.. 257\n",
      "2021-11-20 00:00:09.179038 recording loss.. 257\n",
      "2021-11-20 00:00:09.180387 start 258\n",
      "2021-11-20 00:00:09.181250 calculating gradient.. 258\n",
      "2021-11-20 00:01:11.999469 updating params.. 258\n",
      "2021-11-20 00:01:12.000463 recording loss.. 258\n",
      "2021-11-20 00:01:12.001777 start 259\n",
      "2021-11-20 00:01:12.002480 calculating gradient.. 259\n",
      "2021-11-20 00:02:25.335701 updating params.. 259\n",
      "2021-11-20 00:02:25.336902 recording loss.. 259\n",
      "2021-11-20 00:02:25.339191 start 260\n",
      "2021-11-20 00:02:25.340271 calculating gradient.. 260\n",
      "2021-11-20 00:03:45.551918 updating params.. 260\n",
      "2021-11-20 00:03:45.552875 recording loss.. 260\n",
      "train acc, test acc | 0.5129166666666667,0.5211\n",
      "2021-11-20 00:03:46.258483 start 261\n",
      "2021-11-20 00:03:46.259595 calculating gradient.. 261\n",
      "2021-11-20 00:04:49.718371 updating params.. 261\n",
      "2021-11-20 00:04:49.719316 recording loss.. 261\n",
      "2021-11-20 00:04:49.720605 start 262\n",
      "2021-11-20 00:04:49.721324 calculating gradient.. 262\n",
      "2021-11-20 00:05:51.918585 updating params.. 262\n",
      "2021-11-20 00:05:51.919525 recording loss.. 262\n",
      "2021-11-20 00:05:51.920791 start 263\n",
      "2021-11-20 00:05:51.921492 calculating gradient.. 263\n",
      "2021-11-20 00:06:54.353037 updating params.. 263\n",
      "2021-11-20 00:06:54.353985 recording loss.. 263\n",
      "2021-11-20 00:06:54.355267 start 264\n",
      "2021-11-20 00:06:54.355967 calculating gradient.. 264\n",
      "2021-11-20 00:07:56.774587 updating params.. 264\n",
      "2021-11-20 00:07:56.775538 recording loss.. 264\n",
      "2021-11-20 00:07:56.776733 start 265\n",
      "2021-11-20 00:07:56.777408 calculating gradient.. 265\n",
      "2021-11-20 00:08:59.241529 updating params.. 265\n",
      "2021-11-20 00:08:59.242471 recording loss.. 265\n",
      "2021-11-20 00:08:59.243754 start 266\n",
      "2021-11-20 00:08:59.244491 calculating gradient.. 266\n",
      "2021-11-20 00:10:02.336423 updating params.. 266\n",
      "2021-11-20 00:10:02.337389 recording loss.. 266\n",
      "2021-11-20 00:10:02.338797 start 267\n",
      "2021-11-20 00:10:02.339510 calculating gradient.. 267\n",
      "2021-11-20 00:11:04.553357 updating params.. 267\n",
      "2021-11-20 00:11:04.554267 recording loss.. 267\n",
      "2021-11-20 00:11:04.555476 start 268\n",
      "2021-11-20 00:11:04.556197 calculating gradient.. 268\n",
      "2021-11-20 00:12:06.883097 updating params.. 268\n",
      "2021-11-20 00:12:06.884038 recording loss.. 268\n",
      "2021-11-20 00:12:06.885348 start 269\n",
      "2021-11-20 00:12:06.886062 calculating gradient.. 269\n",
      "2021-11-20 00:13:09.455300 updating params.. 269\n",
      "2021-11-20 00:13:09.456298 recording loss.. 269\n",
      "2021-11-20 00:13:09.457974 start 270\n",
      "2021-11-20 00:13:09.458787 calculating gradient.. 270\n",
      "2021-11-20 00:14:11.859263 updating params.. 270\n",
      "2021-11-20 00:14:11.860233 recording loss.. 270\n",
      "train acc, test acc | 0.47773333333333334,0.4862\n",
      "2021-11-20 00:14:12.495288 start 271\n",
      "2021-11-20 00:14:12.496095 calculating gradient.. 271\n",
      "2021-11-20 00:15:15.790817 updating params.. 271\n",
      "2021-11-20 00:15:15.791707 recording loss.. 271\n",
      "2021-11-20 00:15:15.792914 start 272\n",
      "2021-11-20 00:15:15.793589 calculating gradient.. 272\n",
      "2021-11-20 00:16:17.860390 updating params.. 272\n",
      "2021-11-20 00:16:17.861327 recording loss.. 272\n",
      "2021-11-20 00:16:17.862673 start 273\n",
      "2021-11-20 00:16:17.863459 calculating gradient.. 273\n",
      "2021-11-20 00:17:20.819058 updating params.. 273\n",
      "2021-11-20 00:17:20.820032 recording loss.. 273\n",
      "2021-11-20 00:17:20.821408 start 274\n",
      "2021-11-20 00:17:20.822192 calculating gradient.. 274\n",
      "2021-11-20 00:18:23.362731 updating params.. 274\n",
      "2021-11-20 00:18:23.363848 recording loss.. 274\n",
      "2021-11-20 00:18:23.365502 start 275\n",
      "2021-11-20 00:18:23.365913 calculating gradient.. 275\n",
      "2021-11-20 00:19:26.019820 updating params.. 275\n",
      "2021-11-20 00:19:26.020779 recording loss.. 275\n",
      "2021-11-20 00:19:26.022359 start 276\n",
      "2021-11-20 00:19:26.023150 calculating gradient.. 276\n",
      "2021-11-20 00:20:28.596243 updating params.. 276\n",
      "2021-11-20 00:20:28.597165 recording loss.. 276\n",
      "2021-11-20 00:20:28.598578 start 277\n",
      "2021-11-20 00:20:28.599305 calculating gradient.. 277\n",
      "2021-11-20 00:21:31.523313 updating params.. 277\n",
      "2021-11-20 00:21:31.524759 recording loss.. 277\n",
      "2021-11-20 00:21:31.526995 start 278\n",
      "2021-11-20 00:21:31.527998 calculating gradient.. 278\n",
      "2021-11-20 00:22:34.015203 updating params.. 278\n",
      "2021-11-20 00:22:34.016165 recording loss.. 278\n",
      "2021-11-20 00:22:34.017425 start 279\n",
      "2021-11-20 00:22:34.018082 calculating gradient.. 279\n",
      "2021-11-20 00:23:36.544917 updating params.. 279\n",
      "2021-11-20 00:23:36.545933 recording loss.. 279\n",
      "2021-11-20 00:23:36.547217 start 280\n",
      "2021-11-20 00:23:36.547874 calculating gradient.. 280\n",
      "2021-11-20 00:24:39.703275 updating params.. 280\n",
      "2021-11-20 00:24:39.704212 recording loss.. 280\n",
      "train acc, test acc | 0.4889833333333333,0.4883\n",
      "2021-11-20 00:24:40.311595 start 281\n",
      "2021-11-20 00:24:40.312631 calculating gradient.. 281\n",
      "2021-11-20 00:25:43.154504 updating params.. 281\n",
      "2021-11-20 00:25:43.155456 recording loss.. 281\n",
      "2021-11-20 00:25:43.156822 start 282\n",
      "2021-11-20 00:25:43.157817 calculating gradient.. 282\n",
      "2021-11-20 00:26:45.696080 updating params.. 282\n",
      "2021-11-20 00:26:45.697004 recording loss.. 282\n",
      "2021-11-20 00:26:45.698230 start 283\n",
      "2021-11-20 00:26:45.698882 calculating gradient.. 283\n",
      "2021-11-20 00:27:48.040216 updating params.. 283\n",
      "2021-11-20 00:27:48.041172 recording loss.. 283\n",
      "2021-11-20 00:27:48.042357 start 284\n",
      "2021-11-20 00:27:48.043008 calculating gradient.. 284\n",
      "2021-11-20 00:28:50.467290 updating params.. 284\n",
      "2021-11-20 00:28:50.468225 recording loss.. 284\n",
      "2021-11-20 00:28:50.469521 start 285\n",
      "2021-11-20 00:28:50.470226 calculating gradient.. 285\n",
      "2021-11-20 00:29:53.156277 updating params.. 285\n",
      "2021-11-20 00:29:53.157293 recording loss.. 285\n",
      "2021-11-20 00:29:53.158372 start 286\n",
      "2021-11-20 00:29:53.159072 calculating gradient.. 286\n",
      "2021-11-20 00:30:55.452045 updating params.. 286\n",
      "2021-11-20 00:30:55.453082 recording loss.. 286\n",
      "2021-11-20 00:30:55.454430 start 287\n",
      "2021-11-20 00:30:55.455077 calculating gradient.. 287\n",
      "2021-11-20 00:31:57.964175 updating params.. 287\n",
      "2021-11-20 00:31:57.965251 recording loss.. 287\n",
      "2021-11-20 00:31:57.966901 start 288\n",
      "2021-11-20 00:31:57.967621 calculating gradient.. 288\n",
      "2021-11-20 00:33:00.189818 updating params.. 288\n",
      "2021-11-20 00:33:00.190756 recording loss.. 288\n",
      "2021-11-20 00:33:00.192044 start 289\n",
      "2021-11-20 00:33:00.192763 calculating gradient.. 289\n",
      "2021-11-20 00:34:02.596161 updating params.. 289\n",
      "2021-11-20 00:34:02.597110 recording loss.. 289\n",
      "2021-11-20 00:34:02.598426 start 290\n",
      "2021-11-20 00:34:02.599139 calculating gradient.. 290\n",
      "2021-11-20 00:35:06.488362 updating params.. 290\n",
      "2021-11-20 00:35:06.489521 recording loss.. 290\n",
      "train acc, test acc | 0.5147166666666667,0.5192\n",
      "2021-11-20 00:35:07.032657 start 291\n",
      "2021-11-20 00:35:07.033759 calculating gradient.. 291\n",
      "2021-11-20 00:36:09.096450 updating params.. 291\n",
      "2021-11-20 00:36:09.097393 recording loss.. 291\n",
      "2021-11-20 00:36:09.098936 start 292\n",
      "2021-11-20 00:36:09.099726 calculating gradient.. 292\n",
      "2021-11-20 00:37:11.408468 updating params.. 292\n",
      "2021-11-20 00:37:11.409416 recording loss.. 292\n",
      "2021-11-20 00:37:11.410700 start 293\n",
      "2021-11-20 00:37:11.411397 calculating gradient.. 293\n",
      "2021-11-20 00:38:13.781875 updating params.. 293\n",
      "2021-11-20 00:38:13.782903 recording loss.. 293\n",
      "2021-11-20 00:38:13.784170 start 294\n",
      "2021-11-20 00:38:13.784892 calculating gradient.. 294\n",
      "2021-11-20 00:39:16.181417 updating params.. 294\n",
      "2021-11-20 00:39:16.182378 recording loss.. 294\n",
      "2021-11-20 00:39:16.183721 start 295\n",
      "2021-11-20 00:39:16.184428 calculating gradient.. 295\n",
      "2021-11-20 00:40:19.173516 updating params.. 295\n",
      "2021-11-20 00:40:19.174475 recording loss.. 295\n",
      "2021-11-20 00:40:19.175743 start 296\n",
      "2021-11-20 00:40:19.176386 calculating gradient.. 296\n",
      "2021-11-20 00:41:21.344112 updating params.. 296\n",
      "2021-11-20 00:41:21.345471 recording loss.. 296\n",
      "2021-11-20 00:41:21.347685 start 297\n",
      "2021-11-20 00:41:21.348848 calculating gradient.. 297\n",
      "2021-11-20 00:42:23.747701 updating params.. 297\n",
      "2021-11-20 00:42:23.748608 recording loss.. 297\n",
      "2021-11-20 00:42:23.749922 start 298\n",
      "2021-11-20 00:42:23.750750 calculating gradient.. 298\n",
      "2021-11-20 00:43:26.541282 updating params.. 298\n",
      "2021-11-20 00:43:26.542225 recording loss.. 298\n",
      "2021-11-20 00:43:26.543503 start 299\n",
      "2021-11-20 00:43:26.544219 calculating gradient.. 299\n",
      "2021-11-20 00:44:29.300228 updating params.. 299\n",
      "2021-11-20 00:44:29.301307 recording loss.. 299\n",
      "2021-11-20 00:44:29.302720 start 300\n",
      "2021-11-20 00:44:29.303170 calculating gradient.. 300\n",
      "2021-11-20 00:45:32.177314 updating params.. 300\n",
      "2021-11-20 00:45:32.178206 recording loss.. 300\n",
      "train acc, test acc | 0.48733333333333334,0.4896\n",
      "2021-11-20 00:45:32.722060 start 301\n",
      "2021-11-20 00:45:32.722878 calculating gradient.. 301\n",
      "2021-11-20 00:46:34.788268 updating params.. 301\n",
      "2021-11-20 00:46:34.789349 recording loss.. 301\n",
      "2021-11-20 00:46:34.790754 start 302\n",
      "2021-11-20 00:46:34.791577 calculating gradient.. 302\n",
      "2021-11-20 00:47:37.105376 updating params.. 302\n",
      "2021-11-20 00:47:37.106307 recording loss.. 302\n",
      "2021-11-20 00:47:37.107589 start 303\n",
      "2021-11-20 00:47:37.108286 calculating gradient.. 303\n",
      "2021-11-20 00:48:39.539247 updating params.. 303\n",
      "2021-11-20 00:48:39.540178 recording loss.. 303\n",
      "2021-11-20 00:48:39.541425 start 304\n",
      "2021-11-20 00:48:39.542089 calculating gradient.. 304\n",
      "2021-11-20 00:49:42.117136 updating params.. 304\n",
      "2021-11-20 00:49:42.118098 recording loss.. 304\n",
      "2021-11-20 00:49:42.119323 start 305\n",
      "2021-11-20 00:49:42.120040 calculating gradient.. 305\n",
      "2021-11-20 00:50:44.927906 updating params.. 305\n",
      "2021-11-20 00:50:44.928936 recording loss.. 305\n",
      "2021-11-20 00:50:44.930032 start 306\n",
      "2021-11-20 00:50:44.930788 calculating gradient.. 306\n",
      "2021-11-20 00:51:47.470072 updating params.. 306\n",
      "2021-11-20 00:51:47.471006 recording loss.. 306\n",
      "2021-11-20 00:51:47.472241 start 307\n",
      "2021-11-20 00:51:47.473052 calculating gradient.. 307\n",
      "2021-11-20 00:52:49.696877 updating params.. 307\n",
      "2021-11-20 00:52:49.698040 recording loss.. 307\n",
      "2021-11-20 00:52:49.699368 start 308\n",
      "2021-11-20 00:52:49.700022 calculating gradient.. 308\n",
      "2021-11-20 00:53:51.933992 updating params.. 308\n",
      "2021-11-20 00:53:51.934945 recording loss.. 308\n",
      "2021-11-20 00:53:51.936241 start 309\n",
      "2021-11-20 00:53:51.936901 calculating gradient.. 309\n",
      "2021-11-20 00:54:55.229520 updating params.. 309\n",
      "2021-11-20 00:54:55.230438 recording loss.. 309\n",
      "2021-11-20 00:54:55.231685 start 310\n",
      "2021-11-20 00:54:55.232337 calculating gradient.. 310\n",
      "2021-11-20 00:55:57.689992 updating params.. 310\n",
      "2021-11-20 00:55:57.690956 recording loss.. 310\n",
      "train acc, test acc | 0.5390666666666667,0.5459\n",
      "2021-11-20 00:55:58.255180 start 311\n",
      "2021-11-20 00:55:58.256011 calculating gradient.. 311\n",
      "2021-11-20 00:57:01.117037 updating params.. 311\n",
      "2021-11-20 00:57:01.118102 recording loss.. 311\n",
      "2021-11-20 00:57:01.119956 start 312\n",
      "2021-11-20 00:57:01.120918 calculating gradient.. 312\n",
      "2021-11-20 00:58:03.378431 updating params.. 312\n",
      "2021-11-20 00:58:03.379421 recording loss.. 312\n",
      "2021-11-20 00:58:03.380832 start 313\n",
      "2021-11-20 00:58:03.381641 calculating gradient.. 313\n",
      "2021-11-20 00:59:05.837550 updating params.. 313\n",
      "2021-11-20 00:59:05.838471 recording loss.. 313\n",
      "2021-11-20 00:59:05.839763 start 314\n",
      "2021-11-20 00:59:05.840430 calculating gradient.. 314\n",
      "2021-11-20 01:00:08.414189 updating params.. 314\n",
      "2021-11-20 01:00:08.415137 recording loss.. 314\n",
      "2021-11-20 01:00:08.416457 start 315\n",
      "2021-11-20 01:00:08.417157 calculating gradient.. 315\n",
      "2021-11-20 01:01:10.814571 updating params.. 315\n",
      "2021-11-20 01:01:10.815511 recording loss.. 315\n",
      "2021-11-20 01:01:10.816727 start 316\n",
      "2021-11-20 01:01:10.817391 calculating gradient.. 316\n",
      "2021-11-20 01:02:20.152370 updating params.. 316\n",
      "2021-11-20 01:02:20.153636 recording loss.. 316\n",
      "2021-11-20 01:02:20.155892 start 317\n",
      "2021-11-20 01:02:20.156907 calculating gradient.. 317\n",
      "2021-11-20 01:03:41.898223 updating params.. 317\n",
      "2021-11-20 01:03:41.899156 recording loss.. 317\n",
      "2021-11-20 01:03:41.900671 start 318\n",
      "2021-11-20 01:03:41.901416 calculating gradient.. 318\n",
      "2021-11-20 01:04:44.794750 updating params.. 318\n",
      "2021-11-20 01:04:44.795694 recording loss.. 318\n",
      "2021-11-20 01:04:44.797082 start 319\n",
      "2021-11-20 01:04:44.797955 calculating gradient.. 319\n",
      "2021-11-20 01:05:47.461459 updating params.. 319\n",
      "2021-11-20 01:05:47.462383 recording loss.. 319\n",
      "2021-11-20 01:05:47.463593 start 320\n",
      "2021-11-20 01:05:47.464244 calculating gradient.. 320\n",
      "2021-11-20 01:06:49.879469 updating params.. 320\n",
      "2021-11-20 01:06:49.880473 recording loss.. 320\n",
      "train acc, test acc | 0.55775,0.57\n",
      "2021-11-20 01:06:50.473406 start 321\n",
      "2021-11-20 01:06:50.474198 calculating gradient.. 321\n",
      "2021-11-20 01:07:52.645999 updating params.. 321\n",
      "2021-11-20 01:07:52.646937 recording loss.. 321\n",
      "2021-11-20 01:07:52.648053 start 322\n",
      "2021-11-20 01:07:52.648693 calculating gradient.. 322\n",
      "2021-11-20 01:08:55.048663 updating params.. 322\n",
      "2021-11-20 01:08:55.049604 recording loss.. 322\n",
      "2021-11-20 01:08:55.050797 start 323\n",
      "2021-11-20 01:08:55.051442 calculating gradient.. 323\n",
      "2021-11-20 01:09:57.847167 updating params.. 323\n",
      "2021-11-20 01:09:57.848162 recording loss.. 323\n",
      "2021-11-20 01:09:57.849460 start 324\n",
      "2021-11-20 01:09:57.850161 calculating gradient.. 324\n",
      "2021-11-20 01:11:00.273702 updating params.. 324\n",
      "2021-11-20 01:11:00.274641 recording loss.. 324\n",
      "2021-11-20 01:11:00.275945 start 325\n",
      "2021-11-20 01:11:00.276599 calculating gradient.. 325\n",
      "2021-11-20 01:12:02.751690 updating params.. 325\n",
      "2021-11-20 01:12:02.752694 recording loss.. 325\n",
      "2021-11-20 01:12:02.753774 start 326\n",
      "2021-11-20 01:12:02.754427 calculating gradient.. 326\n",
      "2021-11-20 01:13:05.096915 updating params.. 326\n",
      "2021-11-20 01:13:05.097863 recording loss.. 326\n",
      "2021-11-20 01:13:05.099153 start 327\n",
      "2021-11-20 01:13:05.099850 calculating gradient.. 327\n",
      "2021-11-20 01:14:07.500809 updating params.. 327\n",
      "2021-11-20 01:14:07.501758 recording loss.. 327\n",
      "2021-11-20 01:14:07.503063 start 328\n",
      "2021-11-20 01:14:07.503790 calculating gradient.. 328\n",
      "2021-11-20 01:15:11.091224 updating params.. 328\n",
      "2021-11-20 01:15:11.092320 recording loss.. 328\n",
      "2021-11-20 01:15:11.094066 start 329\n",
      "2021-11-20 01:15:11.094924 calculating gradient.. 329\n",
      "2021-11-20 01:16:13.542393 updating params.. 329\n",
      "2021-11-20 01:16:13.543306 recording loss.. 329\n",
      "2021-11-20 01:16:13.544512 start 330\n",
      "2021-11-20 01:16:13.545187 calculating gradient.. 330\n",
      "2021-11-20 01:17:15.891950 updating params.. 330\n",
      "2021-11-20 01:17:15.892933 recording loss.. 330\n",
      "train acc, test acc | 0.5651166666666667,0.5714\n",
      "2021-11-20 01:17:16.475326 start 331\n",
      "2021-11-20 01:17:16.476130 calculating gradient.. 331\n",
      "2021-11-20 01:18:18.761050 updating params.. 331\n",
      "2021-11-20 01:18:18.762010 recording loss.. 331\n",
      "2021-11-20 01:18:18.763230 start 332\n",
      "2021-11-20 01:18:18.764068 calculating gradient.. 332\n",
      "2021-11-20 01:19:21.132921 updating params.. 332\n",
      "2021-11-20 01:19:21.133878 recording loss.. 332\n",
      "2021-11-20 01:19:21.135166 start 333\n",
      "2021-11-20 01:19:21.135933 calculating gradient.. 333\n",
      "2021-11-20 01:20:24.026137 updating params.. 333\n",
      "2021-11-20 01:20:24.027183 recording loss.. 333\n",
      "2021-11-20 01:20:24.028454 start 334\n",
      "2021-11-20 01:20:24.029121 calculating gradient.. 334\n",
      "2021-11-20 01:21:27.319384 updating params.. 334\n",
      "2021-11-20 01:21:27.320311 recording loss.. 334\n",
      "2021-11-20 01:21:27.321530 start 335\n",
      "2021-11-20 01:21:27.322184 calculating gradient.. 335\n",
      "2021-11-20 01:22:29.609489 updating params.. 335\n",
      "2021-11-20 01:22:29.610518 recording loss.. 335\n",
      "2021-11-20 01:22:29.611790 start 336\n",
      "2021-11-20 01:22:29.612502 calculating gradient.. 336\n",
      "2021-11-20 01:23:31.914178 updating params.. 336\n",
      "2021-11-20 01:23:31.915137 recording loss.. 336\n",
      "2021-11-20 01:23:31.916416 start 337\n",
      "2021-11-20 01:23:31.917133 calculating gradient.. 337\n",
      "2021-11-20 01:24:34.921742 updating params.. 337\n",
      "2021-11-20 01:24:34.922692 recording loss.. 337\n",
      "2021-11-20 01:24:34.923936 start 338\n",
      "2021-11-20 01:24:34.924662 calculating gradient.. 338\n",
      "2021-11-20 01:25:38.043884 updating params.. 338\n",
      "2021-11-20 01:25:38.044836 recording loss.. 338\n",
      "2021-11-20 01:25:38.046185 start 339\n",
      "2021-11-20 01:25:38.047074 calculating gradient.. 339\n",
      "2021-11-20 01:26:40.092988 updating params.. 339\n",
      "2021-11-20 01:26:40.093939 recording loss.. 339\n",
      "2021-11-20 01:26:40.095254 start 340\n",
      "2021-11-20 01:26:40.095960 calculating gradient.. 340\n",
      "2021-11-20 01:27:42.667088 updating params.. 340\n",
      "2021-11-20 01:27:42.668048 recording loss.. 340\n",
      "train acc, test acc | 0.5640166666666667,0.5672\n",
      "2021-11-20 01:27:43.262019 start 341\n",
      "2021-11-20 01:27:43.262538 calculating gradient.. 341\n",
      "2021-11-20 01:28:45.599868 updating params.. 341\n",
      "2021-11-20 01:28:45.600895 recording loss.. 341\n",
      "2021-11-20 01:28:45.602165 start 342\n",
      "2021-11-20 01:28:45.602858 calculating gradient.. 342\n",
      "2021-11-20 01:29:48.098183 updating params.. 342\n",
      "2021-11-20 01:29:48.099126 recording loss.. 342\n",
      "2021-11-20 01:29:48.100362 start 343\n",
      "2021-11-20 01:29:48.101002 calculating gradient.. 343\n",
      "2021-11-20 01:30:50.533338 updating params.. 343\n",
      "2021-11-20 01:30:50.534314 recording loss.. 343\n",
      "2021-11-20 01:30:50.535949 start 344\n",
      "2021-11-20 01:30:50.536751 calculating gradient.. 344\n",
      "2021-11-20 01:31:52.763006 updating params.. 344\n",
      "2021-11-20 01:31:52.763943 recording loss.. 344\n",
      "2021-11-20 01:31:52.765468 start 345\n",
      "2021-11-20 01:31:52.766399 calculating gradient.. 345\n",
      "2021-11-20 01:32:55.105022 updating params.. 345\n",
      "2021-11-20 01:32:55.105959 recording loss.. 345\n",
      "2021-11-20 01:32:55.107230 start 346\n",
      "2021-11-20 01:32:55.107907 calculating gradient.. 346\n",
      "2021-11-20 01:33:57.208071 updating params.. 346\n",
      "2021-11-20 01:33:57.209054 recording loss.. 346\n",
      "2021-11-20 01:33:57.210575 start 347\n",
      "2021-11-20 01:33:57.211373 calculating gradient.. 347\n",
      "2021-11-20 01:35:00.568202 updating params.. 347\n",
      "2021-11-20 01:35:00.569154 recording loss.. 347\n",
      "2021-11-20 01:35:00.570501 start 348\n",
      "2021-11-20 01:35:00.571233 calculating gradient.. 348\n",
      "2021-11-20 01:36:02.918910 updating params.. 348\n",
      "2021-11-20 01:36:02.919800 recording loss.. 348\n",
      "2021-11-20 01:36:02.921174 start 349\n",
      "2021-11-20 01:36:02.922012 calculating gradient.. 349\n",
      "2021-11-20 01:37:05.279342 updating params.. 349\n",
      "2021-11-20 01:37:05.280298 recording loss.. 349\n",
      "2021-11-20 01:37:05.281701 start 350\n",
      "2021-11-20 01:37:05.282432 calculating gradient.. 350\n",
      "2021-11-20 01:38:07.635942 updating params.. 350\n",
      "2021-11-20 01:38:07.636897 recording loss.. 350\n",
      "train acc, test acc | 0.6053833333333334,0.6119\n",
      "2021-11-20 01:38:08.215248 start 351\n",
      "2021-11-20 01:38:08.216170 calculating gradient.. 351\n",
      "2021-11-20 01:39:10.577571 updating params.. 351\n",
      "2021-11-20 01:39:10.578503 recording loss.. 351\n",
      "2021-11-20 01:39:10.579851 start 352\n",
      "2021-11-20 01:39:10.580619 calculating gradient.. 352\n",
      "2021-11-20 01:40:13.057723 updating params.. 352\n",
      "2021-11-20 01:40:13.058690 recording loss.. 352\n",
      "2021-11-20 01:40:13.059980 start 353\n",
      "2021-11-20 01:40:13.060682 calculating gradient.. 353\n",
      "2021-11-20 01:41:15.468326 updating params.. 353\n",
      "2021-11-20 01:41:15.469272 recording loss.. 353\n",
      "2021-11-20 01:41:15.470478 start 354\n",
      "2021-11-20 01:41:15.471116 calculating gradient.. 354\n",
      "2021-11-20 01:42:17.789510 updating params.. 354\n",
      "2021-11-20 01:42:17.790523 recording loss.. 354\n",
      "2021-11-20 01:42:17.791828 start 355\n",
      "2021-11-20 01:42:17.792482 calculating gradient.. 355\n",
      "2021-11-20 01:43:20.531534 updating params.. 355\n",
      "2021-11-20 01:43:20.532831 recording loss.. 355\n",
      "2021-11-20 01:43:20.534236 start 356\n",
      "2021-11-20 01:43:20.534953 calculating gradient.. 356\n",
      "2021-11-20 01:44:22.762988 updating params.. 356\n",
      "2021-11-20 01:44:22.764021 recording loss.. 356\n",
      "2021-11-20 01:44:22.765493 start 357\n",
      "2021-11-20 01:44:22.766265 calculating gradient.. 357\n",
      "2021-11-20 01:45:26.082773 updating params.. 357\n",
      "2021-11-20 01:45:26.083830 recording loss.. 357\n",
      "2021-11-20 01:45:26.085536 start 358\n",
      "2021-11-20 01:45:26.086484 calculating gradient.. 358\n",
      "2021-11-20 01:46:28.607998 updating params.. 358\n",
      "2021-11-20 01:46:28.609313 recording loss.. 358\n",
      "2021-11-20 01:46:28.610544 start 359\n",
      "2021-11-20 01:46:28.611199 calculating gradient.. 359\n",
      "2021-11-20 01:47:31.053471 updating params.. 359\n",
      "2021-11-20 01:47:31.054385 recording loss.. 359\n",
      "2021-11-20 01:47:31.055589 start 360\n",
      "2021-11-20 01:47:31.056234 calculating gradient.. 360\n",
      "2021-11-20 01:48:33.996691 updating params.. 360\n",
      "2021-11-20 01:48:33.997649 recording loss.. 360\n",
      "train acc, test acc | 0.6300666666666667,0.6398\n",
      "2021-11-20 01:48:34.568008 start 361\n",
      "2021-11-20 01:48:34.569043 calculating gradient.. 361\n",
      "2021-11-20 01:49:37.051983 updating params.. 361\n",
      "2021-11-20 01:49:37.052634 recording loss.. 361\n",
      "2021-11-20 01:49:37.054131 start 362\n",
      "2021-11-20 01:49:37.054778 calculating gradient.. 362\n",
      "2021-11-20 01:50:39.887094 updating params.. 362\n",
      "2021-11-20 01:50:39.888023 recording loss.. 362\n",
      "2021-11-20 01:50:39.889258 start 363\n",
      "2021-11-20 01:50:39.889908 calculating gradient.. 363\n",
      "2021-11-20 01:51:42.405351 updating params.. 363\n",
      "2021-11-20 01:51:42.406558 recording loss.. 363\n",
      "2021-11-20 01:51:42.408063 start 364\n",
      "2021-11-20 01:51:42.408739 calculating gradient.. 364\n",
      "2021-11-20 01:52:44.527468 updating params.. 364\n",
      "2021-11-20 01:52:44.528433 recording loss.. 364\n",
      "2021-11-20 01:52:44.529756 start 365\n",
      "2021-11-20 01:52:44.530480 calculating gradient.. 365\n",
      "2021-11-20 01:53:46.762374 updating params.. 365\n",
      "2021-11-20 01:53:46.762787 recording loss.. 365\n",
      "2021-11-20 01:53:46.765228 start 366\n",
      "2021-11-20 01:53:46.766025 calculating gradient.. 366\n",
      "2021-11-20 01:54:50.038443 updating params.. 366\n",
      "2021-11-20 01:54:50.039407 recording loss.. 366\n",
      "2021-11-20 01:54:50.040730 start 367\n",
      "2021-11-20 01:54:50.041475 calculating gradient.. 367\n",
      "2021-11-20 01:55:52.842560 updating params.. 367\n",
      "2021-11-20 01:55:52.843513 recording loss.. 367\n",
      "2021-11-20 01:55:52.844770 start 368\n",
      "2021-11-20 01:55:52.845510 calculating gradient.. 368\n",
      "2021-11-20 01:56:55.839338 updating params.. 368\n",
      "2021-11-20 01:56:55.840280 recording loss.. 368\n",
      "2021-11-20 01:56:55.841590 start 369\n",
      "2021-11-20 01:56:55.842292 calculating gradient.. 369\n",
      "2021-11-20 01:57:57.949491 updating params.. 369\n",
      "2021-11-20 01:57:57.950471 recording loss.. 369\n",
      "2021-11-20 01:57:57.952057 start 370\n",
      "2021-11-20 01:57:57.952838 calculating gradient.. 370\n",
      "2021-11-20 01:59:00.187747 updating params.. 370\n",
      "2021-11-20 01:59:00.188797 recording loss.. 370\n",
      "train acc, test acc | 0.5867166666666667,0.5891\n",
      "2021-11-20 01:59:00.758541 start 371\n",
      "2021-11-20 01:59:00.759306 calculating gradient.. 371\n",
      "2021-11-20 02:00:03.673104 updating params.. 371\n",
      "2021-11-20 02:00:03.674099 recording loss.. 371\n",
      "2021-11-20 02:00:03.675415 start 372\n",
      "2021-11-20 02:00:03.676122 calculating gradient.. 372\n",
      "2021-11-20 02:01:06.457762 updating params.. 372\n",
      "2021-11-20 02:01:06.458715 recording loss.. 372\n",
      "2021-11-20 02:01:06.459908 start 373\n",
      "2021-11-20 02:01:06.460599 calculating gradient.. 373\n",
      "2021-11-20 02:02:13.164907 updating params.. 373\n",
      "2021-11-20 02:02:13.166086 recording loss.. 373\n",
      "2021-11-20 02:02:13.167726 start 374\n",
      "2021-11-20 02:02:13.168448 calculating gradient.. 374\n",
      "2021-11-20 02:03:37.275169 updating params.. 374\n",
      "2021-11-20 02:03:37.276159 recording loss.. 374\n",
      "2021-11-20 02:03:37.277791 start 375\n",
      "2021-11-20 02:03:37.278635 calculating gradient.. 375\n",
      "2021-11-20 02:04:39.946309 updating params.. 375\n",
      "2021-11-20 02:04:39.947274 recording loss.. 375\n",
      "2021-11-20 02:04:39.948643 start 376\n",
      "2021-11-20 02:04:39.949381 calculating gradient.. 376\n",
      "2021-11-20 02:05:42.527671 updating params.. 376\n",
      "2021-11-20 02:05:42.528586 recording loss.. 376\n",
      "2021-11-20 02:05:42.529813 start 377\n",
      "2021-11-20 02:05:42.530468 calculating gradient.. 377\n",
      "2021-11-20 02:06:45.577759 updating params.. 377\n",
      "2021-11-20 02:06:45.578760 recording loss.. 377\n",
      "2021-11-20 02:06:45.579819 start 378\n",
      "2021-11-20 02:06:45.580507 calculating gradient.. 378\n",
      "2021-11-20 02:07:47.678765 updating params.. 378\n",
      "2021-11-20 02:07:47.679743 recording loss.. 378\n",
      "2021-11-20 02:07:47.681450 start 379\n",
      "2021-11-20 02:07:47.682293 calculating gradient.. 379\n",
      "2021-11-20 02:08:49.876864 updating params.. 379\n",
      "2021-11-20 02:08:49.877836 recording loss.. 379\n",
      "2021-11-20 02:08:49.878951 start 380\n",
      "2021-11-20 02:08:49.879584 calculating gradient.. 380\n",
      "2021-11-20 02:09:52.314094 updating params.. 380\n",
      "2021-11-20 02:09:52.315077 recording loss.. 380\n",
      "train acc, test acc | 0.6218666666666667,0.6275\n",
      "2021-11-20 02:09:52.915442 start 381\n",
      "2021-11-20 02:09:52.916210 calculating gradient.. 381\n",
      "2021-11-20 02:10:55.338436 updating params.. 381\n",
      "2021-11-20 02:10:55.339414 recording loss.. 381\n",
      "2021-11-20 02:10:55.340659 start 382\n",
      "2021-11-20 02:10:55.341324 calculating gradient.. 382\n",
      "2021-11-20 02:11:57.995597 updating params.. 382\n",
      "2021-11-20 02:11:57.996527 recording loss.. 382\n",
      "2021-11-20 02:11:57.997850 start 383\n",
      "2021-11-20 02:11:57.998556 calculating gradient.. 383\n",
      "2021-11-20 02:13:00.071790 updating params.. 383\n",
      "2021-11-20 02:13:00.072727 recording loss.. 383\n",
      "2021-11-20 02:13:00.074034 start 384\n",
      "2021-11-20 02:13:00.074735 calculating gradient.. 384\n",
      "2021-11-20 02:14:02.271515 updating params.. 384\n",
      "2021-11-20 02:14:02.272445 recording loss.. 384\n",
      "2021-11-20 02:14:02.274378 start 385\n",
      "2021-11-20 02:14:02.275110 calculating gradient.. 385\n",
      "2021-11-20 02:15:07.476792 updating params.. 385\n",
      "2021-11-20 02:15:07.477272 recording loss.. 385\n",
      "2021-11-20 02:15:07.479006 start 386\n",
      "2021-11-20 02:15:07.479418 calculating gradient.. 386\n",
      "2021-11-20 02:16:17.963861 updating params.. 386\n",
      "2021-11-20 02:16:17.964804 recording loss.. 386\n",
      "2021-11-20 02:16:17.966582 start 387\n",
      "2021-11-20 02:16:17.967418 calculating gradient.. 387\n",
      "2021-11-20 02:17:20.777480 updating params.. 387\n",
      "2021-11-20 02:17:20.778428 recording loss.. 387\n",
      "2021-11-20 02:17:20.779791 start 388\n",
      "2021-11-20 02:17:20.780500 calculating gradient.. 388\n",
      "2021-11-20 02:18:23.046981 updating params.. 388\n",
      "2021-11-20 02:18:23.048083 recording loss.. 388\n",
      "2021-11-20 02:18:23.050126 start 389\n",
      "2021-11-20 02:18:23.050972 calculating gradient.. 389\n",
      "2021-11-20 02:19:25.468629 updating params.. 389\n",
      "2021-11-20 02:19:25.469948 recording loss.. 389\n",
      "2021-11-20 02:19:25.472217 start 390\n",
      "2021-11-20 02:19:25.475573 calculating gradient.. 390\n",
      "2021-11-20 02:20:28.407240 updating params.. 390\n",
      "2021-11-20 02:20:28.408178 recording loss.. 390\n",
      "train acc, test acc | 0.6588333333333334,0.6656\n",
      "2021-11-20 02:20:29.281724 start 391\n",
      "2021-11-20 02:20:29.282824 calculating gradient.. 391\n",
      "2021-11-20 02:21:31.936715 updating params.. 391\n",
      "2021-11-20 02:21:31.937688 recording loss.. 391\n",
      "2021-11-20 02:21:31.938789 start 392\n",
      "2021-11-20 02:21:31.939632 calculating gradient.. 392\n",
      "2021-11-20 02:22:34.223466 updating params.. 392\n",
      "2021-11-20 02:22:34.224374 recording loss.. 392\n",
      "2021-11-20 02:22:34.225664 start 393\n",
      "2021-11-20 02:22:34.226331 calculating gradient.. 393\n",
      "2021-11-20 02:23:36.488836 updating params.. 393\n",
      "2021-11-20 02:23:36.489797 recording loss.. 393\n",
      "2021-11-20 02:23:36.491215 start 394\n",
      "2021-11-20 02:23:36.492022 calculating gradient.. 394\n",
      "2021-11-20 02:24:39.210133 updating params.. 394\n",
      "2021-11-20 02:24:39.211076 recording loss.. 394\n",
      "2021-11-20 02:24:39.212353 start 395\n",
      "2021-11-20 02:24:39.213045 calculating gradient.. 395\n",
      "2021-11-20 02:25:42.231237 updating params.. 395\n",
      "2021-11-20 02:25:42.232178 recording loss.. 395\n",
      "2021-11-20 02:25:42.233482 start 396\n",
      "2021-11-20 02:25:42.234151 calculating gradient.. 396\n",
      "2021-11-20 02:26:44.296287 updating params.. 396\n",
      "2021-11-20 02:26:44.297321 recording loss.. 396\n",
      "2021-11-20 02:26:44.298529 start 397\n",
      "2021-11-20 02:26:44.299202 calculating gradient.. 397\n",
      "2021-11-20 02:27:46.663580 updating params.. 397\n",
      "2021-11-20 02:27:46.664520 recording loss.. 397\n",
      "2021-11-20 02:27:46.665831 start 398\n",
      "2021-11-20 02:27:46.666538 calculating gradient.. 398\n",
      "2021-11-20 02:28:49.011485 updating params.. 398\n",
      "2021-11-20 02:28:49.012557 recording loss.. 398\n",
      "2021-11-20 02:28:49.013923 start 399\n",
      "2021-11-20 02:28:49.014633 calculating gradient.. 399\n",
      "2021-11-20 02:29:51.702110 updating params.. 399\n",
      "2021-11-20 02:29:51.703058 recording loss.. 399\n",
      "2021-11-20 02:29:51.704300 start 400\n",
      "2021-11-20 02:29:51.704957 calculating gradient.. 400\n",
      "2021-11-20 02:30:54.026722 updating params.. 400\n",
      "2021-11-20 02:30:54.027709 recording loss.. 400\n",
      "train acc, test acc | 0.6213833333333333,0.6276\n",
      "2021-11-20 02:30:54.735317 start 401\n",
      "2021-11-20 02:30:54.736358 calculating gradient.. 401\n",
      "2021-11-20 02:31:57.415344 updating params.. 401\n",
      "2021-11-20 02:31:57.416359 recording loss.. 401\n",
      "2021-11-20 02:31:57.417590 start 402\n",
      "2021-11-20 02:31:57.418245 calculating gradient.. 402\n",
      "2021-11-20 02:32:59.501009 updating params.. 402\n",
      "2021-11-20 02:32:59.502283 recording loss.. 402\n",
      "2021-11-20 02:32:59.503582 start 403\n",
      "2021-11-20 02:32:59.504242 calculating gradient.. 403\n",
      "2021-11-20 02:34:01.750329 updating params.. 403\n",
      "2021-11-20 02:34:01.751278 recording loss.. 403\n",
      "2021-11-20 02:34:01.752640 start 404\n",
      "2021-11-20 02:34:01.753378 calculating gradient.. 404\n",
      "2021-11-20 02:35:04.951279 updating params.. 404\n",
      "2021-11-20 02:35:04.952185 recording loss.. 404\n",
      "2021-11-20 02:35:04.953409 start 405\n",
      "2021-11-20 02:35:04.954062 calculating gradient.. 405\n",
      "2021-11-20 02:36:07.540576 updating params.. 405\n",
      "2021-11-20 02:36:07.541508 recording loss.. 405\n",
      "2021-11-20 02:36:07.542716 start 406\n",
      "2021-11-20 02:36:07.543363 calculating gradient.. 406\n",
      "2021-11-20 02:37:10.021269 updating params.. 406\n",
      "2021-11-20 02:37:10.022256 recording loss.. 406\n",
      "2021-11-20 02:37:10.023498 start 407\n",
      "2021-11-20 02:37:10.024164 calculating gradient.. 407\n",
      "2021-11-20 02:38:12.241114 updating params.. 407\n",
      "2021-11-20 02:38:12.242080 recording loss.. 407\n",
      "2021-11-20 02:38:12.243297 start 408\n",
      "2021-11-20 02:38:12.243941 calculating gradient.. 408\n",
      "2021-11-20 02:39:14.302790 updating params.. 408\n",
      "2021-11-20 02:39:14.303877 recording loss.. 408\n",
      "2021-11-20 02:39:14.305004 start 409\n",
      "2021-11-20 02:39:14.305706 calculating gradient.. 409\n",
      "2021-11-20 02:40:19.760776 updating params.. 409\n",
      "2021-11-20 02:40:19.761735 recording loss.. 409\n",
      "2021-11-20 02:40:19.763029 start 410\n",
      "2021-11-20 02:40:19.763742 calculating gradient.. 410\n",
      "2021-11-20 02:41:21.902542 updating params.. 410\n",
      "2021-11-20 02:41:21.903627 recording loss.. 410\n",
      "train acc, test acc | 0.65045,0.6562\n",
      "2021-11-20 02:41:22.541707 start 411\n",
      "2021-11-20 02:41:22.542738 calculating gradient.. 411\n",
      "2021-11-20 02:42:25.154888 updating params.. 411\n",
      "2021-11-20 02:42:25.155845 recording loss.. 411\n",
      "2021-11-20 02:42:25.157209 start 412\n",
      "2021-11-20 02:42:25.157920 calculating gradient.. 412\n",
      "2021-11-20 02:43:27.965577 updating params.. 412\n",
      "2021-11-20 02:43:27.966560 recording loss.. 412\n",
      "2021-11-20 02:43:27.968209 start 413\n",
      "2021-11-20 02:43:27.969075 calculating gradient.. 413\n",
      "2021-11-20 02:44:30.867120 updating params.. 413\n",
      "2021-11-20 02:44:30.868134 recording loss.. 413\n",
      "2021-11-20 02:44:30.869301 start 414\n",
      "2021-11-20 02:44:30.869982 calculating gradient.. 414\n",
      "2021-11-20 02:45:33.373774 updating params.. 414\n",
      "2021-11-20 02:45:33.374715 recording loss.. 414\n",
      "2021-11-20 02:45:33.376013 start 415\n",
      "2021-11-20 02:45:33.376710 calculating gradient.. 415\n",
      "2021-11-20 02:46:35.753377 updating params.. 415\n",
      "2021-11-20 02:46:35.754334 recording loss.. 415\n",
      "2021-11-20 02:46:35.755625 start 416\n",
      "2021-11-20 02:46:35.756360 calculating gradient.. 416\n",
      "2021-11-20 02:47:38.588940 updating params.. 416\n",
      "2021-11-20 02:47:38.590030 recording loss.. 416\n",
      "2021-11-20 02:47:38.591239 start 417\n",
      "2021-11-20 02:47:38.591889 calculating gradient.. 417\n",
      "2021-11-20 02:48:40.838171 updating params.. 417\n",
      "2021-11-20 02:48:40.839079 recording loss.. 417\n",
      "2021-11-20 02:48:40.840445 start 418\n",
      "2021-11-20 02:48:40.841118 calculating gradient.. 418\n",
      "2021-11-20 02:49:43.087511 updating params.. 418\n",
      "2021-11-20 02:49:43.088439 recording loss.. 418\n",
      "2021-11-20 02:49:43.089709 start 419\n",
      "2021-11-20 02:49:43.090367 calculating gradient.. 419\n",
      "2021-11-20 02:50:45.461891 updating params.. 419\n",
      "2021-11-20 02:50:45.462804 recording loss.. 419\n",
      "2021-11-20 02:50:45.464494 start 420\n",
      "2021-11-20 02:50:45.465273 calculating gradient.. 420\n",
      "2021-11-20 02:51:48.291334 updating params.. 420\n",
      "2021-11-20 02:51:48.292317 recording loss.. 420\n",
      "train acc, test acc | 0.7027833333333333,0.7109\n",
      "2021-11-20 02:51:48.947885 start 421\n",
      "2021-11-20 02:51:48.949030 calculating gradient.. 421\n",
      "2021-11-20 02:52:51.523195 updating params.. 421\n",
      "2021-11-20 02:52:51.524265 recording loss.. 421\n",
      "2021-11-20 02:52:51.525571 start 422\n",
      "2021-11-20 02:52:51.526285 calculating gradient.. 422\n",
      "2021-11-20 02:53:53.624756 updating params.. 422\n",
      "2021-11-20 02:53:53.625693 recording loss.. 422\n",
      "2021-11-20 02:53:53.626898 start 423\n",
      "2021-11-20 02:53:53.627543 calculating gradient.. 423\n",
      "2021-11-20 02:54:56.863992 updating params.. 423\n",
      "2021-11-20 02:54:56.864940 recording loss.. 423\n",
      "2021-11-20 02:54:56.866424 start 424\n",
      "2021-11-20 02:54:56.867388 calculating gradient.. 424\n",
      "2021-11-20 02:55:59.479485 updating params.. 424\n",
      "2021-11-20 02:55:59.480515 recording loss.. 424\n",
      "2021-11-20 02:55:59.482180 start 425\n",
      "2021-11-20 02:55:59.483088 calculating gradient.. 425\n",
      "2021-11-20 02:57:02.605348 updating params.. 425\n",
      "2021-11-20 02:57:02.606288 recording loss.. 425\n",
      "2021-11-20 02:57:02.607662 start 426\n",
      "2021-11-20 02:57:02.608397 calculating gradient.. 426\n",
      "2021-11-20 02:58:05.159170 updating params.. 426\n",
      "2021-11-20 02:58:05.160130 recording loss.. 426\n",
      "2021-11-20 02:58:05.161431 start 427\n",
      "2021-11-20 02:58:05.162110 calculating gradient.. 427\n",
      "2021-11-20 02:59:08.282691 updating params.. 427\n",
      "2021-11-20 02:59:08.283663 recording loss.. 427\n",
      "2021-11-20 02:59:08.284952 start 428\n",
      "2021-11-20 02:59:08.285679 calculating gradient.. 428\n",
      "2021-11-20 03:00:10.948410 updating params.. 428\n",
      "2021-11-20 03:00:10.949365 recording loss.. 428\n",
      "2021-11-20 03:00:10.950634 start 429\n",
      "2021-11-20 03:00:10.951129 calculating gradient.. 429\n",
      "2021-11-20 03:01:13.226769 updating params.. 429\n",
      "2021-11-20 03:01:13.227712 recording loss.. 429\n",
      "2021-11-20 03:01:13.228983 start 430\n",
      "2021-11-20 03:01:13.229701 calculating gradient.. 430\n",
      "2021-11-20 03:02:25.332831 updating params.. 430\n",
      "2021-11-20 03:02:25.333879 recording loss.. 430\n",
      "train acc, test acc | 0.68945,0.6967\n",
      "2021-11-20 03:02:26.334928 start 431\n",
      "2021-11-20 03:02:26.335838 calculating gradient.. 431\n",
      "2021-11-20 03:03:45.285849 updating params.. 431\n",
      "2021-11-20 03:03:45.286816 recording loss.. 431\n",
      "2021-11-20 03:03:45.288047 start 432\n",
      "2021-11-20 03:03:45.288693 calculating gradient.. 432\n",
      "2021-11-20 03:04:48.033698 updating params.. 432\n",
      "2021-11-20 03:04:48.034647 recording loss.. 432\n",
      "2021-11-20 03:04:48.036007 start 433\n",
      "2021-11-20 03:04:48.036750 calculating gradient.. 433\n",
      "2021-11-20 03:05:50.236612 updating params.. 433\n",
      "2021-11-20 03:05:50.237629 recording loss.. 433\n",
      "2021-11-20 03:05:50.238865 start 434\n",
      "2021-11-20 03:05:50.239569 calculating gradient.. 434\n",
      "2021-11-20 03:06:52.636272 updating params.. 434\n",
      "2021-11-20 03:06:52.637268 recording loss.. 434\n",
      "2021-11-20 03:06:52.639002 start 435\n",
      "2021-11-20 03:06:52.639690 calculating gradient.. 435\n",
      "2021-11-20 03:07:55.008570 updating params.. 435\n",
      "2021-11-20 03:07:55.009521 recording loss.. 435\n",
      "2021-11-20 03:07:55.010811 start 436\n",
      "2021-11-20 03:07:55.011526 calculating gradient.. 436\n",
      "2021-11-20 03:08:57.382585 updating params.. 436\n",
      "2021-11-20 03:08:57.383478 recording loss.. 436\n",
      "2021-11-20 03:08:57.385403 start 437\n",
      "2021-11-20 03:08:57.386161 calculating gradient.. 437\n",
      "2021-11-20 03:10:00.369615 updating params.. 437\n",
      "2021-11-20 03:10:00.370580 recording loss.. 437\n",
      "2021-11-20 03:10:00.372196 start 438\n",
      "2021-11-20 03:10:00.373111 calculating gradient.. 438\n",
      "2021-11-20 03:11:02.411360 updating params.. 438\n",
      "2021-11-20 03:11:02.412315 recording loss.. 438\n",
      "2021-11-20 03:11:02.413627 start 439\n",
      "2021-11-20 03:11:02.414335 calculating gradient.. 439\n",
      "2021-11-20 03:12:04.786983 updating params.. 439\n",
      "2021-11-20 03:12:04.787942 recording loss.. 439\n",
      "2021-11-20 03:12:04.789300 start 440\n",
      "2021-11-20 03:12:04.790015 calculating gradient.. 440\n",
      "2021-11-20 03:13:06.975743 updating params.. 440\n",
      "2021-11-20 03:13:06.976739 recording loss.. 440\n",
      "train acc, test acc | 0.6899666666666666,0.6965\n",
      "2021-11-20 03:13:07.709693 start 441\n",
      "2021-11-20 03:13:07.710734 calculating gradient.. 441\n",
      "2021-11-20 03:14:10.040243 updating params.. 441\n",
      "2021-11-20 03:14:10.041172 recording loss.. 441\n",
      "2021-11-20 03:14:10.042516 start 442\n",
      "2021-11-20 03:14:10.043265 calculating gradient.. 442\n",
      "2021-11-20 03:15:13.967281 updating params.. 442\n",
      "2021-11-20 03:15:13.968257 recording loss.. 442\n",
      "2021-11-20 03:15:13.969600 start 443\n",
      "2021-11-20 03:15:13.970367 calculating gradient.. 443\n",
      "2021-11-20 03:16:16.400274 updating params.. 443\n",
      "2021-11-20 03:16:16.401274 recording loss.. 443\n",
      "2021-11-20 03:16:16.402489 start 444\n",
      "2021-11-20 03:16:16.403133 calculating gradient.. 444\n",
      "2021-11-20 03:17:18.629611 updating params.. 444\n",
      "2021-11-20 03:17:18.630556 recording loss.. 444\n",
      "2021-11-20 03:17:18.631855 start 445\n",
      "2021-11-20 03:17:18.632564 calculating gradient.. 445\n",
      "2021-11-20 03:18:20.982396 updating params.. 445\n",
      "2021-11-20 03:18:20.983340 recording loss.. 445\n",
      "2021-11-20 03:18:20.984561 start 446\n",
      "2021-11-20 03:18:20.985236 calculating gradient.. 446\n",
      "2021-11-20 03:19:23.216821 updating params.. 446\n",
      "2021-11-20 03:19:23.217786 recording loss.. 446\n",
      "2021-11-20 03:19:23.219059 start 447\n",
      "2021-11-20 03:19:23.219735 calculating gradient.. 447\n",
      "2021-11-20 03:20:26.032833 updating params.. 447\n",
      "2021-11-20 03:20:26.033823 recording loss.. 447\n",
      "2021-11-20 03:20:26.035108 start 448\n",
      "2021-11-20 03:20:26.035831 calculating gradient.. 448\n",
      "2021-11-20 03:21:28.810260 updating params.. 448\n",
      "2021-11-20 03:21:28.811203 recording loss.. 448\n",
      "2021-11-20 03:21:28.812484 start 449\n",
      "2021-11-20 03:21:28.813196 calculating gradient.. 449\n",
      "2021-11-20 03:22:31.122070 updating params.. 449\n",
      "2021-11-20 03:22:31.124171 recording loss.. 449\n",
      "2021-11-20 03:22:31.125600 start 450\n",
      "2021-11-20 03:22:31.126312 calculating gradient.. 450\n",
      "2021-11-20 03:23:33.278780 updating params.. 450\n",
      "2021-11-20 03:23:33.279815 recording loss.. 450\n",
      "train acc, test acc | 0.6721666666666667,0.6773\n",
      "2021-11-20 03:23:33.913443 start 451\n",
      "2021-11-20 03:23:33.914619 calculating gradient.. 451\n",
      "2021-11-20 03:24:36.732630 updating params.. 451\n",
      "2021-11-20 03:24:36.733623 recording loss.. 451\n",
      "2021-11-20 03:24:36.734887 start 452\n",
      "2021-11-20 03:24:36.735553 calculating gradient.. 452\n",
      "2021-11-20 03:25:39.732743 updating params.. 452\n",
      "2021-11-20 03:25:39.733717 recording loss.. 452\n",
      "2021-11-20 03:25:39.734971 start 453\n",
      "2021-11-20 03:25:39.735624 calculating gradient.. 453\n",
      "2021-11-20 03:26:42.267206 updating params.. 453\n",
      "2021-11-20 03:26:42.268134 recording loss.. 453\n",
      "2021-11-20 03:26:42.269373 start 454\n",
      "2021-11-20 03:26:42.270032 calculating gradient.. 454\n",
      "2021-11-20 03:27:44.705751 updating params.. 454\n",
      "2021-11-20 03:27:44.706749 recording loss.. 454\n",
      "2021-11-20 03:27:44.708390 start 455\n",
      "2021-11-20 03:27:44.709200 calculating gradient.. 455\n",
      "2021-11-20 03:28:46.876068 updating params.. 455\n",
      "2021-11-20 03:28:46.877009 recording loss.. 455\n",
      "2021-11-20 03:28:46.878311 start 456\n",
      "2021-11-20 03:28:46.879013 calculating gradient.. 456\n",
      "2021-11-20 03:29:49.618050 updating params.. 456\n",
      "2021-11-20 03:29:49.618971 recording loss.. 456\n",
      "2021-11-20 03:29:49.620178 start 457\n",
      "2021-11-20 03:29:49.620835 calculating gradient.. 457\n",
      "2021-11-20 03:30:52.143471 updating params.. 457\n",
      "2021-11-20 03:30:52.144402 recording loss.. 457\n",
      "2021-11-20 03:30:52.145735 start 458\n",
      "2021-11-20 03:30:52.146415 calculating gradient.. 458\n",
      "2021-11-20 03:31:54.431859 updating params.. 458\n",
      "2021-11-20 03:31:54.432825 recording loss.. 458\n",
      "2021-11-20 03:31:54.433982 start 459\n",
      "2021-11-20 03:31:54.434629 calculating gradient.. 459\n",
      "2021-11-20 03:32:56.870293 updating params.. 459\n",
      "2021-11-20 03:32:56.871221 recording loss.. 459\n",
      "2021-11-20 03:32:56.872452 start 460\n",
      "2021-11-20 03:32:56.873126 calculating gradient.. 460\n",
      "2021-11-20 03:33:59.000598 updating params.. 460\n",
      "2021-11-20 03:33:59.001386 recording loss.. 460\n",
      "train acc, test acc | 0.6896,0.6984\n",
      "2021-11-20 03:33:59.607839 start 461\n",
      "2021-11-20 03:33:59.608678 calculating gradient.. 461\n",
      "2021-11-20 03:35:02.800127 updating params.. 461\n",
      "2021-11-20 03:35:02.801057 recording loss.. 461\n",
      "2021-11-20 03:35:02.803077 start 462\n",
      "2021-11-20 03:35:02.803823 calculating gradient.. 462\n",
      "2021-11-20 03:36:04.924023 updating params.. 462\n",
      "2021-11-20 03:36:04.924978 recording loss.. 462\n",
      "2021-11-20 03:36:04.926222 start 463\n",
      "2021-11-20 03:36:04.926874 calculating gradient.. 463\n",
      "2021-11-20 03:37:07.324687 updating params.. 463\n",
      "2021-11-20 03:37:07.325668 recording loss.. 463\n",
      "2021-11-20 03:37:07.326770 start 464\n",
      "2021-11-20 03:37:07.327507 calculating gradient.. 464\n",
      "2021-11-20 03:38:09.988516 updating params.. 464\n",
      "2021-11-20 03:38:09.989476 recording loss.. 464\n",
      "2021-11-20 03:38:09.990868 start 465\n",
      "2021-11-20 03:38:09.991622 calculating gradient.. 465\n",
      "2021-11-20 03:39:12.244077 updating params.. 465\n",
      "2021-11-20 03:39:12.245063 recording loss.. 465\n",
      "2021-11-20 03:39:12.246307 start 466\n",
      "2021-11-20 03:39:12.246955 calculating gradient.. 466\n",
      "2021-11-20 03:40:14.751068 updating params.. 466\n",
      "2021-11-20 03:40:14.752054 recording loss.. 466\n",
      "2021-11-20 03:40:14.753283 start 467\n",
      "2021-11-20 03:40:14.753945 calculating gradient.. 467\n",
      "2021-11-20 03:41:16.854075 updating params.. 467\n",
      "2021-11-20 03:41:16.855130 recording loss.. 467\n",
      "2021-11-20 03:41:16.856962 start 468\n",
      "2021-11-20 03:41:16.858034 calculating gradient.. 468\n",
      "2021-11-20 03:42:19.365296 updating params.. 468\n",
      "2021-11-20 03:42:19.366521 recording loss.. 468\n",
      "2021-11-20 03:42:19.367726 start 469\n",
      "2021-11-20 03:42:19.368295 calculating gradient.. 469\n",
      "2021-11-20 03:43:22.274578 updating params.. 469\n",
      "2021-11-20 03:43:22.275616 recording loss.. 469\n",
      "2021-11-20 03:43:22.276824 start 470\n",
      "2021-11-20 03:43:22.277488 calculating gradient.. 470\n",
      "2021-11-20 03:44:25.425323 updating params.. 470\n",
      "2021-11-20 03:44:25.436862 recording loss.. 470\n",
      "train acc, test acc | 0.7239333333333333,0.7315\n",
      "2021-11-20 03:44:26.194359 start 471\n",
      "2021-11-20 03:44:26.195530 calculating gradient.. 471\n",
      "2021-11-20 03:45:28.506323 updating params.. 471\n",
      "2021-11-20 03:45:28.507279 recording loss.. 471\n",
      "2021-11-20 03:45:28.508583 start 472\n",
      "2021-11-20 03:45:28.509263 calculating gradient.. 472\n",
      "2021-11-20 03:46:30.734768 updating params.. 472\n",
      "2021-11-20 03:46:30.735711 recording loss.. 472\n",
      "2021-11-20 03:46:30.736996 start 473\n",
      "2021-11-20 03:46:30.737715 calculating gradient.. 473\n",
      "2021-11-20 03:47:33.341279 updating params.. 473\n",
      "2021-11-20 03:47:33.342213 recording loss.. 473\n",
      "2021-11-20 03:47:33.343491 start 474\n",
      "2021-11-20 03:47:33.344192 calculating gradient.. 474\n",
      "2021-11-20 03:48:35.864135 updating params.. 474\n",
      "2021-11-20 03:48:35.865166 recording loss.. 474\n",
      "2021-11-20 03:48:35.866394 start 475\n",
      "2021-11-20 03:48:35.867041 calculating gradient.. 475\n",
      "2021-11-20 03:49:38.752081 updating params.. 475\n",
      "2021-11-20 03:49:38.753053 recording loss.. 475\n",
      "2021-11-20 03:49:38.754321 start 476\n",
      "2021-11-20 03:49:38.754978 calculating gradient.. 476\n",
      "2021-11-20 03:50:40.905948 updating params.. 476\n",
      "2021-11-20 03:50:40.906881 recording loss.. 476\n",
      "2021-11-20 03:50:40.908213 start 477\n",
      "2021-11-20 03:50:40.908923 calculating gradient.. 477\n",
      "2021-11-20 03:51:43.476724 updating params.. 477\n",
      "2021-11-20 03:51:43.477753 recording loss.. 477\n",
      "2021-11-20 03:51:43.479366 start 478\n",
      "2021-11-20 03:51:43.480324 calculating gradient.. 478\n",
      "2021-11-20 03:52:45.883549 updating params.. 478\n",
      "2021-11-20 03:52:45.884470 recording loss.. 478\n",
      "2021-11-20 03:52:45.886024 start 479\n",
      "2021-11-20 03:52:45.886758 calculating gradient.. 479\n",
      "2021-11-20 03:53:48.253123 updating params.. 479\n",
      "2021-11-20 03:53:48.254224 recording loss.. 479\n",
      "2021-11-20 03:53:48.255427 start 480\n",
      "2021-11-20 03:53:48.256071 calculating gradient.. 480\n",
      "2021-11-20 03:54:51.673914 updating params.. 480\n",
      "2021-11-20 03:54:51.674845 recording loss.. 480\n",
      "train acc, test acc | 0.7370166666666667,0.7414\n",
      "2021-11-20 03:54:52.301379 start 481\n",
      "2021-11-20 03:54:52.302375 calculating gradient.. 481\n",
      "2021-11-20 03:55:54.692288 updating params.. 481\n",
      "2021-11-20 03:55:54.693216 recording loss.. 481\n",
      "2021-11-20 03:55:54.694528 start 482\n",
      "2021-11-20 03:55:54.695265 calculating gradient.. 482\n",
      "2021-11-20 03:56:57.355646 updating params.. 482\n",
      "2021-11-20 03:56:57.356647 recording loss.. 482\n",
      "2021-11-20 03:56:57.358287 start 483\n",
      "2021-11-20 03:56:57.358688 calculating gradient.. 483\n",
      "2021-11-20 03:57:59.808494 updating params.. 483\n",
      "2021-11-20 03:57:59.810462 recording loss.. 483\n",
      "2021-11-20 03:57:59.812171 start 484\n",
      "2021-11-20 03:57:59.812906 calculating gradient.. 484\n",
      "2021-11-20 03:59:02.284810 updating params.. 484\n",
      "2021-11-20 03:59:02.285759 recording loss.. 484\n",
      "2021-11-20 03:59:02.287507 start 485\n",
      "2021-11-20 03:59:02.288382 calculating gradient.. 485\n",
      "2021-11-20 04:00:04.955173 updating params.. 485\n",
      "2021-11-20 04:00:04.956158 recording loss.. 485\n",
      "2021-11-20 04:00:04.957471 start 486\n",
      "2021-11-20 04:00:04.958174 calculating gradient.. 486\n",
      "2021-11-20 04:01:07.703786 updating params.. 486\n",
      "2021-11-20 04:01:07.704730 recording loss.. 486\n",
      "2021-11-20 04:01:07.706044 start 487\n",
      "2021-11-20 04:01:07.706794 calculating gradient.. 487\n",
      "2021-11-20 04:02:15.836671 updating params.. 487\n",
      "2021-11-20 04:02:15.837062 recording loss.. 487\n",
      "2021-11-20 04:02:15.839694 start 488\n",
      "2021-11-20 04:02:15.840594 calculating gradient.. 488\n",
      "2021-11-20 04:03:39.256768 updating params.. 488\n",
      "2021-11-20 04:03:39.257725 recording loss.. 488\n",
      "2021-11-20 04:03:39.259524 start 489\n",
      "2021-11-20 04:03:39.260339 calculating gradient.. 489\n",
      "2021-11-20 04:04:42.066589 updating params.. 489\n",
      "2021-11-20 04:04:42.067706 recording loss.. 489\n",
      "2021-11-20 04:04:42.069092 start 490\n",
      "2021-11-20 04:04:42.069850 calculating gradient.. 490\n",
      "2021-11-20 04:05:44.495295 updating params.. 490\n",
      "2021-11-20 04:05:44.496250 recording loss.. 490\n",
      "train acc, test acc | 0.7370833333333333,0.7458\n",
      "2021-11-20 04:05:45.147839 start 491\n",
      "2021-11-20 04:05:45.148867 calculating gradient.. 491\n",
      "2021-11-20 04:06:47.584950 updating params.. 491\n",
      "2021-11-20 04:06:47.585895 recording loss.. 491\n",
      "2021-11-20 04:06:47.587194 start 492\n",
      "2021-11-20 04:06:47.587893 calculating gradient.. 492\n",
      "2021-11-20 04:07:50.387843 updating params.. 492\n",
      "2021-11-20 04:07:50.388864 recording loss.. 492\n",
      "2021-11-20 04:07:50.390307 start 493\n",
      "2021-11-20 04:07:50.391175 calculating gradient.. 493\n",
      "2021-11-20 04:08:52.399808 updating params.. 493\n",
      "2021-11-20 04:08:52.400735 recording loss.. 493\n",
      "2021-11-20 04:08:52.402059 start 494\n",
      "2021-11-20 04:08:52.402778 calculating gradient.. 494\n",
      "2021-11-20 04:09:54.791247 updating params.. 494\n",
      "2021-11-20 04:09:54.792253 recording loss.. 494\n",
      "2021-11-20 04:09:54.793519 start 495\n",
      "2021-11-20 04:09:54.794229 calculating gradient.. 495\n",
      "2021-11-20 04:10:56.974947 updating params.. 495\n",
      "2021-11-20 04:10:56.975881 recording loss.. 495\n",
      "2021-11-20 04:10:56.977219 start 496\n",
      "2021-11-20 04:10:56.977935 calculating gradient.. 496\n",
      "2021-11-20 04:11:59.494718 updating params.. 496\n",
      "2021-11-20 04:11:59.495670 recording loss.. 496\n",
      "2021-11-20 04:11:59.496921 start 497\n",
      "2021-11-20 04:11:59.497686 calculating gradient.. 497\n",
      "2021-11-20 04:13:02.191808 updating params.. 497\n",
      "2021-11-20 04:13:02.192751 recording loss.. 497\n",
      "2021-11-20 04:13:02.194048 start 498\n",
      "2021-11-20 04:13:02.194809 calculating gradient.. 498\n",
      "2021-11-20 04:14:04.578376 updating params.. 498\n",
      "2021-11-20 04:14:04.579315 recording loss.. 498\n",
      "2021-11-20 04:14:04.580594 start 499\n",
      "2021-11-20 04:14:04.581326 calculating gradient.. 499\n",
      "2021-11-20 04:15:07.734982 updating params.. 499\n",
      "2021-11-20 04:15:07.735964 recording loss.. 499\n",
      "2021-11-20 04:15:07.737279 start 500\n",
      "2021-11-20 04:15:07.738001 calculating gradient.. 500\n",
      "2021-11-20 04:16:10.003287 updating params.. 500\n",
      "2021-11-20 04:16:10.004244 recording loss.. 500\n",
      "train acc, test acc | 0.7410166666666667,0.7556\n",
      "2021-11-20 04:16:10.716322 start 501\n",
      "2021-11-20 04:16:10.717088 calculating gradient.. 501\n",
      "2021-11-20 04:17:13.203009 updating params.. 501\n",
      "2021-11-20 04:17:13.203977 recording loss.. 501\n",
      "2021-11-20 04:17:13.205314 start 502\n",
      "2021-11-20 04:17:13.206087 calculating gradient.. 502\n",
      "2021-11-20 04:18:15.553365 updating params.. 502\n",
      "2021-11-20 04:18:15.554371 recording loss.. 502\n",
      "2021-11-20 04:18:15.555616 start 503\n",
      "2021-11-20 04:18:15.556305 calculating gradient.. 503\n",
      "2021-11-20 04:19:18.051026 updating params.. 503\n",
      "2021-11-20 04:19:18.051995 recording loss.. 503\n",
      "2021-11-20 04:19:18.053296 start 504\n",
      "2021-11-20 04:19:18.053995 calculating gradient.. 504\n",
      "2021-11-20 04:20:21.286385 updating params.. 504\n",
      "2021-11-20 04:20:21.287468 recording loss.. 504\n",
      "2021-11-20 04:20:21.288697 start 505\n",
      "2021-11-20 04:20:21.289358 calculating gradient.. 505\n",
      "2021-11-20 04:21:23.979990 updating params.. 505\n",
      "2021-11-20 04:21:23.981001 recording loss.. 505\n",
      "2021-11-20 04:21:23.982286 start 506\n",
      "2021-11-20 04:21:23.983074 calculating gradient.. 506\n",
      "2021-11-20 04:22:26.646838 updating params.. 506\n",
      "2021-11-20 04:22:26.647854 recording loss.. 506\n",
      "2021-11-20 04:22:26.649106 start 507\n",
      "2021-11-20 04:22:26.649833 calculating gradient.. 507\n",
      "2021-11-20 04:23:28.966753 updating params.. 507\n",
      "2021-11-20 04:23:28.967710 recording loss.. 507\n",
      "2021-11-20 04:23:28.969669 start 508\n",
      "2021-11-20 04:23:28.970561 calculating gradient.. 508\n",
      "2021-11-20 04:24:31.737708 updating params.. 508\n",
      "2021-11-20 04:24:31.738606 recording loss.. 508\n",
      "2021-11-20 04:24:31.739944 start 509\n",
      "2021-11-20 04:24:31.740654 calculating gradient.. 509\n",
      "2021-11-20 04:25:34.272399 updating params.. 509\n",
      "2021-11-20 04:25:34.273356 recording loss.. 509\n",
      "2021-11-20 04:25:34.274560 start 510\n",
      "2021-11-20 04:25:34.275253 calculating gradient.. 510\n",
      "2021-11-20 04:26:36.494154 updating params.. 510\n",
      "2021-11-20 04:26:36.495108 recording loss.. 510\n",
      "train acc, test acc | 0.7308166666666667,0.7404\n",
      "2021-11-20 04:26:37.166211 start 511\n",
      "2021-11-20 04:26:37.167407 calculating gradient.. 511\n",
      "2021-11-20 04:27:39.438813 updating params.. 511\n",
      "2021-11-20 04:27:39.439735 recording loss.. 511\n",
      "2021-11-20 04:27:39.441004 start 512\n",
      "2021-11-20 04:27:39.441750 calculating gradient.. 512\n",
      "2021-11-20 04:28:42.163541 updating params.. 512\n",
      "2021-11-20 04:28:42.164425 recording loss.. 512\n",
      "2021-11-20 04:28:42.165665 start 513\n",
      "2021-11-20 04:28:42.166321 calculating gradient.. 513\n",
      "2021-11-20 04:29:44.664227 updating params.. 513\n",
      "2021-11-20 04:29:44.665369 recording loss.. 513\n",
      "2021-11-20 04:29:44.666651 start 514\n",
      "2021-11-20 04:29:44.667349 calculating gradient.. 514\n",
      "2021-11-20 04:30:47.015230 updating params.. 514\n",
      "2021-11-20 04:30:47.017332 recording loss.. 514\n",
      "2021-11-20 04:30:47.018940 start 515\n",
      "2021-11-20 04:30:47.019882 calculating gradient.. 515\n",
      "2021-11-20 04:31:49.425066 updating params.. 515\n",
      "2021-11-20 04:31:49.426084 recording loss.. 515\n",
      "2021-11-20 04:31:49.427317 start 516\n",
      "2021-11-20 04:31:49.427939 calculating gradient.. 516\n",
      "2021-11-20 04:32:51.636680 updating params.. 516\n",
      "2021-11-20 04:32:51.637633 recording loss.. 516\n",
      "2021-11-20 04:32:51.638918 start 517\n",
      "2021-11-20 04:32:51.639616 calculating gradient.. 517\n",
      "2021-11-20 04:33:53.837049 updating params.. 517\n",
      "2021-11-20 04:33:53.838027 recording loss.. 517\n",
      "2021-11-20 04:33:53.839164 start 518\n",
      "2021-11-20 04:33:53.839810 calculating gradient.. 518\n",
      "2021-11-20 04:35:05.210934 updating params.. 518\n",
      "2021-11-20 04:35:05.213534 recording loss.. 518\n",
      "2021-11-20 04:35:05.215887 start 519\n",
      "2021-11-20 04:35:05.217122 calculating gradient.. 519\n",
      "2021-11-20 04:36:13.327616 updating params.. 519\n",
      "2021-11-20 04:36:13.328552 recording loss.. 519\n",
      "2021-11-20 04:36:13.329866 start 520\n",
      "2021-11-20 04:36:13.330568 calculating gradient.. 520\n",
      "2021-11-20 04:37:15.888990 updating params.. 520\n",
      "2021-11-20 04:37:15.889930 recording loss.. 520\n",
      "train acc, test acc | 0.743,0.7506\n",
      "2021-11-20 04:37:16.967735 start 521\n",
      "2021-11-20 04:37:16.968843 calculating gradient.. 521\n",
      "2021-11-20 04:38:19.594089 updating params.. 521\n",
      "2021-11-20 04:38:19.595039 recording loss.. 521\n",
      "2021-11-20 04:38:19.596149 start 522\n",
      "2021-11-20 04:38:19.596788 calculating gradient.. 522\n",
      "2021-11-20 04:39:21.656661 updating params.. 522\n",
      "2021-11-20 04:39:21.657593 recording loss.. 522\n",
      "2021-11-20 04:39:21.658822 start 523\n",
      "2021-11-20 04:39:21.659460 calculating gradient.. 523\n",
      "2021-11-20 04:40:24.096152 updating params.. 523\n",
      "2021-11-20 04:40:24.097155 recording loss.. 523\n",
      "2021-11-20 04:40:24.098479 start 524\n",
      "2021-11-20 04:40:24.099190 calculating gradient.. 524\n",
      "2021-11-20 04:41:26.412354 updating params.. 524\n",
      "2021-11-20 04:41:26.413310 recording loss.. 524\n",
      "2021-11-20 04:41:26.414537 start 525\n",
      "2021-11-20 04:41:26.415192 calculating gradient.. 525\n",
      "2021-11-20 04:42:28.878452 updating params.. 525\n",
      "2021-11-20 04:42:28.879531 recording loss.. 525\n",
      "2021-11-20 04:42:28.881271 start 526\n",
      "2021-11-20 04:42:28.882214 calculating gradient.. 526\n",
      "2021-11-20 04:43:31.634250 updating params.. 526\n",
      "2021-11-20 04:43:31.635195 recording loss.. 526\n",
      "2021-11-20 04:43:31.636429 start 527\n",
      "2021-11-20 04:43:31.636967 calculating gradient.. 527\n",
      "2021-11-20 04:44:34.084366 updating params.. 527\n",
      "2021-11-20 04:44:34.085449 recording loss.. 527\n",
      "2021-11-20 04:44:34.087159 start 528\n",
      "2021-11-20 04:44:34.088260 calculating gradient.. 528\n",
      "2021-11-20 04:45:36.410168 updating params.. 528\n",
      "2021-11-20 04:45:36.411188 recording loss.. 528\n",
      "2021-11-20 04:45:36.412444 start 529\n",
      "2021-11-20 04:45:36.413134 calculating gradient.. 529\n",
      "2021-11-20 04:46:38.581581 updating params.. 529\n",
      "2021-11-20 04:46:38.582580 recording loss.. 529\n",
      "2021-11-20 04:46:38.583773 start 530\n",
      "2021-11-20 04:46:38.584436 calculating gradient.. 530\n",
      "2021-11-20 04:47:41.051219 updating params.. 530\n",
      "2021-11-20 04:47:41.052136 recording loss.. 530\n",
      "train acc, test acc | 0.75065,0.7601\n",
      "2021-11-20 04:47:41.905030 start 531\n",
      "2021-11-20 04:47:41.906161 calculating gradient.. 531\n",
      "2021-11-20 04:48:44.311341 updating params.. 531\n",
      "2021-11-20 04:48:44.312261 recording loss.. 531\n",
      "2021-11-20 04:48:44.313459 start 532\n",
      "2021-11-20 04:48:44.314114 calculating gradient.. 532\n",
      "2021-11-20 04:49:47.601624 updating params.. 532\n",
      "2021-11-20 04:49:47.602747 recording loss.. 532\n",
      "2021-11-20 04:49:47.604428 start 533\n",
      "2021-11-20 04:49:47.604872 calculating gradient.. 533\n",
      "2021-11-20 04:50:50.762556 updating params.. 533\n",
      "2021-11-20 04:50:50.763508 recording loss.. 533\n",
      "2021-11-20 04:50:50.764783 start 534\n",
      "2021-11-20 04:50:50.765493 calculating gradient.. 534\n",
      "2021-11-20 04:51:53.194860 updating params.. 534\n",
      "2021-11-20 04:51:53.195809 recording loss.. 534\n",
      "2021-11-20 04:51:53.197112 start 535\n",
      "2021-11-20 04:51:53.197832 calculating gradient.. 535\n",
      "2021-11-20 04:52:55.842303 updating params.. 535\n",
      "2021-11-20 04:52:55.843335 recording loss.. 535\n",
      "2021-11-20 04:52:55.844546 start 536\n",
      "2021-11-20 04:52:55.845272 calculating gradient.. 536\n",
      "2021-11-20 04:53:58.216672 updating params.. 536\n",
      "2021-11-20 04:53:58.217615 recording loss.. 536\n",
      "2021-11-20 04:53:58.218895 start 537\n",
      "2021-11-20 04:53:58.219585 calculating gradient.. 537\n",
      "2021-11-20 04:55:00.970970 updating params.. 537\n",
      "2021-11-20 04:55:00.971961 recording loss.. 537\n",
      "2021-11-20 04:55:00.973294 start 538\n",
      "2021-11-20 04:55:00.974001 calculating gradient.. 538\n",
      "2021-11-20 04:56:03.384619 updating params.. 538\n",
      "2021-11-20 04:56:03.385578 recording loss.. 538\n",
      "2021-11-20 04:56:03.386781 start 539\n",
      "2021-11-20 04:56:03.387428 calculating gradient.. 539\n",
      "2021-11-20 04:57:05.855072 updating params.. 539\n",
      "2021-11-20 04:57:05.856056 recording loss.. 539\n",
      "2021-11-20 04:57:05.857558 start 540\n",
      "2021-11-20 04:57:05.858395 calculating gradient.. 540\n",
      "2021-11-20 04:58:08.411265 updating params.. 540\n",
      "2021-11-20 04:58:08.412202 recording loss.. 540\n",
      "train acc, test acc | 0.77065,0.7788\n",
      "2021-11-20 04:58:08.964470 start 541\n",
      "2021-11-20 04:58:08.965323 calculating gradient.. 541\n",
      "2021-11-20 04:59:12.261885 updating params.. 541\n",
      "2021-11-20 04:59:12.262825 recording loss.. 541\n",
      "2021-11-20 04:59:12.264118 start 542\n",
      "2021-11-20 04:59:12.264811 calculating gradient.. 542\n",
      "2021-11-20 05:00:15.525673 updating params.. 542\n",
      "2021-11-20 05:00:15.526646 recording loss.. 542\n",
      "2021-11-20 05:00:15.527923 start 543\n",
      "2021-11-20 05:00:15.528614 calculating gradient.. 543\n",
      "2021-11-20 05:01:17.834733 updating params.. 543\n",
      "2021-11-20 05:01:17.835678 recording loss.. 543\n",
      "2021-11-20 05:01:17.836754 start 544\n",
      "2021-11-20 05:01:17.837411 calculating gradient.. 544\n",
      "2021-11-20 05:02:31.757847 updating params.. 544\n",
      "2021-11-20 05:02:31.758983 recording loss.. 544\n",
      "2021-11-20 05:02:31.760723 start 545\n",
      "2021-11-20 05:02:31.761732 calculating gradient.. 545\n",
      "2021-11-20 05:04:02.178363 updating params.. 545\n",
      "2021-11-20 05:04:02.179582 recording loss.. 545\n",
      "2021-11-20 05:04:02.181884 start 546\n",
      "2021-11-20 05:04:02.182996 calculating gradient.. 546\n",
      "2021-11-20 05:05:44.377407 updating params.. 546\n",
      "2021-11-20 05:05:44.378380 recording loss.. 546\n",
      "2021-11-20 05:05:44.380324 start 547\n",
      "2021-11-20 05:05:44.381675 calculating gradient.. 547\n",
      "2021-11-20 05:07:17.059139 updating params.. 547\n",
      "2021-11-20 05:07:17.060317 recording loss.. 547\n",
      "2021-11-20 05:07:17.062389 start 548\n",
      "2021-11-20 05:07:17.063242 calculating gradient.. 548\n",
      "2021-11-20 05:08:52.956579 updating params.. 548\n",
      "2021-11-20 05:08:52.957557 recording loss.. 548\n",
      "2021-11-20 05:08:52.958917 start 549\n",
      "2021-11-20 05:08:52.959660 calculating gradient.. 549\n",
      "2021-11-20 05:10:26.334412 updating params.. 549\n",
      "2021-11-20 05:10:26.337350 recording loss.. 549\n",
      "2021-11-20 05:10:26.339380 start 550\n",
      "2021-11-20 05:10:26.340358 calculating gradient.. 550\n",
      "2021-11-20 05:11:54.087435 updating params.. 550\n",
      "2021-11-20 05:11:54.088526 recording loss.. 550\n",
      "train acc, test acc | 0.7724833333333333,0.7801\n",
      "2021-11-20 05:11:55.292021 start 551\n",
      "2021-11-20 05:11:55.292927 calculating gradient.. 551\n",
      "2021-11-20 05:13:05.415740 updating params.. 551\n",
      "2021-11-20 05:13:05.416896 recording loss.. 551\n",
      "2021-11-20 05:13:05.418798 start 552\n",
      "2021-11-20 05:13:05.419815 calculating gradient.. 552\n",
      "2021-11-20 05:14:30.797513 updating params.. 552\n",
      "2021-11-20 05:14:30.799052 recording loss.. 552\n",
      "2021-11-20 05:14:30.801106 start 553\n",
      "2021-11-20 05:14:30.801949 calculating gradient.. 553\n",
      "2021-11-20 05:16:15.594969 updating params.. 553\n",
      "2021-11-20 05:16:15.595397 recording loss.. 553\n",
      "2021-11-20 05:16:15.598126 start 554\n",
      "2021-11-20 05:16:15.598966 calculating gradient.. 554\n",
      "2021-11-20 05:18:00.330003 updating params.. 554\n",
      "2021-11-20 05:18:00.331117 recording loss.. 554\n",
      "2021-11-20 05:18:00.332714 start 555\n",
      "2021-11-20 05:18:00.333631 calculating gradient.. 555\n",
      "2021-11-20 05:19:45.334706 updating params.. 555\n",
      "2021-11-20 05:19:45.335117 recording loss.. 555\n",
      "2021-11-20 05:19:45.337108 start 556\n",
      "2021-11-20 05:19:45.338202 calculating gradient.. 556\n",
      "2021-11-20 05:21:30.679351 updating params.. 556\n",
      "2021-11-20 05:21:30.680836 recording loss.. 556\n",
      "2021-11-20 05:21:30.682864 start 557\n",
      "2021-11-20 05:21:30.683710 calculating gradient.. 557\n",
      "2021-11-20 05:23:16.483321 updating params.. 557\n",
      "2021-11-20 05:23:16.484349 recording loss.. 557\n",
      "2021-11-20 05:23:16.485919 start 558\n",
      "2021-11-20 05:23:16.486304 calculating gradient.. 558\n",
      "2021-11-20 05:25:01.744973 updating params.. 558\n",
      "2021-11-20 05:25:01.746070 recording loss.. 558\n",
      "2021-11-20 05:25:01.747945 start 559\n",
      "2021-11-20 05:25:01.748783 calculating gradient.. 559\n",
      "2021-11-20 05:26:45.981477 updating params.. 559\n",
      "2021-11-20 05:26:45.982619 recording loss.. 559\n",
      "2021-11-20 05:26:45.984503 start 560\n",
      "2021-11-20 05:26:45.985428 calculating gradient.. 560\n",
      "2021-11-20 05:28:24.695101 updating params.. 560\n",
      "2021-11-20 05:28:24.696221 recording loss.. 560\n",
      "train acc, test acc | 0.7809166666666667,0.7885\n",
      "2021-11-20 05:28:25.818644 start 561\n",
      "2021-11-20 05:28:25.819840 calculating gradient.. 561\n",
      "2021-11-20 05:30:00.055012 updating params.. 561\n",
      "2021-11-20 05:30:00.056107 recording loss.. 561\n",
      "2021-11-20 05:30:00.058017 start 562\n",
      "2021-11-20 05:30:00.058849 calculating gradient.. 562\n",
      "2021-11-20 05:31:37.330129 updating params.. 562\n",
      "2021-11-20 05:31:37.331091 recording loss.. 562\n",
      "2021-11-20 05:31:37.332441 start 563\n",
      "2021-11-20 05:31:37.333156 calculating gradient.. 563\n",
      "2021-11-20 05:33:09.525498 updating params.. 563\n",
      "2021-11-20 05:33:09.526459 recording loss.. 563\n",
      "2021-11-20 05:33:09.527754 start 564\n",
      "2021-11-20 05:33:09.528447 calculating gradient.. 564\n",
      "2021-11-20 05:34:45.417342 updating params.. 564\n",
      "2021-11-20 05:34:45.418388 recording loss.. 564\n",
      "2021-11-20 05:34:45.422763 start 565\n",
      "2021-11-20 05:34:45.424085 calculating gradient.. 565\n",
      "2021-11-20 05:36:15.101372 updating params.. 565\n",
      "2021-11-20 05:36:15.102441 recording loss.. 565\n",
      "2021-11-20 05:36:15.104308 start 566\n",
      "2021-11-20 05:36:15.105165 calculating gradient.. 566\n",
      "2021-11-20 05:38:00.092932 updating params.. 566\n",
      "2021-11-20 05:38:00.093354 recording loss.. 566\n",
      "2021-11-20 05:38:00.094980 start 567\n",
      "2021-11-20 05:38:00.097126 calculating gradient.. 567\n",
      "2021-11-20 05:39:19.590216 updating params.. 567\n",
      "2021-11-20 05:39:19.591133 recording loss.. 567\n",
      "2021-11-20 05:39:19.592341 start 568\n",
      "2021-11-20 05:39:19.593041 calculating gradient.. 568\n",
      "2021-11-20 05:40:22.455554 updating params.. 568\n",
      "2021-11-20 05:40:22.456497 recording loss.. 568\n",
      "2021-11-20 05:40:22.457750 start 569\n",
      "2021-11-20 05:40:22.458508 calculating gradient.. 569\n",
      "2021-11-20 05:41:24.904485 updating params.. 569\n",
      "2021-11-20 05:41:24.905431 recording loss.. 569\n",
      "2021-11-20 05:41:24.906760 start 570\n",
      "2021-11-20 05:41:24.907474 calculating gradient.. 570\n",
      "2021-11-20 05:42:27.282808 updating params.. 570\n",
      "2021-11-20 05:42:27.283745 recording loss.. 570\n",
      "train acc, test acc | 0.7777166666666666,0.7841\n",
      "2021-11-20 05:42:28.197192 start 571\n",
      "2021-11-20 05:42:28.199538 calculating gradient.. 571\n",
      "2021-11-20 05:43:30.483549 updating params.. 571\n",
      "2021-11-20 05:43:30.484519 recording loss.. 571\n",
      "2021-11-20 05:43:30.485847 start 572\n",
      "2021-11-20 05:43:30.486567 calculating gradient.. 572\n",
      "2021-11-20 05:44:33.069689 updating params.. 572\n",
      "2021-11-20 05:44:33.070613 recording loss.. 572\n",
      "2021-11-20 05:44:33.071946 start 573\n",
      "2021-11-20 05:44:33.072656 calculating gradient.. 573\n",
      "2021-11-20 05:45:35.451364 updating params.. 573\n",
      "2021-11-20 05:45:35.452305 recording loss.. 573\n",
      "2021-11-20 05:45:35.453603 start 574\n",
      "2021-11-20 05:45:35.454357 calculating gradient.. 574\n",
      "2021-11-20 05:46:37.759172 updating params.. 574\n",
      "2021-11-20 05:46:37.760261 recording loss.. 574\n",
      "2021-11-20 05:46:37.761593 start 575\n",
      "2021-11-20 05:46:37.762306 calculating gradient.. 575\n",
      "2021-11-20 05:47:40.684282 updating params.. 575\n",
      "2021-11-20 05:47:40.685360 recording loss.. 575\n",
      "2021-11-20 05:47:40.686662 start 576\n",
      "2021-11-20 05:47:40.687332 calculating gradient.. 576\n",
      "2021-11-20 05:48:42.785066 updating params.. 576\n",
      "2021-11-20 05:48:42.785445 recording loss.. 576\n",
      "2021-11-20 05:48:42.787418 start 577\n",
      "2021-11-20 05:48:42.788115 calculating gradient.. 577\n",
      "2021-11-20 05:49:45.695312 updating params.. 577\n",
      "2021-11-20 05:49:45.696273 recording loss.. 577\n",
      "2021-11-20 05:49:45.697761 start 578\n",
      "2021-11-20 05:49:45.698470 calculating gradient.. 578\n",
      "2021-11-20 05:50:48.373640 updating params.. 578\n",
      "2021-11-20 05:50:48.374648 recording loss.. 578\n",
      "2021-11-20 05:50:48.375867 start 579\n",
      "2021-11-20 05:50:48.376506 calculating gradient.. 579\n",
      "2021-11-20 05:51:50.714745 updating params.. 579\n",
      "2021-11-20 05:51:50.715910 recording loss.. 579\n",
      "2021-11-20 05:51:50.717123 start 580\n",
      "2021-11-20 05:51:50.717814 calculating gradient.. 580\n",
      "2021-11-20 05:52:53.248232 updating params.. 580\n",
      "2021-11-20 05:52:53.249251 recording loss.. 580\n",
      "train acc, test acc | 0.7812333333333333,0.7898\n",
      "2021-11-20 05:52:54.039421 start 581\n",
      "2021-11-20 05:52:54.040192 calculating gradient.. 581\n",
      "2021-11-20 05:53:56.691442 updating params.. 581\n",
      "2021-11-20 05:53:56.692347 recording loss.. 581\n",
      "2021-11-20 05:53:56.693579 start 582\n",
      "2021-11-20 05:53:56.694224 calculating gradient.. 582\n",
      "2021-11-20 05:54:59.010408 updating params.. 582\n",
      "2021-11-20 05:54:59.011381 recording loss.. 582\n",
      "2021-11-20 05:54:59.012794 start 583\n",
      "2021-11-20 05:54:59.013492 calculating gradient.. 583\n",
      "2021-11-20 05:56:01.088448 updating params.. 583\n",
      "2021-11-20 05:56:01.089399 recording loss.. 583\n",
      "2021-11-20 05:56:01.090610 start 584\n",
      "2021-11-20 05:56:01.091281 calculating gradient.. 584\n",
      "2021-11-20 05:57:03.939940 updating params.. 584\n",
      "2021-11-20 05:57:03.940961 recording loss.. 584\n",
      "2021-11-20 05:57:03.942351 start 585\n",
      "2021-11-20 05:57:03.943148 calculating gradient.. 585\n",
      "2021-11-20 05:58:06.644360 updating params.. 585\n",
      "2021-11-20 05:58:06.645325 recording loss.. 585\n",
      "2021-11-20 05:58:06.646554 start 586\n",
      "2021-11-20 05:58:06.647211 calculating gradient.. 586\n",
      "2021-11-20 05:59:08.996788 updating params.. 586\n",
      "2021-11-20 05:59:08.997778 recording loss.. 586\n",
      "2021-11-20 05:59:08.998900 start 587\n",
      "2021-11-20 05:59:08.999551 calculating gradient.. 587\n",
      "2021-11-20 06:00:14.628981 updating params.. 587\n",
      "2021-11-20 06:00:14.629396 recording loss.. 587\n",
      "2021-11-20 06:00:14.630564 start 588\n",
      "2021-11-20 06:00:14.632353 calculating gradient.. 588\n",
      "2021-11-20 06:01:17.137017 updating params.. 588\n",
      "2021-11-20 06:01:17.138084 recording loss.. 588\n",
      "2021-11-20 06:01:17.139298 start 589\n",
      "2021-11-20 06:01:17.140103 calculating gradient.. 589\n",
      "2021-11-20 06:02:30.554664 updating params.. 589\n",
      "2021-11-20 06:02:30.556732 recording loss.. 589\n",
      "2021-11-20 06:02:30.558364 start 590\n",
      "2021-11-20 06:02:30.559028 calculating gradient.. 590\n",
      "2021-11-20 06:03:49.194114 updating params.. 590\n",
      "2021-11-20 06:03:49.195099 recording loss.. 590\n",
      "train acc, test acc | 0.7908166666666666,0.7958\n",
      "2021-11-20 06:03:50.031920 start 591\n",
      "2021-11-20 06:03:50.032994 calculating gradient.. 591\n",
      "2021-11-20 06:04:52.925289 updating params.. 591\n",
      "2021-11-20 06:04:52.926221 recording loss.. 591\n",
      "2021-11-20 06:04:52.927778 start 592\n",
      "2021-11-20 06:04:52.928572 calculating gradient.. 592\n",
      "2021-11-20 06:05:55.150187 updating params.. 592\n",
      "2021-11-20 06:05:55.151136 recording loss.. 592\n",
      "2021-11-20 06:05:55.152416 start 593\n",
      "2021-11-20 06:05:55.153119 calculating gradient.. 593\n",
      "2021-11-20 06:06:57.536220 updating params.. 593\n",
      "2021-11-20 06:06:57.537176 recording loss.. 593\n",
      "2021-11-20 06:06:57.538941 start 594\n",
      "2021-11-20 06:06:57.539663 calculating gradient.. 594\n",
      "2021-11-20 06:08:00.008135 updating params.. 594\n",
      "2021-11-20 06:08:00.009070 recording loss.. 594\n",
      "2021-11-20 06:08:00.011013 start 595\n",
      "2021-11-20 06:08:00.011788 calculating gradient.. 595\n",
      "2021-11-20 06:09:02.529207 updating params.. 595\n",
      "2021-11-20 06:09:02.530112 recording loss.. 595\n",
      "2021-11-20 06:09:02.531328 start 596\n",
      "2021-11-20 06:09:02.531997 calculating gradient.. 596\n",
      "2021-11-20 06:10:05.749730 updating params.. 596\n",
      "2021-11-20 06:10:05.750658 recording loss.. 596\n",
      "2021-11-20 06:10:05.751895 start 597\n",
      "2021-11-20 06:10:05.752549 calculating gradient.. 597\n",
      "2021-11-20 06:11:08.123055 updating params.. 597\n",
      "2021-11-20 06:11:08.123996 recording loss.. 597\n",
      "2021-11-20 06:11:08.125295 start 598\n",
      "2021-11-20 06:11:08.125996 calculating gradient.. 598\n",
      "2021-11-20 06:12:10.195198 updating params.. 598\n",
      "2021-11-20 06:12:10.196127 recording loss.. 598\n",
      "2021-11-20 06:12:10.197264 start 599\n",
      "2021-11-20 06:12:10.197983 calculating gradient.. 599\n",
      "2021-11-20 06:13:12.621474 updating params.. 599\n",
      "2021-11-20 06:13:12.622399 recording loss.. 599\n",
      "2021-11-20 06:13:12.624079 start 600\n",
      "2021-11-20 06:13:12.624883 calculating gradient.. 600\n",
      "2021-11-20 06:14:14.692213 updating params.. 600\n",
      "2021-11-20 06:14:14.693173 recording loss.. 600\n",
      "train acc, test acc | 0.7913666666666667,0.7982\n",
      "2021-11-20 06:14:15.461867 start 601\n",
      "2021-11-20 06:14:15.463209 calculating gradient.. 601\n",
      "2021-11-20 06:15:18.138528 updating params.. 601\n",
      "2021-11-20 06:15:18.139460 recording loss.. 601\n",
      "2021-11-20 06:15:18.140796 start 602\n",
      "2021-11-20 06:15:18.141544 calculating gradient.. 602\n",
      "2021-11-20 06:16:21.196415 updating params.. 602\n",
      "2021-11-20 06:16:21.197383 recording loss.. 602\n",
      "2021-11-20 06:16:21.199047 start 603\n",
      "2021-11-20 06:16:21.199832 calculating gradient.. 603\n",
      "2021-11-20 06:17:23.124346 updating params.. 603\n",
      "2021-11-20 06:17:23.125307 recording loss.. 603\n",
      "2021-11-20 06:17:23.126518 start 604\n",
      "2021-11-20 06:17:23.127170 calculating gradient.. 604\n",
      "2021-11-20 06:18:25.585025 updating params.. 604\n",
      "2021-11-20 06:18:25.586138 recording loss.. 604\n",
      "2021-11-20 06:18:25.587565 start 605\n",
      "2021-11-20 06:18:25.588322 calculating gradient.. 605\n",
      "2021-11-20 06:19:30.659274 updating params.. 605\n",
      "2021-11-20 06:19:30.660234 recording loss.. 605\n",
      "2021-11-20 06:19:30.661546 start 606\n",
      "2021-11-20 06:19:30.662318 calculating gradient.. 606\n",
      "2021-11-20 06:20:33.604449 updating params.. 606\n",
      "2021-11-20 06:20:33.605458 recording loss.. 606\n",
      "2021-11-20 06:20:33.607459 start 607\n",
      "2021-11-20 06:20:33.608196 calculating gradient.. 607\n",
      "2021-11-20 06:21:35.652511 updating params.. 607\n",
      "2021-11-20 06:21:35.653497 recording loss.. 607\n",
      "2021-11-20 06:21:35.654778 start 608\n",
      "2021-11-20 06:21:35.655551 calculating gradient.. 608\n",
      "2021-11-20 06:22:38.090499 updating params.. 608\n",
      "2021-11-20 06:22:38.091441 recording loss.. 608\n",
      "2021-11-20 06:22:38.092765 start 609\n",
      "2021-11-20 06:22:38.093489 calculating gradient.. 609\n",
      "2021-11-20 06:23:40.342264 updating params.. 609\n",
      "2021-11-20 06:23:40.343290 recording loss.. 609\n",
      "2021-11-20 06:23:40.344583 start 610\n",
      "2021-11-20 06:23:40.345282 calculating gradient.. 610\n",
      "2021-11-20 06:24:42.484973 updating params.. 610\n",
      "2021-11-20 06:24:42.485922 recording loss.. 610\n",
      "train acc, test acc | 0.7956333333333333,0.8017\n",
      "2021-11-20 06:24:43.144756 start 611\n",
      "2021-11-20 06:24:43.145534 calculating gradient.. 611\n",
      "2021-11-20 06:25:45.691159 updating params.. 611\n",
      "2021-11-20 06:25:45.692104 recording loss.. 611\n",
      "2021-11-20 06:25:45.693340 start 612\n",
      "2021-11-20 06:25:45.694156 calculating gradient.. 612\n",
      "2021-11-20 06:26:47.999951 updating params.. 612\n",
      "2021-11-20 06:26:48.000899 recording loss.. 612\n",
      "2021-11-20 06:26:48.002205 start 613\n",
      "2021-11-20 06:26:48.002858 calculating gradient.. 613\n",
      "2021-11-20 06:27:50.404354 updating params.. 613\n",
      "2021-11-20 06:27:50.405388 recording loss.. 613\n",
      "2021-11-20 06:27:50.406758 start 614\n",
      "2021-11-20 06:27:50.407500 calculating gradient.. 614\n",
      "2021-11-20 06:28:52.600188 updating params.. 614\n",
      "2021-11-20 06:28:52.601119 recording loss.. 614\n",
      "2021-11-20 06:28:52.602560 start 615\n",
      "2021-11-20 06:28:52.603137 calculating gradient.. 615\n",
      "2021-11-20 06:29:55.409783 updating params.. 615\n",
      "2021-11-20 06:29:55.410732 recording loss.. 615\n",
      "2021-11-20 06:29:55.411968 start 616\n",
      "2021-11-20 06:29:55.412445 calculating gradient.. 616\n",
      "2021-11-20 06:30:57.269367 updating params.. 616\n",
      "2021-11-20 06:30:57.270279 recording loss.. 616\n",
      "2021-11-20 06:30:57.271485 start 617\n",
      "2021-11-20 06:30:57.272119 calculating gradient.. 617\n",
      "2021-11-20 06:31:59.158962 updating params.. 617\n",
      "2021-11-20 06:31:59.159904 recording loss.. 617\n",
      "2021-11-20 06:31:59.161215 start 618\n",
      "2021-11-20 06:31:59.162052 calculating gradient.. 618\n",
      "2021-11-20 06:33:01.401376 updating params.. 618\n",
      "2021-11-20 06:33:01.402328 recording loss.. 618\n",
      "2021-11-20 06:33:01.403611 start 619\n",
      "2021-11-20 06:33:01.404251 calculating gradient.. 619\n",
      "2021-11-20 06:34:03.545518 updating params.. 619\n",
      "2021-11-20 06:34:03.546438 recording loss.. 619\n",
      "2021-11-20 06:34:03.547771 start 620\n",
      "2021-11-20 06:34:03.548493 calculating gradient.. 620\n",
      "2021-11-20 06:35:06.057210 updating params.. 620\n",
      "2021-11-20 06:35:06.058179 recording loss.. 620\n",
      "train acc, test acc | 0.7873666666666667,0.7949\n",
      "2021-11-20 06:35:06.733631 start 621\n",
      "2021-11-20 06:35:06.734718 calculating gradient.. 621\n",
      "2021-11-20 06:36:08.727610 updating params.. 621\n",
      "2021-11-20 06:36:08.728526 recording loss.. 621\n",
      "2021-11-20 06:36:08.729752 start 622\n",
      "2021-11-20 06:36:08.730397 calculating gradient.. 622\n",
      "2021-11-20 06:37:10.653430 updating params.. 622\n",
      "2021-11-20 06:37:10.654365 recording loss.. 622\n",
      "2021-11-20 06:37:10.655722 start 623\n",
      "2021-11-20 06:37:10.656479 calculating gradient.. 623\n",
      "2021-11-20 06:38:13.047559 updating params.. 623\n",
      "2021-11-20 06:38:13.048500 recording loss.. 623\n",
      "2021-11-20 06:38:13.049791 start 624\n",
      "2021-11-20 06:38:13.050496 calculating gradient.. 624\n",
      "2021-11-20 06:39:15.181333 updating params.. 624\n",
      "2021-11-20 06:39:15.182251 recording loss.. 624\n",
      "2021-11-20 06:39:15.183468 start 625\n",
      "2021-11-20 06:39:15.184128 calculating gradient.. 625\n",
      "2021-11-20 06:40:18.029404 updating params.. 625\n",
      "2021-11-20 06:40:18.030340 recording loss.. 625\n",
      "2021-11-20 06:40:18.031568 start 626\n",
      "2021-11-20 06:40:18.032231 calculating gradient.. 626\n",
      "2021-11-20 06:41:19.755022 updating params.. 626\n",
      "2021-11-20 06:41:19.756003 recording loss.. 626\n",
      "2021-11-20 06:41:19.757941 start 627\n",
      "2021-11-20 06:41:19.758642 calculating gradient.. 627\n",
      "2021-11-20 06:42:21.703472 updating params.. 627\n",
      "2021-11-20 06:42:21.704296 recording loss.. 627\n",
      "2021-11-20 06:42:21.705621 start 628\n",
      "2021-11-20 06:42:21.706275 calculating gradient.. 628\n",
      "2021-11-20 06:43:24.226860 updating params.. 628\n",
      "2021-11-20 06:43:24.227836 recording loss.. 628\n",
      "2021-11-20 06:43:24.229113 start 629\n",
      "2021-11-20 06:43:24.229832 calculating gradient.. 629\n",
      "2021-11-20 06:44:26.517809 updating params.. 629\n",
      "2021-11-20 06:44:26.518740 recording loss.. 629\n",
      "2021-11-20 06:44:26.520019 start 630\n",
      "2021-11-20 06:44:26.520718 calculating gradient.. 630\n",
      "2021-11-20 06:45:28.803132 updating params.. 630\n",
      "2021-11-20 06:45:28.804146 recording loss.. 630\n",
      "train acc, test acc | 0.7963,0.8015\n",
      "2021-11-20 06:45:29.434082 start 631\n",
      "2021-11-20 06:45:29.434892 calculating gradient.. 631\n",
      "2021-11-20 06:46:31.727268 updating params.. 631\n",
      "2021-11-20 06:46:31.728296 recording loss.. 631\n",
      "2021-11-20 06:46:31.729658 start 632\n",
      "2021-11-20 06:46:31.730322 calculating gradient.. 632\n",
      "2021-11-20 06:47:33.460094 updating params.. 632\n",
      "2021-11-20 06:47:33.461002 recording loss.. 632\n",
      "2021-11-20 06:47:33.462224 start 633\n",
      "2021-11-20 06:47:33.462765 calculating gradient.. 633\n",
      "2021-11-20 06:48:35.681982 updating params.. 633\n",
      "2021-11-20 06:48:35.682946 recording loss.. 633\n",
      "2021-11-20 06:48:35.684257 start 634\n",
      "2021-11-20 06:48:35.684958 calculating gradient.. 634\n",
      "2021-11-20 06:49:38.596657 updating params.. 634\n",
      "2021-11-20 06:49:38.597590 recording loss.. 634\n",
      "2021-11-20 06:49:38.598811 start 635\n",
      "2021-11-20 06:49:38.599461 calculating gradient.. 635\n",
      "2021-11-20 06:50:40.611150 updating params.. 635\n",
      "2021-11-20 06:50:40.612072 recording loss.. 635\n",
      "2021-11-20 06:50:40.613307 start 636\n",
      "2021-11-20 06:50:40.613993 calculating gradient.. 636\n",
      "2021-11-20 06:51:43.073283 updating params.. 636\n",
      "2021-11-20 06:51:43.074244 recording loss.. 636\n",
      "2021-11-20 06:51:43.075533 start 637\n",
      "2021-11-20 06:51:43.076277 calculating gradient.. 637\n",
      "2021-11-20 06:52:45.686007 updating params.. 637\n",
      "2021-11-20 06:52:45.686938 recording loss.. 637\n",
      "2021-11-20 06:52:45.688151 start 638\n",
      "2021-11-20 06:52:45.688793 calculating gradient.. 638\n",
      "2021-11-20 06:53:47.672364 updating params.. 638\n",
      "2021-11-20 06:53:47.673378 recording loss.. 638\n",
      "2021-11-20 06:53:47.674630 start 639\n",
      "2021-11-20 06:53:47.675355 calculating gradient.. 639\n",
      "2021-11-20 06:54:49.705835 updating params.. 639\n",
      "2021-11-20 06:54:49.706828 recording loss.. 639\n",
      "2021-11-20 06:54:49.708233 start 640\n",
      "2021-11-20 06:54:49.708962 calculating gradient.. 640\n",
      "2021-11-20 06:55:51.635937 updating params.. 640\n",
      "2021-11-20 06:55:51.636874 recording loss.. 640\n",
      "train acc, test acc | 0.8047166666666666,0.8096\n",
      "2021-11-20 06:55:52.298230 start 641\n",
      "2021-11-20 06:55:52.298979 calculating gradient.. 641\n",
      "2021-11-20 06:56:55.119709 updating params.. 641\n",
      "2021-11-20 06:56:55.120622 recording loss.. 641\n",
      "2021-11-20 06:56:55.121734 start 642\n",
      "2021-11-20 06:56:55.122449 calculating gradient.. 642\n",
      "2021-11-20 06:57:57.358073 updating params.. 642\n",
      "2021-11-20 06:57:57.359008 recording loss.. 642\n",
      "2021-11-20 06:57:57.360223 start 643\n",
      "2021-11-20 06:57:57.360919 calculating gradient.. 643\n",
      "2021-11-20 06:59:00.455874 updating params.. 643\n",
      "2021-11-20 06:59:00.456928 recording loss.. 643\n",
      "2021-11-20 06:59:00.458264 start 644\n",
      "2021-11-20 06:59:00.458945 calculating gradient.. 644\n",
      "2021-11-20 07:00:02.937781 updating params.. 644\n",
      "2021-11-20 07:00:02.938712 recording loss.. 644\n",
      "2021-11-20 07:00:02.939902 start 645\n",
      "2021-11-20 07:00:02.940545 calculating gradient.. 645\n",
      "2021-11-20 07:01:05.440876 updating params.. 645\n",
      "2021-11-20 07:01:05.441943 recording loss.. 645\n",
      "2021-11-20 07:01:05.443235 start 646\n",
      "2021-11-20 07:01:05.443903 calculating gradient.. 646\n",
      "2021-11-20 07:02:11.622930 updating params.. 646\n",
      "2021-11-20 07:02:11.624036 recording loss.. 646\n",
      "2021-11-20 07:02:11.625663 start 647\n",
      "2021-11-20 07:02:11.626398 calculating gradient.. 647\n",
      "2021-11-20 07:03:36.002653 updating params.. 647\n",
      "2021-11-20 07:03:36.003687 recording loss.. 647\n",
      "2021-11-20 07:03:36.004785 start 648\n",
      "2021-11-20 07:03:36.005462 calculating gradient.. 648\n",
      "2021-11-20 07:04:38.412285 updating params.. 648\n",
      "2021-11-20 07:04:38.413584 recording loss.. 648\n",
      "2021-11-20 07:04:38.414929 start 649\n",
      "2021-11-20 07:04:38.415632 calculating gradient.. 649\n",
      "2021-11-20 07:05:40.892334 updating params.. 649\n",
      "2021-11-20 07:05:40.893324 recording loss.. 649\n",
      "2021-11-20 07:05:40.894592 start 650\n",
      "2021-11-20 07:05:40.895271 calculating gradient.. 650\n",
      "2021-11-20 07:06:42.711920 updating params.. 650\n",
      "2021-11-20 07:06:42.712861 recording loss.. 650\n",
      "train acc, test acc | 0.8150166666666666,0.817\n",
      "2021-11-20 07:06:43.400881 start 651\n",
      "2021-11-20 07:06:43.401680 calculating gradient.. 651\n",
      "2021-11-20 07:07:45.565542 updating params.. 651\n",
      "2021-11-20 07:07:45.566446 recording loss.. 651\n",
      "2021-11-20 07:07:45.567658 start 652\n",
      "2021-11-20 07:07:45.568301 calculating gradient.. 652\n",
      "2021-11-20 07:08:47.568287 updating params.. 652\n",
      "2021-11-20 07:08:47.569040 recording loss.. 652\n",
      "2021-11-20 07:08:47.570502 start 653\n",
      "2021-11-20 07:08:47.571148 calculating gradient.. 653\n",
      "2021-11-20 07:09:50.714751 updating params.. 653\n",
      "2021-11-20 07:09:50.715709 recording loss.. 653\n",
      "2021-11-20 07:09:50.716950 start 654\n",
      "2021-11-20 07:09:50.717634 calculating gradient.. 654\n",
      "2021-11-20 07:10:53.806027 updating params.. 654\n",
      "2021-11-20 07:10:53.807019 recording loss.. 654\n",
      "2021-11-20 07:10:53.808285 start 655\n",
      "2021-11-20 07:10:53.808989 calculating gradient.. 655\n",
      "2021-11-20 07:11:56.012774 updating params.. 655\n",
      "2021-11-20 07:11:56.013739 recording loss.. 655\n",
      "2021-11-20 07:11:56.015056 start 656\n",
      "2021-11-20 07:11:56.015830 calculating gradient.. 656\n",
      "2021-11-20 07:13:06.933673 updating params.. 656\n",
      "2021-11-20 07:13:06.934586 recording loss.. 656\n",
      "2021-11-20 07:13:06.935791 start 657\n",
      "2021-11-20 07:13:06.936501 calculating gradient.. 657\n",
      "2021-11-20 07:14:08.875111 updating params.. 657\n",
      "2021-11-20 07:14:08.875985 recording loss.. 657\n",
      "2021-11-20 07:14:08.877749 start 658\n",
      "2021-11-20 07:14:08.878513 calculating gradient.. 658\n",
      "2021-11-20 07:15:11.194535 updating params.. 658\n",
      "2021-11-20 07:15:11.195558 recording loss.. 658\n",
      "2021-11-20 07:15:11.196769 start 659\n",
      "2021-11-20 07:15:11.197430 calculating gradient.. 659\n",
      "2021-11-20 07:16:13.267471 updating params.. 659\n",
      "2021-11-20 07:16:13.268418 recording loss.. 659\n",
      "2021-11-20 07:16:13.269748 start 660\n",
      "2021-11-20 07:16:13.270480 calculating gradient.. 660\n",
      "2021-11-20 07:17:15.425912 updating params.. 660\n",
      "2021-11-20 07:17:15.427072 recording loss.. 660\n",
      "train acc, test acc | 0.81525,0.8186\n",
      "2021-11-20 07:17:16.088677 start 661\n",
      "2021-11-20 07:17:16.089726 calculating gradient.. 661\n",
      "2021-11-20 07:18:18.508035 updating params.. 661\n",
      "2021-11-20 07:18:18.508987 recording loss.. 661\n",
      "2021-11-20 07:18:18.510313 start 662\n",
      "2021-11-20 07:18:18.511018 calculating gradient.. 662\n",
      "2021-11-20 07:19:20.377670 updating params.. 662\n",
      "2021-11-20 07:19:20.378633 recording loss.. 662\n",
      "2021-11-20 07:19:20.379920 start 663\n",
      "2021-11-20 07:19:20.380614 calculating gradient.. 663\n",
      "2021-11-20 07:20:25.397760 updating params.. 663\n",
      "2021-11-20 07:20:25.398719 recording loss.. 663\n",
      "2021-11-20 07:20:25.400049 start 664\n",
      "2021-11-20 07:20:25.400744 calculating gradient.. 664\n",
      "2021-11-20 07:21:27.734106 updating params.. 664\n",
      "2021-11-20 07:21:27.735038 recording loss.. 664\n",
      "2021-11-20 07:21:27.736253 start 665\n",
      "2021-11-20 07:21:27.736892 calculating gradient.. 665\n",
      "2021-11-20 07:22:29.740794 updating params.. 665\n",
      "2021-11-20 07:22:29.741777 recording loss.. 665\n",
      "2021-11-20 07:22:29.743367 start 666\n",
      "2021-11-20 07:22:29.744202 calculating gradient.. 666\n",
      "2021-11-20 07:23:32.101624 updating params.. 666\n",
      "2021-11-20 07:23:32.102585 recording loss.. 666\n",
      "2021-11-20 07:23:32.103924 start 667\n",
      "2021-11-20 07:23:32.104711 calculating gradient.. 667\n",
      "2021-11-20 07:24:34.789093 updating params.. 667\n",
      "2021-11-20 07:24:34.790064 recording loss.. 667\n",
      "2021-11-20 07:24:34.791510 start 668\n",
      "2021-11-20 07:24:34.792257 calculating gradient.. 668\n",
      "2021-11-20 07:25:37.150465 updating params.. 668\n",
      "2021-11-20 07:25:37.151506 recording loss.. 668\n",
      "2021-11-20 07:25:37.152723 start 669\n",
      "2021-11-20 07:25:37.153401 calculating gradient.. 669\n",
      "2021-11-20 07:26:39.084169 updating params.. 669\n",
      "2021-11-20 07:26:39.085263 recording loss.. 669\n",
      "2021-11-20 07:26:39.087036 start 670\n",
      "2021-11-20 07:26:39.087993 calculating gradient.. 670\n",
      "2021-11-20 07:27:41.346770 updating params.. 670\n",
      "2021-11-20 07:27:41.347728 recording loss.. 670\n",
      "train acc, test acc | 0.8152666666666667,0.8192\n",
      "2021-11-20 07:27:42.155729 start 671\n",
      "2021-11-20 07:27:42.156529 calculating gradient.. 671\n",
      "2021-11-20 07:28:44.547274 updating params.. 671\n",
      "2021-11-20 07:28:44.548183 recording loss.. 671\n",
      "2021-11-20 07:28:44.549453 start 672\n",
      "2021-11-20 07:28:44.550108 calculating gradient.. 672\n",
      "2021-11-20 07:29:47.552369 updating params.. 672\n",
      "2021-11-20 07:29:47.553373 recording loss.. 672\n",
      "2021-11-20 07:29:47.555245 start 673\n",
      "2021-11-20 07:29:47.556084 calculating gradient.. 673\n",
      "2021-11-20 07:30:49.947416 updating params.. 673\n",
      "2021-11-20 07:30:49.948442 recording loss.. 673\n",
      "2021-11-20 07:30:49.949663 start 674\n",
      "2021-11-20 07:30:49.950324 calculating gradient.. 674\n",
      "2021-11-20 07:31:51.821668 updating params.. 674\n",
      "2021-11-20 07:31:51.822601 recording loss.. 674\n",
      "2021-11-20 07:31:51.823923 start 675\n",
      "2021-11-20 07:31:51.824634 calculating gradient.. 675\n",
      "2021-11-20 07:32:53.891759 updating params.. 675\n",
      "2021-11-20 07:32:53.892737 recording loss.. 675\n",
      "2021-11-20 07:32:53.894323 start 676\n",
      "2021-11-20 07:32:53.895104 calculating gradient.. 676\n",
      "2021-11-20 07:33:56.105473 updating params.. 676\n",
      "2021-11-20 07:33:56.106415 recording loss.. 676\n",
      "2021-11-20 07:33:56.107687 start 677\n",
      "2021-11-20 07:33:56.108374 calculating gradient.. 677\n",
      "2021-11-20 07:34:58.460812 updating params.. 677\n",
      "2021-11-20 07:34:58.461811 recording loss.. 677\n",
      "2021-11-20 07:34:58.463052 start 678\n",
      "2021-11-20 07:34:58.463691 calculating gradient.. 678\n",
      "2021-11-20 07:36:20.231344 updating params.. 678\n",
      "2021-11-20 07:36:20.232459 recording loss.. 678\n",
      "2021-11-20 07:36:20.233774 start 679\n",
      "2021-11-20 07:36:20.234490 calculating gradient.. 679\n",
      "2021-11-20 07:37:40.694237 updating params.. 679\n",
      "2021-11-20 07:37:40.695203 recording loss.. 679\n",
      "2021-11-20 07:37:40.696433 start 680\n",
      "2021-11-20 07:37:40.697078 calculating gradient.. 680\n",
      "2021-11-20 07:39:05.117652 updating params.. 680\n",
      "2021-11-20 07:39:05.118927 recording loss.. 680\n",
      "train acc, test acc | 0.8151166666666667,0.8202\n",
      "2021-11-20 07:39:06.058905 start 681\n",
      "2021-11-20 07:39:06.060085 calculating gradient.. 681\n",
      "2021-11-20 07:40:33.091757 updating params.. 681\n",
      "2021-11-20 07:40:33.092724 recording loss.. 681\n",
      "2021-11-20 07:40:33.094123 start 682\n",
      "2021-11-20 07:40:33.094824 calculating gradient.. 682\n",
      "2021-11-20 07:41:53.970926 updating params.. 682\n",
      "2021-11-20 07:41:53.971908 recording loss.. 682\n",
      "2021-11-20 07:41:53.973263 start 683\n",
      "2021-11-20 07:41:53.974030 calculating gradient.. 683\n",
      "2021-11-20 07:43:16.413469 updating params.. 683\n",
      "2021-11-20 07:43:16.414903 recording loss.. 683\n",
      "2021-11-20 07:43:16.416669 start 684\n",
      "2021-11-20 07:43:16.417632 calculating gradient.. 684\n",
      "2021-11-20 07:44:37.960470 updating params.. 684\n",
      "2021-11-20 07:44:37.960899 recording loss.. 684\n",
      "2021-11-20 07:44:37.963785 start 685\n",
      "2021-11-20 07:44:37.964679 calculating gradient.. 685\n",
      "2021-11-20 07:45:59.494762 updating params.. 685\n",
      "2021-11-20 07:45:59.495720 recording loss.. 685\n",
      "2021-11-20 07:45:59.497074 start 686\n",
      "2021-11-20 07:45:59.497825 calculating gradient.. 686\n",
      "2021-11-20 07:47:34.965903 updating params.. 686\n",
      "2021-11-20 07:47:34.966310 recording loss.. 686\n",
      "2021-11-20 07:47:34.968633 start 687\n",
      "2021-11-20 07:47:34.969549 calculating gradient.. 687\n",
      "2021-11-20 07:48:57.876578 updating params.. 687\n",
      "2021-11-20 07:48:57.877138 recording loss.. 687\n",
      "2021-11-20 07:48:57.880986 start 688\n",
      "2021-11-20 07:48:57.881480 calculating gradient.. 688\n",
      "2021-11-20 07:50:20.524148 updating params.. 688\n",
      "2021-11-20 07:50:20.525069 recording loss.. 688\n",
      "2021-11-20 07:50:20.526288 start 689\n",
      "2021-11-20 07:50:20.526930 calculating gradient.. 689\n",
      "2021-11-20 07:51:41.675626 updating params.. 689\n",
      "2021-11-20 07:51:41.676589 recording loss.. 689\n",
      "2021-11-20 07:51:41.678004 start 690\n",
      "2021-11-20 07:51:41.678747 calculating gradient.. 690\n",
      "2021-11-20 07:53:03.646356 updating params.. 690\n",
      "2021-11-20 07:53:03.647553 recording loss.. 690\n",
      "train acc, test acc | 0.81485,0.8184\n",
      "2021-11-20 07:53:04.701130 start 691\n",
      "2021-11-20 07:53:04.702406 calculating gradient.. 691\n",
      "2021-11-20 07:54:26.088645 updating params.. 691\n",
      "2021-11-20 07:54:26.089590 recording loss.. 691\n",
      "2021-11-20 07:54:26.090892 start 692\n",
      "2021-11-20 07:54:26.091596 calculating gradient.. 692\n",
      "2021-11-20 07:55:48.208851 updating params.. 692\n",
      "2021-11-20 07:55:48.209839 recording loss.. 692\n",
      "2021-11-20 07:55:48.211197 start 693\n",
      "2021-11-20 07:55:48.211865 calculating gradient.. 693\n",
      "2021-11-20 07:57:10.940230 updating params.. 693\n",
      "2021-11-20 07:57:10.941193 recording loss.. 693\n",
      "2021-11-20 07:57:10.942501 start 694\n",
      "2021-11-20 07:57:10.943231 calculating gradient.. 694\n",
      "2021-11-20 07:58:31.761542 updating params.. 694\n",
      "2021-11-20 07:58:31.762477 recording loss.. 694\n",
      "2021-11-20 07:58:31.764218 start 695\n",
      "2021-11-20 07:58:31.764994 calculating gradient.. 695\n",
      "2021-11-20 07:59:53.272082 updating params.. 695\n",
      "2021-11-20 07:59:53.273033 recording loss.. 695\n",
      "2021-11-20 07:59:53.274787 start 696\n",
      "2021-11-20 07:59:53.275677 calculating gradient.. 696\n",
      "2021-11-20 08:01:15.667222 updating params.. 696\n",
      "2021-11-20 08:01:15.668293 recording loss.. 696\n",
      "2021-11-20 08:01:15.670105 start 697\n",
      "2021-11-20 08:01:15.671068 calculating gradient.. 697\n",
      "2021-11-20 08:02:54.112124 updating params.. 697\n",
      "2021-11-20 08:02:54.114668 recording loss.. 697\n",
      "2021-11-20 08:02:54.116962 start 698\n",
      "2021-11-20 08:02:54.117854 calculating gradient.. 698\n",
      "2021-11-20 08:04:25.770857 updating params.. 698\n",
      "2021-11-20 08:04:25.771607 recording loss.. 698\n",
      "2021-11-20 08:04:25.773510 start 699\n",
      "2021-11-20 08:04:25.774003 calculating gradient.. 699\n",
      "2021-11-20 08:05:47.367867 updating params.. 699\n",
      "2021-11-20 08:05:47.368851 recording loss.. 699\n",
      "2021-11-20 08:05:47.370762 start 700\n",
      "2021-11-20 08:05:47.371259 calculating gradient.. 700\n",
      "2021-11-20 08:07:08.654523 updating params.. 700\n",
      "2021-11-20 08:07:08.654991 recording loss.. 700\n",
      "train acc, test acc | 0.8177666666666666,0.8216\n",
      "2021-11-20 08:07:09.548002 start 701\n",
      "2021-11-20 08:07:09.548961 calculating gradient.. 701\n",
      "2021-11-20 08:08:31.535624 updating params.. 701\n",
      "2021-11-20 08:08:31.536605 recording loss.. 701\n",
      "2021-11-20 08:08:31.538613 start 702\n",
      "2021-11-20 08:08:31.539033 calculating gradient.. 702\n",
      "2021-11-20 08:09:53.590657 updating params.. 702\n",
      "2021-11-20 08:09:53.591597 recording loss.. 702\n",
      "2021-11-20 08:09:53.593062 start 703\n",
      "2021-11-20 08:09:53.593903 calculating gradient.. 703\n",
      "2021-11-20 08:11:14.338438 updating params.. 703\n",
      "2021-11-20 08:11:14.339378 recording loss.. 703\n",
      "2021-11-20 08:11:14.340981 start 704\n",
      "2021-11-20 08:11:14.341719 calculating gradient.. 704\n",
      "2021-11-20 08:12:35.211873 updating params.. 704\n",
      "2021-11-20 08:12:35.212806 recording loss.. 704\n",
      "2021-11-20 08:12:35.214055 start 705\n",
      "2021-11-20 08:12:35.214701 calculating gradient.. 705\n",
      "2021-11-20 08:13:56.278585 updating params.. 705\n",
      "2021-11-20 08:13:56.279521 recording loss.. 705\n",
      "2021-11-20 08:13:56.280803 start 706\n",
      "2021-11-20 08:13:56.281532 calculating gradient.. 706\n",
      "2021-11-20 08:15:17.915044 updating params.. 706\n",
      "2021-11-20 08:15:17.915973 recording loss.. 706\n",
      "2021-11-20 08:15:17.917207 start 707\n",
      "2021-11-20 08:15:17.917922 calculating gradient.. 707\n",
      "2021-11-20 08:16:41.065123 updating params.. 707\n",
      "2021-11-20 08:16:41.066070 recording loss.. 707\n",
      "2021-11-20 08:16:41.067398 start 708\n",
      "2021-11-20 08:16:41.068067 calculating gradient.. 708\n",
      "2021-11-20 08:18:02.184258 updating params.. 708\n",
      "2021-11-20 08:18:02.185163 recording loss.. 708\n",
      "2021-11-20 08:18:02.186437 start 709\n",
      "2021-11-20 08:18:02.187095 calculating gradient.. 709\n",
      "2021-11-20 08:19:24.478021 updating params.. 709\n",
      "2021-11-20 08:19:24.478453 recording loss.. 709\n",
      "2021-11-20 08:19:24.479965 start 710\n",
      "2021-11-20 08:19:24.480363 calculating gradient.. 710\n",
      "2021-11-20 08:20:46.255862 updating params.. 710\n",
      "2021-11-20 08:20:46.256781 recording loss.. 710\n",
      "train acc, test acc | 0.8242166666666667,0.8279\n",
      "2021-11-20 08:20:46.956943 start 711\n",
      "2021-11-20 08:20:46.958120 calculating gradient.. 711\n",
      "2021-11-20 08:22:09.801990 updating params.. 711\n",
      "2021-11-20 08:22:09.802966 recording loss.. 711\n",
      "2021-11-20 08:22:09.804694 start 712\n",
      "2021-11-20 08:22:09.805079 calculating gradient.. 712\n",
      "2021-11-20 08:23:32.404619 updating params.. 712\n",
      "2021-11-20 08:23:32.405580 recording loss.. 712\n",
      "2021-11-20 08:23:32.406880 start 713\n",
      "2021-11-20 08:23:32.407581 calculating gradient.. 713\n",
      "2021-11-20 08:24:54.199128 updating params.. 713\n",
      "2021-11-20 08:24:54.200104 recording loss.. 713\n",
      "2021-11-20 08:24:54.201745 start 714\n",
      "2021-11-20 08:24:54.202606 calculating gradient.. 714\n",
      "2021-11-20 08:26:01.876966 updating params.. 714\n",
      "2021-11-20 08:26:01.877920 recording loss.. 714\n",
      "2021-11-20 08:26:01.879207 start 715\n",
      "2021-11-20 08:26:01.879952 calculating gradient.. 715\n",
      "2021-11-20 08:27:04.162937 updating params.. 715\n",
      "2021-11-20 08:27:04.163873 recording loss.. 715\n",
      "2021-11-20 08:27:04.165072 start 716\n",
      "2021-11-20 08:27:04.165747 calculating gradient.. 716\n",
      "2021-11-20 08:28:06.600894 updating params.. 716\n",
      "2021-11-20 08:28:06.601951 recording loss.. 716\n",
      "2021-11-20 08:28:06.603370 start 717\n",
      "2021-11-20 08:28:06.604235 calculating gradient.. 717\n",
      "2021-11-20 08:29:09.193118 updating params.. 717\n",
      "2021-11-20 08:29:09.194065 recording loss.. 717\n",
      "2021-11-20 08:29:09.195275 start 718\n",
      "2021-11-20 08:29:09.195987 calculating gradient.. 718\n",
      "2021-11-20 08:30:12.273013 updating params.. 718\n",
      "2021-11-20 08:30:12.273974 recording loss.. 718\n",
      "2021-11-20 08:30:12.275195 start 719\n",
      "2021-11-20 08:30:12.275824 calculating gradient.. 719\n",
      "2021-11-20 08:31:14.314550 updating params.. 719\n",
      "2021-11-20 08:31:14.315502 recording loss.. 719\n",
      "2021-11-20 08:31:14.316699 start 720\n",
      "2021-11-20 08:31:14.317405 calculating gradient.. 720\n",
      "2021-11-20 08:32:16.476020 updating params.. 720\n",
      "2021-11-20 08:32:16.477018 recording loss.. 720\n",
      "train acc, test acc | 0.8301833333333334,0.8332\n",
      "2021-11-20 08:32:17.163252 start 721\n",
      "2021-11-20 08:32:17.164070 calculating gradient.. 721\n",
      "2021-11-20 08:33:19.613805 updating params.. 721\n",
      "2021-11-20 08:33:19.614781 recording loss.. 721\n",
      "2021-11-20 08:33:19.616064 start 722\n",
      "2021-11-20 08:33:19.616785 calculating gradient.. 722\n",
      "2021-11-20 08:34:21.788463 updating params.. 722\n",
      "2021-11-20 08:34:21.789403 recording loss.. 722\n",
      "2021-11-20 08:34:21.790682 start 723\n",
      "2021-11-20 08:34:21.791368 calculating gradient.. 723\n",
      "2021-11-20 08:35:24.652757 updating params.. 723\n",
      "2021-11-20 08:35:24.653708 recording loss.. 723\n",
      "2021-11-20 08:35:24.654992 start 724\n",
      "2021-11-20 08:35:24.655697 calculating gradient.. 724\n",
      "2021-11-20 08:36:26.525262 updating params.. 724\n",
      "2021-11-20 08:36:26.526175 recording loss.. 724\n",
      "2021-11-20 08:36:26.527433 start 725\n",
      "2021-11-20 08:36:26.528110 calculating gradient.. 725\n",
      "2021-11-20 08:37:28.563939 updating params.. 725\n",
      "2021-11-20 08:37:28.564876 recording loss.. 725\n",
      "2021-11-20 08:37:28.566443 start 726\n",
      "2021-11-20 08:37:28.567187 calculating gradient.. 726\n",
      "2021-11-20 08:38:30.880231 updating params.. 726\n",
      "2021-11-20 08:38:30.881175 recording loss.. 726\n",
      "2021-11-20 08:38:30.882515 start 727\n",
      "2021-11-20 08:38:30.883239 calculating gradient.. 727\n",
      "2021-11-20 08:39:33.450552 updating params.. 727\n",
      "2021-11-20 08:39:33.451490 recording loss.. 727\n",
      "2021-11-20 08:39:33.452813 start 728\n",
      "2021-11-20 08:39:33.453557 calculating gradient.. 728\n",
      "2021-11-20 08:40:35.719835 updating params.. 728\n",
      "2021-11-20 08:40:35.720881 recording loss.. 728\n",
      "2021-11-20 08:40:35.722711 start 729\n",
      "2021-11-20 08:40:35.723621 calculating gradient.. 729\n",
      "2021-11-20 08:41:38.383911 updating params.. 729\n",
      "2021-11-20 08:41:38.384903 recording loss.. 729\n",
      "2021-11-20 08:41:38.386220 start 730\n",
      "2021-11-20 08:41:38.386930 calculating gradient.. 730\n",
      "2021-11-20 08:42:40.276939 updating params.. 730\n",
      "2021-11-20 08:42:40.277897 recording loss.. 730\n",
      "train acc, test acc | 0.8321,0.8347\n",
      "2021-11-20 08:42:40.835583 start 731\n",
      "2021-11-20 08:42:40.836352 calculating gradient.. 731\n",
      "2021-11-20 08:43:43.440889 updating params.. 731\n",
      "2021-11-20 08:43:43.441861 recording loss.. 731\n",
      "2021-11-20 08:43:43.443167 start 732\n",
      "2021-11-20 08:43:43.443934 calculating gradient.. 732\n",
      "2021-11-20 08:44:46.153122 updating params.. 732\n",
      "2021-11-20 08:44:46.154093 recording loss.. 732\n",
      "2021-11-20 08:44:46.155396 start 733\n",
      "2021-11-20 08:44:46.156151 calculating gradient.. 733\n",
      "2021-11-20 08:45:48.619954 updating params.. 733\n",
      "2021-11-20 08:45:48.620893 recording loss.. 733\n",
      "2021-11-20 08:45:48.622192 start 734\n",
      "2021-11-20 08:45:48.622905 calculating gradient.. 734\n",
      "2021-11-20 08:46:57.899931 updating params.. 734\n",
      "2021-11-20 08:46:57.900956 recording loss.. 734\n",
      "2021-11-20 08:46:57.902755 start 735\n",
      "2021-11-20 08:46:57.904208 calculating gradient.. 735\n",
      "2021-11-20 08:48:14.064476 updating params.. 735\n",
      "2021-11-20 08:48:14.065459 recording loss.. 735\n",
      "2021-11-20 08:48:14.066873 start 736\n",
      "2021-11-20 08:48:14.067883 calculating gradient.. 736\n",
      "2021-11-20 08:49:26.738669 updating params.. 736\n",
      "2021-11-20 08:49:26.740097 recording loss.. 736\n",
      "2021-11-20 08:49:26.742085 start 737\n",
      "2021-11-20 08:49:26.742793 calculating gradient.. 737\n",
      "2021-11-20 08:50:39.573804 updating params.. 737\n",
      "2021-11-20 08:50:39.574711 recording loss.. 737\n",
      "2021-11-20 08:50:39.575933 start 738\n",
      "2021-11-20 08:50:39.576572 calculating gradient.. 738\n",
      "2021-11-20 08:51:52.452030 updating params.. 738\n",
      "2021-11-20 08:51:52.453006 recording loss.. 738\n",
      "2021-11-20 08:51:52.454336 start 739\n",
      "2021-11-20 08:51:52.455064 calculating gradient.. 739\n",
      "2021-11-20 08:53:05.273488 updating params.. 739\n",
      "2021-11-20 08:53:05.274597 recording loss.. 739\n",
      "2021-11-20 08:53:05.276235 start 740\n",
      "2021-11-20 08:53:05.277050 calculating gradient.. 740\n",
      "2021-11-20 08:54:13.465739 updating params.. 740\n",
      "2021-11-20 08:54:13.466704 recording loss.. 740\n",
      "train acc, test acc | 0.8301833333333334,0.8333\n",
      "2021-11-20 08:54:14.093773 start 741\n",
      "2021-11-20 08:54:14.094867 calculating gradient.. 741\n",
      "2021-11-20 08:55:22.478517 updating params.. 741\n",
      "2021-11-20 08:55:22.479526 recording loss.. 741\n",
      "2021-11-20 08:55:22.480762 start 742\n",
      "2021-11-20 08:55:22.481437 calculating gradient.. 742\n",
      "2021-11-20 08:56:31.761524 updating params.. 742\n",
      "2021-11-20 08:56:31.762476 recording loss.. 742\n",
      "2021-11-20 08:56:31.763690 start 743\n",
      "2021-11-20 08:56:31.764362 calculating gradient.. 743\n",
      "2021-11-20 08:57:43.289085 updating params.. 743\n",
      "2021-11-20 08:57:43.290822 recording loss.. 743\n",
      "2021-11-20 08:57:43.293138 start 744\n",
      "2021-11-20 08:57:43.294255 calculating gradient.. 744\n",
      "2021-11-20 08:58:51.561783 updating params.. 744\n",
      "2021-11-20 08:58:51.562721 recording loss.. 744\n",
      "2021-11-20 08:58:51.564073 start 745\n",
      "2021-11-20 08:58:51.564814 calculating gradient.. 745\n",
      "2021-11-20 09:00:00.665065 updating params.. 745\n",
      "2021-11-20 09:00:00.665994 recording loss.. 745\n",
      "2021-11-20 09:00:00.667188 start 746\n",
      "2021-11-20 09:00:00.667833 calculating gradient.. 746\n",
      "2021-11-20 09:01:08.409202 updating params.. 746\n",
      "2021-11-20 09:01:08.410126 recording loss.. 746\n",
      "2021-11-20 09:01:08.411337 start 747\n",
      "2021-11-20 09:01:08.411976 calculating gradient.. 747\n",
      "2021-11-20 09:02:45.880893 updating params.. 747\n",
      "2021-11-20 09:02:45.882015 recording loss.. 747\n",
      "2021-11-20 09:02:45.883765 start 748\n",
      "2021-11-20 09:02:45.884587 calculating gradient.. 748\n",
      "2021-11-20 09:04:04.544997 updating params.. 748\n",
      "2021-11-20 09:04:04.546022 recording loss.. 748\n",
      "2021-11-20 09:04:04.547323 start 749\n",
      "2021-11-20 09:04:04.547975 calculating gradient.. 749\n",
      "2021-11-20 09:05:07.463566 updating params.. 749\n",
      "2021-11-20 09:05:07.464518 recording loss.. 749\n",
      "2021-11-20 09:05:07.465812 start 750\n",
      "2021-11-20 09:05:07.466516 calculating gradient.. 750\n",
      "2021-11-20 09:06:23.438581 updating params.. 750\n",
      "2021-11-20 09:06:23.439524 recording loss.. 750\n",
      "train acc, test acc | 0.8326,0.8377\n",
      "2021-11-20 09:06:24.199680 start 751\n",
      "2021-11-20 09:06:24.200503 calculating gradient.. 751\n",
      "2021-11-20 09:07:30.051056 updating params.. 751\n",
      "2021-11-20 09:07:30.052211 recording loss.. 751\n",
      "2021-11-20 09:07:30.053479 start 752\n",
      "2021-11-20 09:07:30.053899 calculating gradient.. 752\n",
      "2021-11-20 09:08:38.643565 updating params.. 752\n",
      "2021-11-20 09:08:38.644514 recording loss.. 752\n",
      "2021-11-20 09:08:38.645812 start 753\n",
      "2021-11-20 09:08:38.646516 calculating gradient.. 753\n",
      "2021-11-20 09:09:40.283607 updating params.. 753\n",
      "2021-11-20 09:09:40.284552 recording loss.. 753\n",
      "2021-11-20 09:09:40.286111 start 754\n",
      "2021-11-20 09:09:40.286909 calculating gradient.. 754\n",
      "2021-11-20 09:10:56.237575 updating params.. 754\n",
      "2021-11-20 09:10:56.238502 recording loss.. 754\n",
      "2021-11-20 09:10:56.239778 start 755\n",
      "2021-11-20 09:10:56.240486 calculating gradient.. 755\n",
      "2021-11-20 09:12:02.715234 updating params.. 755\n",
      "2021-11-20 09:12:02.716224 recording loss.. 755\n",
      "2021-11-20 09:12:02.717452 start 756\n",
      "2021-11-20 09:12:02.718104 calculating gradient.. 756\n",
      "2021-11-20 09:13:07.197340 updating params.. 756\n",
      "2021-11-20 09:13:07.198844 recording loss.. 756\n",
      "2021-11-20 09:13:07.201472 start 757\n",
      "2021-11-20 09:13:07.203230 calculating gradient.. 757\n",
      "2021-11-20 09:14:10.074124 updating params.. 757\n",
      "2021-11-20 09:14:10.075161 recording loss.. 757\n",
      "2021-11-20 09:14:10.076393 start 758\n",
      "2021-11-20 09:14:10.077039 calculating gradient.. 758\n",
      "2021-11-20 09:15:24.027122 updating params.. 758\n",
      "2021-11-20 09:15:24.028146 recording loss.. 758\n",
      "2021-11-20 09:15:24.029945 start 759\n",
      "2021-11-20 09:15:24.030773 calculating gradient.. 759\n",
      "2021-11-20 09:16:36.779009 updating params.. 759\n",
      "2021-11-20 09:16:36.780064 recording loss.. 759\n",
      "2021-11-20 09:16:36.782018 start 760\n",
      "2021-11-20 09:16:36.782921 calculating gradient.. 760\n",
      "2021-11-20 09:17:42.771541 updating params.. 760\n",
      "2021-11-20 09:17:42.772490 recording loss.. 760\n",
      "train acc, test acc | 0.8333,0.8379\n",
      "2021-11-20 09:17:43.474213 start 761\n",
      "2021-11-20 09:17:43.475391 calculating gradient.. 761\n",
      "2021-11-20 09:18:42.971722 updating params.. 761\n",
      "2021-11-20 09:18:42.972664 recording loss.. 761\n",
      "2021-11-20 09:18:42.973964 start 762\n",
      "2021-11-20 09:18:42.974685 calculating gradient.. 762\n",
      "2021-11-20 09:19:43.781746 updating params.. 762\n",
      "2021-11-20 09:19:43.782637 recording loss.. 762\n",
      "2021-11-20 09:19:43.784234 start 763\n",
      "2021-11-20 09:19:43.784902 calculating gradient.. 763\n",
      "2021-11-20 09:20:43.806558 updating params.. 763\n",
      "2021-11-20 09:20:43.807589 recording loss.. 763\n",
      "2021-11-20 09:20:43.808803 start 764\n",
      "2021-11-20 09:20:43.809470 calculating gradient.. 764\n",
      "2021-11-20 09:21:43.897574 updating params.. 764\n",
      "2021-11-20 09:21:43.898519 recording loss.. 764\n",
      "2021-11-20 09:21:43.899799 start 765\n",
      "2021-11-20 09:21:43.900495 calculating gradient.. 765\n",
      "2021-11-20 09:22:44.212939 updating params.. 765\n",
      "2021-11-20 09:22:44.213876 recording loss.. 765\n",
      "2021-11-20 09:22:44.215094 start 766\n",
      "2021-11-20 09:22:44.215688 calculating gradient.. 766\n",
      "2021-11-20 09:23:43.745491 updating params.. 766\n",
      "2021-11-20 09:23:43.746424 recording loss.. 766\n",
      "2021-11-20 09:23:43.747697 start 767\n",
      "2021-11-20 09:23:43.748388 calculating gradient.. 767\n",
      "2021-11-20 09:24:43.426914 updating params.. 767\n",
      "2021-11-20 09:24:43.427875 recording loss.. 767\n",
      "2021-11-20 09:24:43.429187 start 768\n",
      "2021-11-20 09:24:43.429904 calculating gradient.. 768\n",
      "2021-11-20 09:25:43.110813 updating params.. 768\n",
      "2021-11-20 09:25:43.111867 recording loss.. 768\n",
      "2021-11-20 09:25:43.113151 start 769\n",
      "2021-11-20 09:25:43.113815 calculating gradient.. 769\n",
      "2021-11-20 09:26:42.626538 updating params.. 769\n",
      "2021-11-20 09:26:42.627483 recording loss.. 769\n",
      "2021-11-20 09:26:42.628754 start 770\n",
      "2021-11-20 09:26:42.629457 calculating gradient.. 770\n",
      "2021-11-20 09:27:42.180735 updating params.. 770\n",
      "2021-11-20 09:27:42.181690 recording loss.. 770\n",
      "train acc, test acc | 0.8347666666666667,0.8378\n",
      "2021-11-20 09:27:42.831730 start 771\n",
      "2021-11-20 09:27:42.832496 calculating gradient.. 771\n",
      "2021-11-20 09:28:42.587601 updating params.. 771\n",
      "2021-11-20 09:28:42.588565 recording loss.. 771\n",
      "2021-11-20 09:28:42.589868 start 772\n",
      "2021-11-20 09:28:42.590566 calculating gradient.. 772\n",
      "2021-11-20 09:29:42.508616 updating params.. 772\n",
      "2021-11-20 09:29:42.509579 recording loss.. 772\n",
      "2021-11-20 09:29:42.510860 start 773\n",
      "2021-11-20 09:29:42.511555 calculating gradient.. 773\n",
      "2021-11-20 09:30:41.902005 updating params.. 773\n",
      "2021-11-20 09:30:41.902953 recording loss.. 773\n",
      "2021-11-20 09:30:41.904240 start 774\n",
      "2021-11-20 09:30:41.904969 calculating gradient.. 774\n",
      "2021-11-20 09:31:41.724533 updating params.. 774\n",
      "2021-11-20 09:31:41.725503 recording loss.. 774\n",
      "2021-11-20 09:31:41.726799 start 775\n",
      "2021-11-20 09:31:41.727498 calculating gradient.. 775\n",
      "2021-11-20 09:32:41.616694 updating params.. 775\n",
      "2021-11-20 09:32:41.617756 recording loss.. 775\n",
      "2021-11-20 09:32:41.619269 start 776\n",
      "2021-11-20 09:32:41.619734 calculating gradient.. 776\n",
      "2021-11-20 09:33:41.478744 updating params.. 776\n",
      "2021-11-20 09:33:41.479681 recording loss.. 776\n",
      "2021-11-20 09:33:41.480956 start 777\n",
      "2021-11-20 09:33:41.481665 calculating gradient.. 777\n",
      "2021-11-20 09:34:41.418508 updating params.. 777\n",
      "2021-11-20 09:34:41.419420 recording loss.. 777\n",
      "2021-11-20 09:34:41.420624 start 778\n",
      "2021-11-20 09:34:41.421278 calculating gradient.. 778\n",
      "2021-11-20 09:35:40.928473 updating params.. 778\n",
      "2021-11-20 09:35:40.929442 recording loss.. 778\n",
      "2021-11-20 09:35:40.930646 start 779\n",
      "2021-11-20 09:35:40.931287 calculating gradient.. 779\n",
      "2021-11-20 09:36:40.390895 updating params.. 779\n",
      "2021-11-20 09:36:40.391810 recording loss.. 779\n",
      "2021-11-20 09:36:40.393012 start 780\n",
      "2021-11-20 09:36:40.393814 calculating gradient.. 780\n",
      "2021-11-20 09:37:39.906983 updating params.. 780\n",
      "2021-11-20 09:37:39.907924 recording loss.. 780\n",
      "train acc, test acc | 0.8365,0.8404\n",
      "2021-11-20 09:37:40.467859 start 781\n",
      "2021-11-20 09:37:40.468892 calculating gradient.. 781\n",
      "2021-11-20 09:38:40.088166 updating params.. 781\n",
      "2021-11-20 09:38:40.089124 recording loss.. 781\n",
      "2021-11-20 09:38:40.090425 start 782\n",
      "2021-11-20 09:38:40.091140 calculating gradient.. 782\n",
      "2021-11-20 09:39:40.267118 updating params.. 782\n",
      "2021-11-20 09:39:40.268454 recording loss.. 782\n",
      "2021-11-20 09:39:40.269727 start 783\n",
      "2021-11-20 09:39:40.270431 calculating gradient.. 783\n",
      "2021-11-20 09:40:39.991196 updating params.. 783\n",
      "2021-11-20 09:40:39.992213 recording loss.. 783\n",
      "2021-11-20 09:40:39.993523 start 784\n",
      "2021-11-20 09:40:39.994233 calculating gradient.. 784\n",
      "2021-11-20 09:41:39.413329 updating params.. 784\n",
      "2021-11-20 09:41:39.414271 recording loss.. 784\n",
      "2021-11-20 09:41:39.415546 start 785\n",
      "2021-11-20 09:41:39.416267 calculating gradient.. 785\n",
      "2021-11-20 09:42:38.824452 updating params.. 785\n",
      "2021-11-20 09:42:38.825450 recording loss.. 785\n",
      "2021-11-20 09:42:38.826701 start 786\n",
      "2021-11-20 09:42:38.827464 calculating gradient.. 786\n",
      "2021-11-20 09:43:38.932208 updating params.. 786\n",
      "2021-11-20 09:43:38.933311 recording loss.. 786\n",
      "2021-11-20 09:43:38.934633 start 787\n",
      "2021-11-20 09:43:38.935358 calculating gradient.. 787\n",
      "2021-11-20 09:44:39.040705 updating params.. 787\n",
      "2021-11-20 09:44:39.041668 recording loss.. 787\n",
      "2021-11-20 09:44:39.042900 start 788\n",
      "2021-11-20 09:44:39.043558 calculating gradient.. 788\n",
      "2021-11-20 09:45:38.573441 updating params.. 788\n",
      "2021-11-20 09:45:38.574359 recording loss.. 788\n",
      "2021-11-20 09:45:38.575536 start 789\n",
      "2021-11-20 09:45:38.576188 calculating gradient.. 789\n",
      "2021-11-20 09:46:38.081745 updating params.. 789\n",
      "2021-11-20 09:46:38.082731 recording loss.. 789\n",
      "2021-11-20 09:46:38.083937 start 790\n",
      "2021-11-20 09:46:38.084585 calculating gradient.. 790\n",
      "2021-11-20 09:47:37.856452 updating params.. 790\n",
      "2021-11-20 09:47:37.857447 recording loss.. 790\n",
      "train acc, test acc | 0.8415833333333333,0.8431\n",
      "2021-11-20 09:47:38.400267 start 791\n",
      "2021-11-20 09:47:38.401509 calculating gradient.. 791\n",
      "2021-11-20 09:48:37.813308 updating params.. 791\n",
      "2021-11-20 09:48:37.814246 recording loss.. 791\n",
      "2021-11-20 09:48:37.815527 start 792\n",
      "2021-11-20 09:48:37.816226 calculating gradient.. 792\n",
      "2021-11-20 09:49:37.850810 updating params.. 792\n",
      "2021-11-20 09:49:37.851803 recording loss.. 792\n",
      "2021-11-20 09:49:37.853097 start 793\n",
      "2021-11-20 09:49:37.853839 calculating gradient.. 793\n",
      "2021-11-20 09:50:37.597506 updating params.. 793\n",
      "2021-11-20 09:50:37.598438 recording loss.. 793\n",
      "2021-11-20 09:50:37.599739 start 794\n",
      "2021-11-20 09:50:37.600441 calculating gradient.. 794\n",
      "2021-11-20 09:51:37.347607 updating params.. 794\n",
      "2021-11-20 09:51:37.348568 recording loss.. 794\n",
      "2021-11-20 09:51:37.349864 start 795\n",
      "2021-11-20 09:51:37.350561 calculating gradient.. 795\n",
      "2021-11-20 09:52:37.083254 updating params.. 795\n",
      "2021-11-20 09:52:37.084216 recording loss.. 795\n",
      "2021-11-20 09:52:37.085511 start 796\n",
      "2021-11-20 09:52:37.086229 calculating gradient.. 796\n",
      "2021-11-20 09:53:36.548958 updating params.. 796\n",
      "2021-11-20 09:53:36.549852 recording loss.. 796\n",
      "2021-11-20 09:53:36.551588 start 797\n",
      "2021-11-20 09:53:36.552327 calculating gradient.. 797\n",
      "2021-11-20 09:54:36.362903 updating params.. 797\n",
      "2021-11-20 09:54:36.363925 recording loss.. 797\n",
      "2021-11-20 09:54:36.365601 start 798\n",
      "2021-11-20 09:54:36.366433 calculating gradient.. 798\n",
      "2021-11-20 09:55:36.216223 updating params.. 798\n",
      "2021-11-20 09:55:36.217152 recording loss.. 798\n",
      "2021-11-20 09:55:36.218403 start 799\n",
      "2021-11-20 09:55:36.219053 calculating gradient.. 799\n",
      "2021-11-20 09:56:36.530863 updating params.. 799\n",
      "2021-11-20 09:56:36.531801 recording loss.. 799\n",
      "2021-11-20 09:56:36.533084 start 800\n",
      "2021-11-20 09:56:36.533827 calculating gradient.. 800\n",
      "2021-11-20 09:57:36.251824 updating params.. 800\n",
      "2021-11-20 09:57:36.252745 recording loss.. 800\n",
      "train acc, test acc | 0.8386166666666667,0.8432\n",
      "2021-11-20 09:57:36.789514 start 801\n",
      "2021-11-20 09:57:36.790610 calculating gradient.. 801\n",
      "2021-11-20 09:58:36.366350 updating params.. 801\n",
      "2021-11-20 09:58:36.367324 recording loss.. 801\n",
      "2021-11-20 09:58:36.368929 start 802\n",
      "2021-11-20 09:58:36.369758 calculating gradient.. 802\n",
      "2021-11-20 09:59:36.907220 updating params.. 802\n",
      "2021-11-20 09:59:36.908255 recording loss.. 802\n",
      "2021-11-20 09:59:36.909826 start 803\n",
      "2021-11-20 09:59:36.910578 calculating gradient.. 803\n",
      "2021-11-20 10:00:36.380804 updating params.. 803\n",
      "2021-11-20 10:00:36.381757 recording loss.. 803\n",
      "2021-11-20 10:00:36.383039 start 804\n",
      "2021-11-20 10:00:36.383727 calculating gradient.. 804\n",
      "2021-11-20 10:01:35.820702 updating params.. 804\n",
      "2021-11-20 10:01:35.821652 recording loss.. 804\n",
      "2021-11-20 10:01:35.822940 start 805\n",
      "2021-11-20 10:01:35.823632 calculating gradient.. 805\n",
      "2021-11-20 10:02:56.395569 updating params.. 805\n",
      "2021-11-20 10:02:56.396511 recording loss.. 805\n",
      "2021-11-20 10:02:56.397590 start 806\n",
      "2021-11-20 10:02:56.398241 calculating gradient.. 806\n",
      "2021-11-20 10:03:55.591125 updating params.. 806\n",
      "2021-11-20 10:03:55.592126 recording loss.. 806\n",
      "2021-11-20 10:03:55.593394 start 807\n",
      "2021-11-20 10:03:55.594088 calculating gradient.. 807\n",
      "2021-11-20 10:04:56.057240 updating params.. 807\n",
      "2021-11-20 10:04:56.058178 recording loss.. 807\n",
      "2021-11-20 10:04:56.059455 start 808\n",
      "2021-11-20 10:04:56.060169 calculating gradient.. 808\n",
      "2021-11-20 10:05:55.487884 updating params.. 808\n",
      "2021-11-20 10:05:55.488806 recording loss.. 808\n",
      "2021-11-20 10:05:55.490099 start 809\n",
      "2021-11-20 10:05:55.490793 calculating gradient.. 809\n",
      "2021-11-20 10:06:55.591679 updating params.. 809\n",
      "2021-11-20 10:06:55.592576 recording loss.. 809\n",
      "2021-11-20 10:06:55.593795 start 810\n",
      "2021-11-20 10:06:55.594446 calculating gradient.. 810\n",
      "2021-11-20 10:07:56.114013 updating params.. 810\n",
      "2021-11-20 10:07:56.115028 recording loss.. 810\n",
      "train acc, test acc | 0.8453166666666667,0.8488\n",
      "2021-11-20 10:07:56.662669 start 811\n",
      "2021-11-20 10:07:56.663547 calculating gradient.. 811\n",
      "2021-11-20 10:08:56.328624 updating params.. 811\n",
      "2021-11-20 10:08:56.329678 recording loss.. 811\n",
      "2021-11-20 10:08:56.330988 start 812\n",
      "2021-11-20 10:08:56.331691 calculating gradient.. 812\n",
      "2021-11-20 10:09:56.114314 updating params.. 812\n",
      "2021-11-20 10:09:56.115180 recording loss.. 812\n",
      "2021-11-20 10:09:56.116615 start 813\n",
      "2021-11-20 10:09:56.117333 calculating gradient.. 813\n",
      "2021-11-20 10:10:55.960292 updating params.. 813\n",
      "2021-11-20 10:10:55.961250 recording loss.. 813\n",
      "2021-11-20 10:10:55.962549 start 814\n",
      "2021-11-20 10:10:55.963241 calculating gradient.. 814\n",
      "2021-11-20 10:11:55.425271 updating params.. 814\n",
      "2021-11-20 10:11:55.426203 recording loss.. 814\n",
      "2021-11-20 10:11:55.427472 start 815\n",
      "2021-11-20 10:11:55.428163 calculating gradient.. 815\n",
      "2021-11-20 10:12:55.005693 updating params.. 815\n",
      "2021-11-20 10:12:55.006645 recording loss.. 815\n",
      "2021-11-20 10:12:55.007935 start 816\n",
      "2021-11-20 10:12:55.008625 calculating gradient.. 816\n",
      "2021-11-20 10:13:54.445921 updating params.. 816\n",
      "2021-11-20 10:13:54.446859 recording loss.. 816\n",
      "2021-11-20 10:13:54.448142 start 817\n",
      "2021-11-20 10:13:54.448841 calculating gradient.. 817\n",
      "2021-11-20 10:14:54.098634 updating params.. 817\n",
      "2021-11-20 10:14:54.099569 recording loss.. 817\n",
      "2021-11-20 10:14:54.100790 start 818\n",
      "2021-11-20 10:14:54.101461 calculating gradient.. 818\n",
      "2021-11-20 10:15:53.546224 updating params.. 818\n",
      "2021-11-20 10:15:53.547154 recording loss.. 818\n",
      "2021-11-20 10:15:53.548430 start 819\n",
      "2021-11-20 10:15:53.549147 calculating gradient.. 819\n",
      "2021-11-20 10:16:53.493628 updating params.. 819\n",
      "2021-11-20 10:16:53.494562 recording loss.. 819\n",
      "2021-11-20 10:16:53.495869 start 820\n",
      "2021-11-20 10:16:53.496581 calculating gradient.. 820\n",
      "2021-11-20 10:17:52.666278 updating params.. 820\n",
      "2021-11-20 10:17:52.667263 recording loss.. 820\n",
      "train acc, test acc | 0.83985,0.8445\n",
      "2021-11-20 10:17:53.200370 start 821\n",
      "2021-11-20 10:17:53.201418 calculating gradient.. 821\n",
      "2021-11-20 10:18:51.768604 updating params.. 821\n",
      "2021-11-20 10:18:51.769624 recording loss.. 821\n",
      "2021-11-20 10:18:51.770692 start 822\n",
      "2021-11-20 10:18:51.771380 calculating gradient.. 822\n",
      "2021-11-20 10:19:51.291292 updating params.. 822\n",
      "2021-11-20 10:19:51.293028 recording loss.. 822\n",
      "2021-11-20 10:19:51.294405 start 823\n",
      "2021-11-20 10:19:51.295111 calculating gradient.. 823\n",
      "2021-11-20 10:20:50.668495 updating params.. 823\n",
      "2021-11-20 10:20:50.669444 recording loss.. 823\n",
      "2021-11-20 10:20:50.670730 start 824\n",
      "2021-11-20 10:20:50.671426 calculating gradient.. 824\n",
      "2021-11-20 10:21:49.257364 updating params.. 824\n",
      "2021-11-20 10:21:49.258374 recording loss.. 824\n",
      "2021-11-20 10:21:49.259441 start 825\n",
      "2021-11-20 10:21:49.260098 calculating gradient.. 825\n",
      "2021-11-20 10:22:48.277380 updating params.. 825\n",
      "2021-11-20 10:22:48.278261 recording loss.. 825\n",
      "2021-11-20 10:22:48.279472 start 826\n",
      "2021-11-20 10:22:48.280118 calculating gradient.. 826\n",
      "2021-11-20 10:23:47.157815 updating params.. 826\n",
      "2021-11-20 10:23:47.158731 recording loss.. 826\n",
      "2021-11-20 10:23:47.160044 start 827\n",
      "2021-11-20 10:23:47.160694 calculating gradient.. 827\n",
      "2021-11-20 10:24:45.938938 updating params.. 827\n",
      "2021-11-20 10:24:45.939886 recording loss.. 827\n",
      "2021-11-20 10:24:45.941166 start 828\n",
      "2021-11-20 10:24:45.941879 calculating gradient.. 828\n",
      "2021-11-20 10:25:45.596068 updating params.. 828\n",
      "2021-11-20 10:25:45.597023 recording loss.. 828\n",
      "2021-11-20 10:25:45.598295 start 829\n",
      "2021-11-20 10:25:45.598940 calculating gradient.. 829\n",
      "2021-11-20 10:26:44.846634 updating params.. 829\n",
      "2021-11-20 10:26:44.847568 recording loss.. 829\n",
      "2021-11-20 10:26:44.848865 start 830\n",
      "2021-11-20 10:26:44.849601 calculating gradient.. 830\n",
      "2021-11-20 10:27:43.524064 updating params.. 830\n",
      "2021-11-20 10:27:43.525004 recording loss.. 830\n",
      "train acc, test acc | 0.8450833333333333,0.8481\n",
      "2021-11-20 10:27:44.050422 start 831\n",
      "2021-11-20 10:27:44.051491 calculating gradient.. 831\n",
      "2021-11-20 10:28:42.972902 updating params.. 831\n",
      "2021-11-20 10:28:42.973843 recording loss.. 831\n",
      "2021-11-20 10:28:42.975125 start 832\n",
      "2021-11-20 10:28:42.975819 calculating gradient.. 832\n",
      "2021-11-20 10:29:43.318331 updating params.. 832\n",
      "2021-11-20 10:29:43.319264 recording loss.. 832\n",
      "2021-11-20 10:29:43.320547 start 833\n",
      "2021-11-20 10:29:43.321254 calculating gradient.. 833\n",
      "2021-11-20 10:30:42.050731 updating params.. 833\n",
      "2021-11-20 10:30:42.051663 recording loss.. 833\n",
      "2021-11-20 10:30:42.052912 start 834\n",
      "2021-11-20 10:30:42.053588 calculating gradient.. 834\n",
      "2021-11-20 10:31:40.634744 updating params.. 834\n",
      "2021-11-20 10:31:40.635667 recording loss.. 834\n",
      "2021-11-20 10:31:40.636941 start 835\n",
      "2021-11-20 10:31:40.637655 calculating gradient.. 835\n",
      "2021-11-20 10:32:39.471009 updating params.. 835\n",
      "2021-11-20 10:32:39.471959 recording loss.. 835\n",
      "2021-11-20 10:32:39.473204 start 836\n",
      "2021-11-20 10:32:39.473851 calculating gradient.. 836\n",
      "2021-11-20 10:33:38.014581 updating params.. 836\n",
      "2021-11-20 10:33:38.015499 recording loss.. 836\n",
      "2021-11-20 10:33:38.016710 start 837\n",
      "2021-11-20 10:33:38.017371 calculating gradient.. 837\n",
      "2021-11-20 10:34:37.066046 updating params.. 837\n",
      "2021-11-20 10:34:37.066987 recording loss.. 837\n",
      "2021-11-20 10:34:37.068265 start 838\n",
      "2021-11-20 10:34:37.068961 calculating gradient.. 838\n",
      "2021-11-20 10:35:36.005611 updating params.. 838\n",
      "2021-11-20 10:35:36.006540 recording loss.. 838\n",
      "2021-11-20 10:35:36.007820 start 839\n",
      "2021-11-20 10:35:36.008516 calculating gradient.. 839\n",
      "2021-11-20 10:36:34.680289 updating params.. 839\n",
      "2021-11-20 10:36:34.681239 recording loss.. 839\n",
      "2021-11-20 10:36:34.682522 start 840\n",
      "2021-11-20 10:36:34.683217 calculating gradient.. 840\n",
      "2021-11-20 10:37:33.857210 updating params.. 840\n",
      "2021-11-20 10:37:33.858124 recording loss.. 840\n",
      "train acc, test acc | 0.8438,0.8495\n",
      "2021-11-20 10:37:34.394991 start 841\n",
      "2021-11-20 10:37:34.396124 calculating gradient.. 841\n",
      "2021-11-20 10:38:33.077041 updating params.. 841\n",
      "2021-11-20 10:38:33.078098 recording loss.. 841\n",
      "2021-11-20 10:38:33.079664 start 842\n",
      "2021-11-20 10:38:33.080485 calculating gradient.. 842\n",
      "2021-11-20 10:39:32.684359 updating params.. 842\n",
      "2021-11-20 10:39:32.685324 recording loss.. 842\n",
      "2021-11-20 10:39:32.686528 start 843\n",
      "2021-11-20 10:39:32.687180 calculating gradient.. 843\n",
      "2021-11-20 10:40:31.647975 updating params.. 843\n",
      "2021-11-20 10:40:31.648920 recording loss.. 843\n",
      "2021-11-20 10:40:31.650218 start 844\n",
      "2021-11-20 10:40:31.650912 calculating gradient.. 844\n",
      "2021-11-20 10:41:30.545059 updating params.. 844\n",
      "2021-11-20 10:41:30.546014 recording loss.. 844\n",
      "2021-11-20 10:41:30.547259 start 845\n",
      "2021-11-20 10:41:30.547909 calculating gradient.. 845\n",
      "2021-11-20 10:42:29.232827 updating params.. 845\n",
      "2021-11-20 10:42:29.233770 recording loss.. 845\n",
      "2021-11-20 10:42:29.235122 start 846\n",
      "2021-11-20 10:42:29.235815 calculating gradient.. 846\n",
      "2021-11-20 10:43:28.065931 updating params.. 846\n",
      "2021-11-20 10:43:28.066885 recording loss.. 846\n",
      "2021-11-20 10:43:28.068175 start 847\n",
      "2021-11-20 10:43:28.068874 calculating gradient.. 847\n",
      "2021-11-20 10:44:27.073260 updating params.. 847\n",
      "2021-11-20 10:44:27.074191 recording loss.. 847\n",
      "2021-11-20 10:44:27.075402 start 848\n",
      "2021-11-20 10:44:27.076051 calculating gradient.. 848\n",
      "2021-11-20 10:45:25.779945 updating params.. 848\n",
      "2021-11-20 10:45:25.780880 recording loss.. 848\n",
      "2021-11-20 10:45:25.782172 start 849\n",
      "2021-11-20 10:45:25.782869 calculating gradient.. 849\n",
      "2021-11-20 10:46:24.511959 updating params.. 849\n",
      "2021-11-20 10:46:24.512891 recording loss.. 849\n",
      "2021-11-20 10:46:24.514229 start 850\n",
      "2021-11-20 10:46:24.514935 calculating gradient.. 850\n",
      "2021-11-20 10:47:23.626250 updating params.. 850\n",
      "2021-11-20 10:47:23.627187 recording loss.. 850\n",
      "train acc, test acc | 0.8438666666666667,0.8494\n",
      "2021-11-20 10:47:24.158124 start 851\n",
      "2021-11-20 10:47:24.159171 calculating gradient.. 851\n",
      "2021-11-20 10:48:22.925343 updating params.. 851\n",
      "2021-11-20 10:48:22.926276 recording loss.. 851\n",
      "2021-11-20 10:48:22.927553 start 852\n",
      "2021-11-20 10:48:22.928245 calculating gradient.. 852\n",
      "2021-11-20 10:49:21.429383 updating params.. 852\n",
      "2021-11-20 10:49:21.430328 recording loss.. 852\n",
      "2021-11-20 10:49:21.431608 start 853\n",
      "2021-11-20 10:49:21.432391 calculating gradient.. 853\n",
      "2021-11-20 10:50:20.876486 updating params.. 853\n",
      "2021-11-20 10:50:20.877547 recording loss.. 853\n",
      "2021-11-20 10:50:20.878626 start 854\n",
      "2021-11-20 10:50:20.879274 calculating gradient.. 854\n",
      "2021-11-20 10:51:19.898408 updating params.. 854\n",
      "2021-11-20 10:51:19.899455 recording loss.. 854\n",
      "2021-11-20 10:51:19.900733 start 855\n",
      "2021-11-20 10:51:19.901423 calculating gradient.. 855\n",
      "2021-11-20 10:52:18.578135 updating params.. 855\n",
      "2021-11-20 10:52:18.579058 recording loss.. 855\n",
      "2021-11-20 10:52:18.580272 start 856\n",
      "2021-11-20 10:52:18.580910 calculating gradient.. 856\n",
      "2021-11-20 10:53:17.502270 updating params.. 856\n",
      "2021-11-20 10:53:17.503322 recording loss.. 856\n",
      "2021-11-20 10:53:17.504528 start 857\n",
      "2021-11-20 10:53:17.505011 calculating gradient.. 857\n",
      "2021-11-20 10:54:16.257463 updating params.. 857\n",
      "2021-11-20 10:54:16.258398 recording loss.. 857\n",
      "2021-11-20 10:54:16.259624 start 858\n",
      "2021-11-20 10:54:16.260358 calculating gradient.. 858\n",
      "2021-11-20 10:55:15.292377 updating params.. 858\n",
      "2021-11-20 10:55:15.293268 recording loss.. 858\n",
      "2021-11-20 10:55:15.294988 start 859\n",
      "2021-11-20 10:55:15.295670 calculating gradient.. 859\n",
      "2021-11-20 10:56:14.946668 updating params.. 859\n",
      "2021-11-20 10:56:14.947581 recording loss.. 859\n",
      "2021-11-20 10:56:14.948817 start 860\n",
      "2021-11-20 10:56:14.949482 calculating gradient.. 860\n",
      "2021-11-20 10:57:13.764287 updating params.. 860\n",
      "2021-11-20 10:57:13.765217 recording loss.. 860\n",
      "train acc, test acc | 0.8415333333333334,0.8467\n",
      "2021-11-20 10:57:14.295075 start 861\n",
      "2021-11-20 10:57:14.295882 calculating gradient.. 861\n",
      "2021-11-20 10:58:13.192234 updating params.. 861\n",
      "2021-11-20 10:58:13.193177 recording loss.. 861\n",
      "2021-11-20 10:58:13.194473 start 862\n",
      "2021-11-20 10:58:13.195172 calculating gradient.. 862\n",
      "2021-11-20 10:59:12.060665 updating params.. 862\n",
      "2021-11-20 10:59:12.061688 recording loss.. 862\n",
      "2021-11-20 10:59:12.062944 start 863\n",
      "2021-11-20 10:59:12.063640 calculating gradient.. 863\n",
      "2021-11-20 11:00:11.917048 updating params.. 863\n",
      "2021-11-20 11:00:11.918030 recording loss.. 863\n",
      "2021-11-20 11:00:11.919264 start 864\n",
      "2021-11-20 11:00:11.919918 calculating gradient.. 864\n",
      "2021-11-20 11:01:10.684756 updating params.. 864\n",
      "2021-11-20 11:01:10.685706 recording loss.. 864\n",
      "2021-11-20 11:01:10.686993 start 865\n",
      "2021-11-20 11:01:10.687711 calculating gradient.. 865\n",
      "2021-11-20 11:02:15.845503 updating params.. 865\n",
      "2021-11-20 11:02:15.846625 recording loss.. 865\n",
      "2021-11-20 11:02:15.848516 start 866\n",
      "2021-11-20 11:02:15.849405 calculating gradient.. 866\n",
      "2021-11-20 11:03:29.238301 updating params.. 866\n",
      "2021-11-20 11:03:29.239214 recording loss.. 866\n",
      "2021-11-20 11:03:29.240474 start 867\n",
      "2021-11-20 11:03:29.241140 calculating gradient.. 867\n",
      "2021-11-20 11:04:28.259237 updating params.. 867\n",
      "2021-11-20 11:04:28.260171 recording loss.. 867\n",
      "2021-11-20 11:04:28.261429 start 868\n",
      "2021-11-20 11:04:28.262090 calculating gradient.. 868\n",
      "2021-11-20 11:05:27.353034 updating params.. 868\n",
      "2021-11-20 11:05:27.353977 recording loss.. 868\n",
      "2021-11-20 11:05:27.355213 start 869\n",
      "2021-11-20 11:05:27.355877 calculating gradient.. 869\n",
      "2021-11-20 11:06:26.429241 updating params.. 869\n",
      "2021-11-20 11:06:26.430177 recording loss.. 869\n",
      "2021-11-20 11:06:26.431529 start 870\n",
      "2021-11-20 11:06:26.432223 calculating gradient.. 870\n",
      "2021-11-20 11:07:25.217492 updating params.. 870\n",
      "2021-11-20 11:07:25.218428 recording loss.. 870\n",
      "train acc, test acc | 0.8482333333333333,0.8518\n",
      "2021-11-20 11:07:25.752336 start 871\n",
      "2021-11-20 11:07:25.753482 calculating gradient.. 871\n",
      "2021-11-20 11:08:24.791910 updating params.. 871\n",
      "2021-11-20 11:08:24.792844 recording loss.. 871\n",
      "2021-11-20 11:08:24.794157 start 872\n",
      "2021-11-20 11:08:24.794922 calculating gradient.. 872\n",
      "2021-11-20 11:09:35.222869 updating params.. 872\n",
      "2021-11-20 11:09:35.223795 recording loss.. 872\n",
      "2021-11-20 11:09:35.225073 start 873\n",
      "2021-11-20 11:09:35.225779 calculating gradient.. 873\n",
      "2021-11-20 11:10:33.954770 updating params.. 873\n",
      "2021-11-20 11:10:33.955737 recording loss.. 873\n",
      "2021-11-20 11:10:33.957514 start 874\n",
      "2021-11-20 11:10:33.958454 calculating gradient.. 874\n",
      "2021-11-20 11:11:32.860004 updating params.. 874\n",
      "2021-11-20 11:11:32.860943 recording loss.. 874\n",
      "2021-11-20 11:11:32.862287 start 875\n",
      "2021-11-20 11:11:32.862994 calculating gradient.. 875\n",
      "2021-11-20 11:12:31.596122 updating params.. 875\n",
      "2021-11-20 11:12:31.597071 recording loss.. 875\n",
      "2021-11-20 11:12:31.598347 start 876\n",
      "2021-11-20 11:12:31.599001 calculating gradient.. 876\n",
      "2021-11-20 11:13:30.603013 updating params.. 876\n",
      "2021-11-20 11:13:30.604038 recording loss.. 876\n",
      "2021-11-20 11:13:30.605252 start 877\n",
      "2021-11-20 11:13:30.605954 calculating gradient.. 877\n",
      "2021-11-20 11:14:29.755572 updating params.. 877\n",
      "2021-11-20 11:14:29.756500 recording loss.. 877\n",
      "2021-11-20 11:14:29.757791 start 878\n",
      "2021-11-20 11:14:29.758489 calculating gradient.. 878\n",
      "2021-11-20 11:15:28.611725 updating params.. 878\n",
      "2021-11-20 11:15:28.612694 recording loss.. 878\n",
      "2021-11-20 11:15:28.614178 start 879\n",
      "2021-11-20 11:15:28.614869 calculating gradient.. 879\n",
      "2021-11-20 11:16:27.333336 updating params.. 879\n",
      "2021-11-20 11:16:27.334269 recording loss.. 879\n",
      "2021-11-20 11:16:27.335547 start 880\n",
      "2021-11-20 11:16:27.336243 calculating gradient.. 880\n",
      "2021-11-20 11:17:26.175769 updating params.. 880\n",
      "2021-11-20 11:17:26.176803 recording loss.. 880\n",
      "train acc, test acc | 0.8522666666666666,0.8553\n",
      "2021-11-20 11:17:26.715741 start 881\n",
      "2021-11-20 11:17:26.716510 calculating gradient.. 881\n",
      "2021-11-20 11:18:25.788631 updating params.. 881\n",
      "2021-11-20 11:18:25.789610 recording loss.. 881\n",
      "2021-11-20 11:18:25.790902 start 882\n",
      "2021-11-20 11:18:25.791621 calculating gradient.. 882\n",
      "2021-11-20 11:19:24.332427 updating params.. 882\n",
      "2021-11-20 11:19:24.333352 recording loss.. 882\n",
      "2021-11-20 11:19:24.334574 start 883\n",
      "2021-11-20 11:19:24.335220 calculating gradient.. 883\n",
      "2021-11-20 11:20:24.507386 updating params.. 883\n",
      "2021-11-20 11:20:24.508330 recording loss.. 883\n",
      "2021-11-20 11:20:24.509658 start 884\n",
      "2021-11-20 11:20:24.510361 calculating gradient.. 884\n",
      "2021-11-20 11:21:23.363558 updating params.. 884\n",
      "2021-11-20 11:21:23.363948 recording loss.. 884\n",
      "2021-11-20 11:21:23.365859 start 885\n",
      "2021-11-20 11:21:23.366574 calculating gradient.. 885\n",
      "2021-11-20 11:22:22.154616 updating params.. 885\n",
      "2021-11-20 11:22:22.155577 recording loss.. 885\n",
      "2021-11-20 11:22:22.156866 start 886\n",
      "2021-11-20 11:22:22.157595 calculating gradient.. 886\n",
      "2021-11-20 11:23:22.044483 updating params.. 886\n",
      "2021-11-20 11:23:22.045435 recording loss.. 886\n",
      "2021-11-20 11:23:22.046646 start 887\n",
      "2021-11-20 11:23:22.047296 calculating gradient.. 887\n",
      "2021-11-20 11:24:20.937892 updating params.. 887\n",
      "2021-11-20 11:24:20.938826 recording loss.. 887\n",
      "2021-11-20 11:24:20.940104 start 888\n",
      "2021-11-20 11:24:20.940889 calculating gradient.. 888\n",
      "2021-11-20 11:25:19.743618 updating params.. 888\n",
      "2021-11-20 11:25:19.744564 recording loss.. 888\n",
      "2021-11-20 11:25:19.745807 start 889\n",
      "2021-11-20 11:25:19.746514 calculating gradient.. 889\n",
      "2021-11-20 11:26:18.754706 updating params.. 889\n",
      "2021-11-20 11:26:18.755609 recording loss.. 889\n",
      "2021-11-20 11:26:18.756845 start 890\n",
      "2021-11-20 11:26:18.757518 calculating gradient.. 890\n",
      "2021-11-20 11:27:17.521663 updating params.. 890\n",
      "2021-11-20 11:27:17.522639 recording loss.. 890\n",
      "train acc, test acc | 0.85285,0.855\n",
      "2021-11-20 11:27:18.053566 start 891\n",
      "2021-11-20 11:27:18.054303 calculating gradient.. 891\n",
      "2021-11-20 11:28:17.233044 updating params.. 891\n",
      "2021-11-20 11:28:17.233966 recording loss.. 891\n",
      "2021-11-20 11:28:17.235219 start 892\n",
      "2021-11-20 11:28:17.235864 calculating gradient.. 892\n",
      "2021-11-20 11:29:15.947253 updating params.. 892\n",
      "2021-11-20 11:29:15.948334 recording loss.. 892\n",
      "2021-11-20 11:29:15.949560 start 893\n",
      "2021-11-20 11:29:15.950208 calculating gradient.. 893\n",
      "2021-11-20 11:30:15.222408 updating params.. 893\n",
      "2021-11-20 11:30:15.223434 recording loss.. 893\n",
      "2021-11-20 11:30:15.224692 start 894\n",
      "2021-11-20 11:30:15.225425 calculating gradient.. 894\n",
      "2021-11-20 11:31:13.956848 updating params.. 894\n",
      "2021-11-20 11:31:13.957799 recording loss.. 894\n",
      "2021-11-20 11:31:13.958880 start 895\n",
      "2021-11-20 11:31:13.959542 calculating gradient.. 895\n",
      "2021-11-20 11:32:13.446760 updating params.. 895\n",
      "2021-11-20 11:32:13.448099 recording loss.. 895\n",
      "2021-11-20 11:32:13.449526 start 896\n",
      "2021-11-20 11:32:13.450280 calculating gradient.. 896\n",
      "2021-11-20 11:33:12.586042 updating params.. 896\n",
      "2021-11-20 11:33:12.587002 recording loss.. 896\n",
      "2021-11-20 11:33:12.588301 start 897\n",
      "2021-11-20 11:33:12.589005 calculating gradient.. 897\n",
      "2021-11-20 11:34:11.228782 updating params.. 897\n",
      "2021-11-20 11:34:11.229737 recording loss.. 897\n",
      "2021-11-20 11:34:11.231041 start 898\n",
      "2021-11-20 11:34:11.231739 calculating gradient.. 898\n",
      "2021-11-20 11:35:10.417749 updating params.. 898\n",
      "2021-11-20 11:35:10.418697 recording loss.. 898\n",
      "2021-11-20 11:35:10.419990 start 899\n",
      "2021-11-20 11:35:10.420716 calculating gradient.. 899\n",
      "2021-11-20 11:36:09.439725 updating params.. 899\n",
      "2021-11-20 11:36:09.440768 recording loss.. 899\n",
      "2021-11-20 11:36:09.442044 start 900\n",
      "2021-11-20 11:36:09.442742 calculating gradient.. 900\n",
      "2021-11-20 11:37:08.318919 updating params.. 900\n",
      "2021-11-20 11:37:08.319898 recording loss.. 900\n",
      "train acc, test acc | 0.8551,0.8584\n",
      "2021-11-20 11:37:08.850338 start 901\n",
      "2021-11-20 11:37:08.851104 calculating gradient.. 901\n",
      "2021-11-20 11:38:08.000206 updating params.. 901\n",
      "2021-11-20 11:38:08.001113 recording loss.. 901\n",
      "2021-11-20 11:38:08.002338 start 902\n",
      "2021-11-20 11:38:08.002976 calculating gradient.. 902\n",
      "2021-11-20 11:39:06.630111 updating params.. 902\n",
      "2021-11-20 11:39:06.631142 recording loss.. 902\n",
      "2021-11-20 11:39:06.632275 start 903\n",
      "2021-11-20 11:39:06.632921 calculating gradient.. 903\n",
      "2021-11-20 11:40:06.126296 updating params.. 903\n",
      "2021-11-20 11:40:06.127240 recording loss.. 903\n",
      "2021-11-20 11:40:06.128521 start 904\n",
      "2021-11-20 11:40:06.129230 calculating gradient.. 904\n",
      "2021-11-20 11:41:04.984812 updating params.. 904\n",
      "2021-11-20 11:41:04.985790 recording loss.. 904\n",
      "2021-11-20 11:41:04.987069 start 905\n",
      "2021-11-20 11:41:04.987744 calculating gradient.. 905\n",
      "2021-11-20 11:42:03.829063 updating params.. 905\n",
      "2021-11-20 11:42:03.830107 recording loss.. 905\n",
      "2021-11-20 11:42:03.832222 start 906\n",
      "2021-11-20 11:42:03.832961 calculating gradient.. 906\n",
      "2021-11-20 11:43:03.259290 updating params.. 906\n",
      "2021-11-20 11:43:03.260340 recording loss.. 906\n",
      "2021-11-20 11:43:03.261686 start 907\n",
      "2021-11-20 11:43:03.262352 calculating gradient.. 907\n",
      "2021-11-20 11:44:02.083142 updating params.. 907\n",
      "2021-11-20 11:44:02.084062 recording loss.. 907\n",
      "2021-11-20 11:44:02.085364 start 908\n",
      "2021-11-20 11:44:02.086019 calculating gradient.. 908\n",
      "2021-11-20 11:45:01.207582 updating params.. 908\n",
      "2021-11-20 11:45:01.208514 recording loss.. 908\n",
      "2021-11-20 11:45:01.209829 start 909\n",
      "2021-11-20 11:45:01.210533 calculating gradient.. 909\n",
      "2021-11-20 11:45:59.950830 updating params.. 909\n",
      "2021-11-20 11:45:59.951786 recording loss.. 909\n",
      "2021-11-20 11:45:59.953069 start 910\n",
      "2021-11-20 11:45:59.953781 calculating gradient.. 910\n",
      "2021-11-20 11:46:58.649560 updating params.. 910\n",
      "2021-11-20 11:46:58.650513 recording loss.. 910\n",
      "train acc, test acc | 0.8574166666666667,0.8617\n",
      "2021-11-20 11:46:59.181173 start 911\n",
      "2021-11-20 11:46:59.182005 calculating gradient.. 911\n",
      "2021-11-20 11:47:58.009836 updating params.. 911\n",
      "2021-11-20 11:47:58.010864 recording loss.. 911\n",
      "2021-11-20 11:47:58.011928 start 912\n",
      "2021-11-20 11:47:58.012636 calculating gradient.. 912\n",
      "2021-11-20 11:48:56.679311 updating params.. 912\n",
      "2021-11-20 11:48:56.680329 recording loss.. 912\n",
      "2021-11-20 11:48:56.681578 start 913\n",
      "2021-11-20 11:48:56.682232 calculating gradient.. 913\n",
      "2021-11-20 11:49:56.097122 updating params.. 913\n",
      "2021-11-20 11:49:56.098172 recording loss.. 913\n",
      "2021-11-20 11:49:56.099439 start 914\n",
      "2021-11-20 11:49:56.101289 calculating gradient.. 914\n",
      "2021-11-20 11:50:55.201797 updating params.. 914\n",
      "2021-11-20 11:50:55.202795 recording loss.. 914\n",
      "2021-11-20 11:50:55.204111 start 915\n",
      "2021-11-20 11:50:55.204790 calculating gradient.. 915\n",
      "2021-11-20 11:51:54.160175 updating params.. 915\n",
      "2021-11-20 11:51:54.161208 recording loss.. 915\n",
      "2021-11-20 11:51:54.162425 start 916\n",
      "2021-11-20 11:51:54.163075 calculating gradient.. 916\n",
      "2021-11-20 11:52:53.481950 updating params.. 916\n",
      "2021-11-20 11:52:53.482852 recording loss.. 916\n",
      "2021-11-20 11:52:53.484055 start 917\n",
      "2021-11-20 11:52:53.484743 calculating gradient.. 917\n",
      "2021-11-20 11:53:52.258487 updating params.. 917\n",
      "2021-11-20 11:53:52.259422 recording loss.. 917\n",
      "2021-11-20 11:53:52.260814 start 918\n",
      "2021-11-20 11:53:52.261506 calculating gradient.. 918\n",
      "2021-11-20 11:54:51.195266 updating params.. 918\n",
      "2021-11-20 11:54:51.196221 recording loss.. 918\n",
      "2021-11-20 11:54:51.197542 start 919\n",
      "2021-11-20 11:54:51.198247 calculating gradient.. 919\n",
      "2021-11-20 11:55:50.424272 updating params.. 919\n",
      "2021-11-20 11:55:50.425219 recording loss.. 919\n",
      "2021-11-20 11:55:50.426499 start 920\n",
      "2021-11-20 11:55:50.427142 calculating gradient.. 920\n",
      "2021-11-20 11:56:49.632451 updating params.. 920\n",
      "2021-11-20 11:56:49.633410 recording loss.. 920\n",
      "train acc, test acc | 0.85775,0.8591\n",
      "2021-11-20 11:56:50.165922 start 921\n",
      "2021-11-20 11:56:50.167018 calculating gradient.. 921\n",
      "2021-11-20 11:57:49.217404 updating params.. 921\n",
      "2021-11-20 11:57:49.218344 recording loss.. 921\n",
      "2021-11-20 11:57:49.219628 start 922\n",
      "2021-11-20 11:57:49.220344 calculating gradient.. 922\n",
      "2021-11-20 11:58:48.129559 updating params.. 922\n",
      "2021-11-20 11:58:48.130487 recording loss.. 922\n",
      "2021-11-20 11:58:48.131736 start 923\n",
      "2021-11-20 11:58:48.132386 calculating gradient.. 923\n",
      "2021-11-20 11:59:47.901603 updating params.. 923\n",
      "2021-11-20 11:59:47.902652 recording loss.. 923\n",
      "2021-11-20 11:59:47.904016 start 924\n",
      "2021-11-20 11:59:47.904747 calculating gradient.. 924\n",
      "2021-11-20 12:00:46.585272 updating params.. 924\n",
      "2021-11-20 12:00:46.586169 recording loss.. 924\n",
      "2021-11-20 12:00:46.587422 start 925\n",
      "2021-11-20 12:00:46.588069 calculating gradient.. 925\n",
      "2021-11-20 12:01:45.458613 updating params.. 925\n",
      "2021-11-20 12:01:45.459694 recording loss.. 925\n",
      "2021-11-20 12:01:45.460916 start 926\n",
      "2021-11-20 12:01:45.461581 calculating gradient.. 926\n",
      "2021-11-20 12:03:04.922798 updating params.. 926\n",
      "2021-11-20 12:03:04.923714 recording loss.. 926\n",
      "2021-11-20 12:03:04.924945 start 927\n",
      "2021-11-20 12:03:04.925616 calculating gradient.. 927\n",
      "2021-11-20 12:04:03.978915 updating params.. 927\n",
      "2021-11-20 12:04:03.979851 recording loss.. 927\n",
      "2021-11-20 12:04:03.981159 start 928\n",
      "2021-11-20 12:04:03.981967 calculating gradient.. 928\n",
      "2021-11-20 12:05:04.836906 updating params.. 928\n",
      "2021-11-20 12:05:04.837856 recording loss.. 928\n",
      "2021-11-20 12:05:04.839084 start 929\n",
      "2021-11-20 12:05:04.839728 calculating gradient.. 929\n",
      "2021-11-20 12:06:03.545491 updating params.. 929\n",
      "2021-11-20 12:06:03.546601 recording loss.. 929\n",
      "2021-11-20 12:06:03.548047 start 930\n",
      "2021-11-20 12:06:03.549334 calculating gradient.. 930\n",
      "2021-11-20 12:07:02.276535 updating params.. 930\n",
      "2021-11-20 12:07:02.277356 recording loss.. 930\n",
      "train acc, test acc | 0.8580666666666666,0.8626\n",
      "2021-11-20 12:07:02.886505 start 931\n",
      "2021-11-20 12:07:02.887591 calculating gradient.. 931\n",
      "2021-11-20 12:08:01.889370 updating params.. 931\n",
      "2021-11-20 12:08:01.890290 recording loss.. 931\n",
      "2021-11-20 12:08:01.891558 start 932\n",
      "2021-11-20 12:08:01.892251 calculating gradient.. 932\n",
      "2021-11-20 12:09:00.980763 updating params.. 932\n",
      "2021-11-20 12:09:00.981707 recording loss.. 932\n",
      "2021-11-20 12:09:00.982985 start 933\n",
      "2021-11-20 12:09:00.983697 calculating gradient.. 933\n",
      "2021-11-20 12:10:06.158918 updating params.. 933\n",
      "2021-11-20 12:10:06.159804 recording loss.. 933\n",
      "2021-11-20 12:10:06.161067 start 934\n",
      "2021-11-20 12:10:06.161733 calculating gradient.. 934\n",
      "2021-11-20 12:11:13.160492 updating params.. 934\n",
      "2021-11-20 12:11:13.161447 recording loss.. 934\n",
      "2021-11-20 12:11:13.162659 start 935\n",
      "2021-11-20 12:11:13.163352 calculating gradient.. 935\n",
      "2021-11-20 12:12:33.930365 updating params.. 935\n",
      "2021-11-20 12:12:33.931305 recording loss.. 935\n",
      "2021-11-20 12:12:33.932596 start 936\n",
      "2021-11-20 12:12:33.933277 calculating gradient.. 936\n",
      "2021-11-20 12:13:58.604319 updating params.. 936\n",
      "2021-11-20 12:13:58.605290 recording loss.. 936\n",
      "2021-11-20 12:13:58.607064 start 937\n",
      "2021-11-20 12:13:58.607525 calculating gradient.. 937\n",
      "2021-11-20 12:15:24.427482 updating params.. 937\n",
      "2021-11-20 12:15:24.429569 recording loss.. 937\n",
      "2021-11-20 12:15:24.431397 start 938\n",
      "2021-11-20 12:15:24.432272 calculating gradient.. 938\n",
      "2021-11-20 12:16:47.525170 updating params.. 938\n",
      "2021-11-20 12:16:47.526116 recording loss.. 938\n",
      "2021-11-20 12:16:47.527466 start 939\n",
      "2021-11-20 12:16:47.528178 calculating gradient.. 939\n",
      "2021-11-20 12:18:00.963144 updating params.. 939\n",
      "2021-11-20 12:18:00.964129 recording loss.. 939\n",
      "2021-11-20 12:18:00.965319 start 940\n",
      "2021-11-20 12:18:00.965969 calculating gradient.. 940\n",
      "2021-11-20 12:19:13.418294 updating params.. 940\n",
      "2021-11-20 12:19:13.419251 recording loss.. 940\n",
      "train acc, test acc | 0.8582,0.8621\n",
      "2021-11-20 12:19:14.333344 start 941\n",
      "2021-11-20 12:19:14.334540 calculating gradient.. 941\n",
      "2021-11-20 12:20:32.961401 updating params.. 941\n",
      "2021-11-20 12:20:32.962362 recording loss.. 941\n",
      "2021-11-20 12:20:32.964239 start 942\n",
      "2021-11-20 12:20:32.964985 calculating gradient.. 942\n",
      "2021-11-20 12:21:46.520340 updating params.. 942\n",
      "2021-11-20 12:21:46.521335 recording loss.. 942\n",
      "2021-11-20 12:21:46.522837 start 943\n",
      "2021-11-20 12:21:46.523736 calculating gradient.. 943\n",
      "2021-11-20 12:23:02.582996 updating params.. 943\n",
      "2021-11-20 12:23:02.583941 recording loss.. 943\n",
      "2021-11-20 12:23:02.585967 start 944\n",
      "2021-11-20 12:23:02.586934 calculating gradient.. 944\n",
      "2021-11-20 12:24:16.435889 updating params.. 944\n",
      "2021-11-20 12:24:16.436910 recording loss.. 944\n",
      "2021-11-20 12:24:16.439027 start 945\n",
      "2021-11-20 12:24:16.439978 calculating gradient.. 945\n",
      "2021-11-20 12:25:31.666415 updating params.. 945\n",
      "2021-11-20 12:25:31.667385 recording loss.. 945\n",
      "2021-11-20 12:25:31.668769 start 946\n",
      "2021-11-20 12:25:31.669504 calculating gradient.. 946\n",
      "2021-11-20 12:26:46.547697 updating params.. 946\n",
      "2021-11-20 12:26:46.548801 recording loss.. 946\n",
      "2021-11-20 12:26:46.550974 start 947\n",
      "2021-11-20 12:26:46.551973 calculating gradient.. 947\n",
      "2021-11-20 12:28:01.824802 updating params.. 947\n",
      "2021-11-20 12:28:01.825953 recording loss.. 947\n",
      "2021-11-20 12:28:01.828010 start 948\n",
      "2021-11-20 12:28:01.828947 calculating gradient.. 948\n",
      "2021-11-20 12:29:15.840303 updating params.. 948\n",
      "2021-11-20 12:29:15.841248 recording loss.. 948\n",
      "2021-11-20 12:29:15.842557 start 949\n",
      "2021-11-20 12:29:15.842908 calculating gradient.. 949\n",
      "2021-11-20 12:30:30.010534 updating params.. 949\n",
      "2021-11-20 12:30:30.011721 recording loss.. 949\n",
      "2021-11-20 12:30:30.013274 start 950\n",
      "2021-11-20 12:30:30.014137 calculating gradient.. 950\n",
      "2021-11-20 12:31:43.637119 updating params.. 950\n",
      "2021-11-20 12:31:43.638064 recording loss.. 950\n",
      "train acc, test acc | 0.85925,0.8623\n",
      "2021-11-20 12:31:44.489949 start 951\n",
      "2021-11-20 12:31:44.491009 calculating gradient.. 951\n",
      "2021-11-20 12:32:58.772301 updating params.. 951\n",
      "2021-11-20 12:32:58.773258 recording loss.. 951\n",
      "2021-11-20 12:32:58.774543 start 952\n",
      "2021-11-20 12:32:58.775234 calculating gradient.. 952\n",
      "2021-11-20 12:34:12.589058 updating params.. 952\n",
      "2021-11-20 12:34:12.590038 recording loss.. 952\n",
      "2021-11-20 12:34:12.591391 start 953\n",
      "2021-11-20 12:34:12.592147 calculating gradient.. 953\n",
      "2021-11-20 12:35:27.361557 updating params.. 953\n",
      "2021-11-20 12:35:27.362508 recording loss.. 953\n",
      "2021-11-20 12:35:27.363795 start 954\n",
      "2021-11-20 12:35:27.364487 calculating gradient.. 954\n",
      "2021-11-20 12:36:41.732061 updating params.. 954\n",
      "2021-11-20 12:36:41.732992 recording loss.. 954\n",
      "2021-11-20 12:36:41.734288 start 955\n",
      "2021-11-20 12:36:41.734978 calculating gradient.. 955\n",
      "2021-11-20 12:37:57.566513 updating params.. 955\n",
      "2021-11-20 12:37:57.567833 recording loss.. 955\n",
      "2021-11-20 12:37:57.569205 start 956\n",
      "2021-11-20 12:37:57.569855 calculating gradient.. 956\n",
      "2021-11-20 12:39:11.311317 updating params.. 956\n",
      "2021-11-20 12:39:11.312241 recording loss.. 956\n",
      "2021-11-20 12:39:11.313693 start 957\n",
      "2021-11-20 12:39:11.314021 calculating gradient.. 957\n",
      "2021-11-20 12:40:24.791340 updating params.. 957\n",
      "2021-11-20 12:40:24.792299 recording loss.. 957\n",
      "2021-11-20 12:40:24.796109 start 958\n",
      "2021-11-20 12:40:24.797019 calculating gradient.. 958\n",
      "2021-11-20 12:41:40.073028 updating params.. 958\n",
      "2021-11-20 12:41:40.074073 recording loss.. 958\n",
      "2021-11-20 12:41:40.075919 start 959\n",
      "2021-11-20 12:41:40.076396 calculating gradient.. 959\n",
      "2021-11-20 12:42:55.887990 updating params.. 959\n",
      "2021-11-20 12:42:55.889000 recording loss.. 959\n",
      "2021-11-20 12:42:55.890899 start 960\n",
      "2021-11-20 12:42:55.891858 calculating gradient.. 960\n",
      "2021-11-20 12:44:09.392964 updating params.. 960\n",
      "2021-11-20 12:44:09.393929 recording loss.. 960\n",
      "train acc, test acc | 0.8606333333333334,0.8644\n",
      "2021-11-20 12:44:10.198204 start 961\n",
      "2021-11-20 12:44:10.199225 calculating gradient.. 961\n",
      "2021-11-20 12:45:25.324195 updating params.. 961\n",
      "2021-11-20 12:45:25.325133 recording loss.. 961\n",
      "2021-11-20 12:45:25.326509 start 962\n",
      "2021-11-20 12:45:25.327228 calculating gradient.. 962\n",
      "2021-11-20 12:46:39.123588 updating params.. 962\n",
      "2021-11-20 12:46:39.124593 recording loss.. 962\n",
      "2021-11-20 12:46:39.125816 start 963\n",
      "2021-11-20 12:46:39.126467 calculating gradient.. 963\n",
      "2021-11-20 12:47:53.484067 updating params.. 963\n",
      "2021-11-20 12:47:53.485113 recording loss.. 963\n",
      "2021-11-20 12:47:53.486679 start 964\n",
      "2021-11-20 12:47:53.487482 calculating gradient.. 964\n",
      "2021-11-20 12:49:06.641681 updating params.. 964\n",
      "2021-11-20 12:49:06.642699 recording loss.. 964\n",
      "2021-11-20 12:49:06.643966 start 965\n",
      "2021-11-20 12:49:06.644664 calculating gradient.. 965\n",
      "2021-11-20 12:50:20.751396 updating params.. 965\n",
      "2021-11-20 12:50:20.752333 recording loss.. 965\n",
      "2021-11-20 12:50:20.755117 start 966\n",
      "2021-11-20 12:50:20.755607 calculating gradient.. 966\n",
      "2021-11-20 12:51:36.315358 updating params.. 966\n",
      "2021-11-20 12:51:36.316438 recording loss.. 966\n",
      "2021-11-20 12:51:36.318354 start 967\n",
      "2021-11-20 12:51:36.319119 calculating gradient.. 967\n",
      "2021-11-20 12:52:50.110240 updating params.. 967\n",
      "2021-11-20 12:52:50.111165 recording loss.. 967\n",
      "2021-11-20 12:52:50.112382 start 968\n",
      "2021-11-20 12:52:50.113019 calculating gradient.. 968\n",
      "2021-11-20 12:54:05.277985 updating params.. 968\n",
      "2021-11-20 12:54:05.279610 recording loss.. 968\n",
      "2021-11-20 12:54:05.281125 start 969\n",
      "2021-11-20 12:54:05.281857 calculating gradient.. 969\n",
      "2021-11-20 12:55:21.007483 updating params.. 969\n",
      "2021-11-20 12:55:21.008443 recording loss.. 969\n",
      "2021-11-20 12:55:21.010819 start 970\n",
      "2021-11-20 12:55:21.011857 calculating gradient.. 970\n",
      "2021-11-20 12:56:37.407446 updating params.. 970\n",
      "2021-11-20 12:56:37.408626 recording loss.. 970\n",
      "train acc, test acc | 0.8583833333333334,0.8629\n",
      "2021-11-20 12:56:38.194983 start 971\n",
      "2021-11-20 12:56:38.196023 calculating gradient.. 971\n",
      "2021-11-20 12:57:51.633709 updating params.. 971\n",
      "2021-11-20 12:57:51.634637 recording loss.. 971\n",
      "2021-11-20 12:57:51.636268 start 972\n",
      "2021-11-20 12:57:51.637461 calculating gradient.. 972\n",
      "2021-11-20 12:59:05.858149 updating params.. 972\n",
      "2021-11-20 12:59:05.859098 recording loss.. 972\n",
      "2021-11-20 12:59:05.860385 start 973\n",
      "2021-11-20 12:59:05.861092 calculating gradient.. 973\n",
      "2021-11-20 13:00:21.694536 updating params.. 973\n",
      "2021-11-20 13:00:21.695514 recording loss.. 973\n",
      "2021-11-20 13:00:21.697049 start 974\n",
      "2021-11-20 13:00:21.697788 calculating gradient.. 974\n",
      "2021-11-20 13:01:37.299755 updating params.. 974\n",
      "2021-11-20 13:01:37.301768 recording loss.. 974\n",
      "2021-11-20 13:01:37.303335 start 975\n",
      "2021-11-20 13:01:37.304217 calculating gradient.. 975\n",
      "2021-11-20 13:03:18.951277 updating params.. 975\n",
      "2021-11-20 13:03:18.952663 recording loss.. 975\n",
      "2021-11-20 13:03:18.955456 start 976\n",
      "2021-11-20 13:03:18.956445 calculating gradient.. 976\n",
      "2021-11-20 13:04:34.919994 updating params.. 976\n",
      "2021-11-20 13:04:34.922114 recording loss.. 976\n",
      "2021-11-20 13:04:34.924934 start 977\n",
      "2021-11-20 13:04:34.925932 calculating gradient.. 977\n",
      "2021-11-20 13:05:50.525037 updating params.. 977\n",
      "2021-11-20 13:05:50.526771 recording loss.. 977\n",
      "2021-11-20 13:05:50.528791 start 978\n",
      "2021-11-20 13:05:50.529574 calculating gradient.. 978\n",
      "2021-11-20 13:07:05.161814 updating params.. 978\n",
      "2021-11-20 13:07:05.162826 recording loss.. 978\n",
      "2021-11-20 13:07:05.165155 start 979\n",
      "2021-11-20 13:07:05.166143 calculating gradient.. 979\n",
      "2021-11-20 13:08:20.318114 updating params.. 979\n",
      "2021-11-20 13:08:20.319242 recording loss.. 979\n",
      "2021-11-20 13:08:20.320950 start 980\n",
      "2021-11-20 13:08:20.321763 calculating gradient.. 980\n",
      "2021-11-20 13:09:36.246720 updating params.. 980\n",
      "2021-11-20 13:09:36.247800 recording loss.. 980\n",
      "train acc, test acc | 0.86165,0.8658\n",
      "2021-11-20 13:09:37.047565 start 981\n",
      "2021-11-20 13:09:37.048382 calculating gradient.. 981\n",
      "2021-11-20 13:10:50.787084 updating params.. 981\n",
      "2021-11-20 13:10:50.788437 recording loss.. 981\n",
      "2021-11-20 13:10:50.790338 start 982\n",
      "2021-11-20 13:10:50.791123 calculating gradient.. 982\n",
      "2021-11-20 13:12:05.341943 updating params.. 982\n",
      "2021-11-20 13:12:05.342856 recording loss.. 982\n",
      "2021-11-20 13:12:05.343975 start 983\n",
      "2021-11-20 13:12:05.344613 calculating gradient.. 983\n",
      "2021-11-20 13:13:19.912418 updating params.. 983\n",
      "2021-11-20 13:13:19.913368 recording loss.. 983\n",
      "2021-11-20 13:13:19.914800 start 984\n",
      "2021-11-20 13:13:19.915738 calculating gradient.. 984\n",
      "2021-11-20 13:14:34.419279 updating params.. 984\n",
      "2021-11-20 13:14:34.419773 recording loss.. 984\n",
      "2021-11-20 13:14:34.421893 start 985\n",
      "2021-11-20 13:14:34.422613 calculating gradient.. 985\n",
      "2021-11-20 13:15:48.697967 updating params.. 985\n",
      "2021-11-20 13:15:48.699452 recording loss.. 985\n",
      "2021-11-20 13:15:48.701530 start 986\n",
      "2021-11-20 13:15:48.703309 calculating gradient.. 986\n",
      "2021-11-20 13:17:03.287482 updating params.. 986\n",
      "2021-11-20 13:17:03.288556 recording loss.. 986\n",
      "2021-11-20 13:17:03.291005 start 987\n",
      "2021-11-20 13:17:03.291449 calculating gradient.. 987\n",
      "2021-11-20 13:18:18.693603 updating params.. 987\n",
      "2021-11-20 13:18:18.694531 recording loss.. 987\n",
      "2021-11-20 13:18:18.695738 start 988\n",
      "2021-11-20 13:18:18.696381 calculating gradient.. 988\n",
      "2021-11-20 13:19:32.577540 updating params.. 988\n",
      "2021-11-20 13:19:32.578459 recording loss.. 988\n",
      "2021-11-20 13:19:32.579683 start 989\n",
      "2021-11-20 13:19:32.580337 calculating gradient.. 989\n",
      "2021-11-20 13:20:47.060867 updating params.. 989\n",
      "2021-11-20 13:20:47.061901 recording loss.. 989\n",
      "2021-11-20 13:20:47.063029 start 990\n",
      "2021-11-20 13:20:47.063866 calculating gradient.. 990\n",
      "2021-11-20 13:22:01.736812 updating params.. 990\n",
      "2021-11-20 13:22:01.737788 recording loss.. 990\n",
      "train acc, test acc | 0.8645333333333334,0.8694\n",
      "2021-11-20 13:22:02.626604 start 991\n",
      "2021-11-20 13:22:02.628000 calculating gradient.. 991\n",
      "2021-11-20 13:23:18.357818 updating params.. 991\n",
      "2021-11-20 13:23:18.358768 recording loss.. 991\n",
      "2021-11-20 13:23:18.360084 start 992\n",
      "2021-11-20 13:23:18.361280 calculating gradient.. 992\n",
      "2021-11-20 13:24:33.960260 updating params.. 992\n",
      "2021-11-20 13:24:33.961280 recording loss.. 992\n",
      "2021-11-20 13:24:33.962727 start 993\n",
      "2021-11-20 13:24:33.963148 calculating gradient.. 993\n",
      "2021-11-20 13:25:41.151746 updating params.. 993\n",
      "2021-11-20 13:25:41.152686 recording loss.. 993\n",
      "2021-11-20 13:25:41.153940 start 994\n",
      "2021-11-20 13:25:41.154586 calculating gradient.. 994\n",
      "2021-11-20 13:26:41.542663 updating params.. 994\n",
      "2021-11-20 13:26:41.543590 recording loss.. 994\n",
      "2021-11-20 13:26:41.544809 start 995\n",
      "2021-11-20 13:26:41.545590 calculating gradient.. 995\n",
      "2021-11-20 13:27:41.831194 updating params.. 995\n",
      "2021-11-20 13:27:41.832143 recording loss.. 995\n",
      "2021-11-20 13:27:41.833447 start 996\n",
      "2021-11-20 13:27:41.834158 calculating gradient.. 996\n",
      "2021-11-20 13:28:42.139385 updating params.. 996\n",
      "2021-11-20 13:28:42.140338 recording loss.. 996\n",
      "2021-11-20 13:28:42.141656 start 997\n",
      "2021-11-20 13:28:42.142358 calculating gradient.. 997\n",
      "2021-11-20 13:29:42.617028 updating params.. 997\n",
      "2021-11-20 13:29:42.617979 recording loss.. 997\n",
      "2021-11-20 13:29:42.619219 start 998\n",
      "2021-11-20 13:29:42.619697 calculating gradient.. 998\n",
      "2021-11-20 13:30:43.039831 updating params.. 998\n",
      "2021-11-20 13:30:43.040804 recording loss.. 998\n",
      "2021-11-20 13:30:43.042127 start 999\n",
      "2021-11-20 13:30:43.042829 calculating gradient.. 999\n",
      "2021-11-20 13:31:43.344490 updating params.. 999\n",
      "2021-11-20 13:31:43.345527 recording loss.. 999\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for i in range(iters_num):\n",
    "    print(datetime.now(),\"start\",i)\n",
    "    # ミニバッチの取得\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    print(datetime.now(),\"calculating gradient..\",i)\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = nework.gradient(..) # 高速版\n",
    "    \n",
    "    # パラメータの更新\n",
    "    print(datetime.now(),\"updating params..\",i)\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 学習経過の記録\n",
    "    print(datetime.now(),\"recording loss..\",i)\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1エポックごとに認識精度を計算\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc__list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \",\" +str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6eaaa9d00>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(train_acc_list)), train_acc_list)\n",
    "plt.plot(range(len(test_acc__list)), test_acc__list)\n",
    "#range(len(train_acc_list))\n",
    "#len(train_acc_list)\n",
    "#train_acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/wd500/gotowork/workspace/study-dl-from-scratch/chapter-04\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "%cd ../../chapter-04/\n",
    "\n",
    "# pickle化してファイルに書き込み\n",
    "with open('pickled_train_acc_list_1k.pkl', 'wb') as f:\n",
    "    pickle.dump(train_acc_list, f)\n",
    "with open('pickled_test_acc__list_1k.pkl', 'wb') as f:\n",
    "    pickle.dump(test_acc__list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/wd500/gotowork/workspace/study-dl-from-scratch/deep-learning-from-scratch/ch04'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
