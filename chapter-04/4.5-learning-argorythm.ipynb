{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ゼロから作るDeep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4章 ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 学習アルゴリズムの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 2層ニューラルネットワークのクラス\n",
    "\n",
    "2層のニューラルネットワーク（隠れ層が1層のニューラルネットワーク）を対象に、MNISTデータセットを使って学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/wd500/gotowork/workspace/study-dl-from-scratch/deep-learning-from-scratch/ch04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd ../deep-learning-from-scratch/ch04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    # このクラスで使用する変数\n",
    "    ## params : ニューラルネットワークのパラメータを保持するディクショナリ変数（インスタンス変数）\n",
    "    ##          params['W1']は1層目の重み、params['b1']は1層目のバイアス。\n",
    "    ##          params['W2']は2層目の重み、params['b2']は2層目のバイアス。\n",
    "    #\n",
    "    ## grads : 勾配を保持するディクショナリ変数（numerical_gradient()メソッドの返り値）\n",
    "    ##         grads['W1']は1層目の重みの勾配、grads['b1']は1層目のバイアスの勾配。\n",
    "    ##         grads['W2']は2層目の重みの勾配、grads['b2']は2層目のバイアスの勾配。\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y,t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一つ例を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape) # 今の層（入力層）のニューロン数×次の層（隠れ層）ニューロン数の行列になる\n",
    "print(net.params['b1'].shape) # 次の層（隠れ層）のニューロン数の行列になる\n",
    "print(net.params['W2'].shape) # 今の層（隠れ層）のニューロン数×次の層（出力層）のニューロン数の行列になる\n",
    "print(net.params['b2'].shape) # 次の層（出力層）のニューロン数の行列になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推論処理の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) # ダミーの入力データ（１００枚分）\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05656624, 0.19617819, 0.10486648, ..., 0.42354662, 0.35273118,\n",
       "        0.87174438],\n",
       "       [0.57755882, 0.48298945, 0.21353107, ..., 0.38059549, 0.23743903,\n",
       "        0.33146339],\n",
       "       [0.46275798, 0.02757556, 0.42526475, ..., 0.39976671, 0.15884461,\n",
       "        0.55388627],\n",
       "       ...,\n",
       "       [0.13981253, 0.78022038, 0.24436076, ..., 0.94848046, 0.21790573,\n",
       "        0.32274977],\n",
       "       [0.39965894, 0.56755264, 0.24788565, ..., 0.28554599, 0.77706347,\n",
       "        0.87499767],\n",
       "       [0.50886433, 0.67234244, 0.37372261, ..., 0.51165776, 0.82388759,\n",
       "        0.78253123]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0959692 , 0.09629166, 0.09979841, 0.09871939, 0.11098569,\n",
       "        0.101662  , 0.09740745, 0.10014477, 0.10529902, 0.09372241],\n",
       "       [0.0960181 , 0.09635296, 0.09954321, 0.09883072, 0.11141286,\n",
       "        0.10196294, 0.09756556, 0.09961232, 0.10519653, 0.09350482],\n",
       "       [0.09610602, 0.09622185, 0.09965249, 0.09874341, 0.111017  ,\n",
       "        0.10171183, 0.09757746, 0.10022934, 0.10529124, 0.09344936],\n",
       "       [0.0960031 , 0.09620877, 0.09979786, 0.09865434, 0.11064326,\n",
       "        0.10164532, 0.09758329, 0.10009401, 0.10551626, 0.0938538 ],\n",
       "       [0.09573872, 0.09627769, 0.09979617, 0.09875095, 0.11092637,\n",
       "        0.10193495, 0.09753129, 0.10013841, 0.10541893, 0.09348653],\n",
       "       [0.09608266, 0.09623521, 0.09996819, 0.09863595, 0.11083231,\n",
       "        0.10199436, 0.09737278, 0.10024432, 0.10516339, 0.09347084],\n",
       "       [0.0962095 , 0.09621766, 0.0997767 , 0.09886011, 0.11125865,\n",
       "        0.10178827, 0.09723453, 0.100102  , 0.10513272, 0.09341986],\n",
       "       [0.09611028, 0.09621453, 0.09931993, 0.09852109, 0.11102311,\n",
       "        0.10186059, 0.09778156, 0.10014316, 0.10544091, 0.09358486],\n",
       "       [0.09614926, 0.09617313, 0.09965823, 0.09842515, 0.11089886,\n",
       "        0.10188489, 0.09768633, 0.0999343 , 0.10542004, 0.09376982],\n",
       "       [0.09622079, 0.09641348, 0.09994284, 0.09831357, 0.11068983,\n",
       "        0.10183874, 0.09771748, 0.10004215, 0.10545106, 0.09337006],\n",
       "       [0.09597318, 0.09619068, 0.09959599, 0.09850834, 0.11121816,\n",
       "        0.10168085, 0.09765469, 0.10020872, 0.10554742, 0.09342196],\n",
       "       [0.09593744, 0.09607142, 0.09974204, 0.09864149, 0.1109025 ,\n",
       "        0.10172469, 0.09765638, 0.10019478, 0.1055715 , 0.09355776],\n",
       "       [0.09561446, 0.09594464, 0.0995904 , 0.09851793, 0.11102418,\n",
       "        0.10173884, 0.09777992, 0.10027942, 0.10584145, 0.09366876],\n",
       "       [0.09558378, 0.0958398 , 0.10004239, 0.09863142, 0.11137283,\n",
       "        0.10194819, 0.09718729, 0.10037185, 0.1055093 , 0.09351316],\n",
       "       [0.09585444, 0.09627405, 0.09958736, 0.09934802, 0.1112339 ,\n",
       "        0.10209414, 0.09727784, 0.09997786, 0.10480145, 0.09355094],\n",
       "       [0.09611598, 0.09613269, 0.09995682, 0.09870592, 0.11099764,\n",
       "        0.10186484, 0.09753594, 0.09985947, 0.10525992, 0.09357077],\n",
       "       [0.09604281, 0.09615939, 0.09980191, 0.09871553, 0.11078038,\n",
       "        0.10194442, 0.09730491, 0.09983538, 0.10562679, 0.09378848],\n",
       "       [0.09619551, 0.09632717, 0.09959315, 0.09861105, 0.11075337,\n",
       "        0.1016708 , 0.09776394, 0.10036016, 0.10515977, 0.0935651 ],\n",
       "       [0.09551494, 0.09584579, 0.09961565, 0.09887012, 0.11066842,\n",
       "        0.10153649, 0.09833531, 0.10029537, 0.10579424, 0.09352367],\n",
       "       [0.09591568, 0.09587945, 0.09990013, 0.09857249, 0.11098718,\n",
       "        0.10183507, 0.09753802, 0.10014086, 0.10563296, 0.09359817],\n",
       "       [0.09629656, 0.09647731, 0.09950417, 0.09859348, 0.11098733,\n",
       "        0.10181913, 0.09742704, 0.10033922, 0.10527937, 0.0932764 ],\n",
       "       [0.09562757, 0.09609371, 0.09985753, 0.09882521, 0.11105402,\n",
       "        0.1019724 , 0.09796424, 0.10004377, 0.10501743, 0.09354412],\n",
       "       [0.09596794, 0.09639043, 0.09975831, 0.09870121, 0.11134237,\n",
       "        0.10195358, 0.09734183, 0.09988719, 0.10497292, 0.09368422],\n",
       "       [0.0956564 , 0.09600067, 0.10014795, 0.09892562, 0.11085386,\n",
       "        0.10191743, 0.09729664, 0.10018645, 0.1056187 , 0.09339627],\n",
       "       [0.09619236, 0.09614339, 0.09975819, 0.09848814, 0.11107975,\n",
       "        0.10162632, 0.09744223, 0.09976957, 0.10563783, 0.09386222],\n",
       "       [0.09595962, 0.09622195, 0.09966432, 0.09842423, 0.11111064,\n",
       "        0.10186266, 0.09747285, 0.10037959, 0.10523325, 0.09367089],\n",
       "       [0.09611353, 0.09613726, 0.09962854, 0.09847807, 0.1108223 ,\n",
       "        0.10154539, 0.09775637, 0.10009913, 0.10574838, 0.09367102],\n",
       "       [0.09577227, 0.09656172, 0.09985729, 0.09830164, 0.11106193,\n",
       "        0.10220295, 0.09732817, 0.10006921, 0.10533653, 0.09350828],\n",
       "       [0.09639014, 0.09640208, 0.09987472, 0.09868489, 0.11088305,\n",
       "        0.10173901, 0.09732782, 0.09991419, 0.10541862, 0.09336547],\n",
       "       [0.09642533, 0.0963643 , 0.0994125 , 0.0988011 , 0.11097859,\n",
       "        0.10189693, 0.09741494, 0.10003662, 0.10517313, 0.09349655],\n",
       "       [0.09587946, 0.09618479, 0.0999441 , 0.09869959, 0.11110515,\n",
       "        0.10169749, 0.09732329, 0.10032891, 0.10521602, 0.09362118],\n",
       "       [0.09585156, 0.09629584, 0.09966101, 0.09873037, 0.11129734,\n",
       "        0.10143278, 0.09765847, 0.09996351, 0.10546251, 0.0936466 ],\n",
       "       [0.0963045 , 0.09604901, 0.09965888, 0.09919298, 0.11100481,\n",
       "        0.10226653, 0.09740773, 0.09991793, 0.10477093, 0.0934267 ],\n",
       "       [0.09597218, 0.09606379, 0.09988107, 0.09874731, 0.11120515,\n",
       "        0.10204365, 0.09751483, 0.09982527, 0.10508043, 0.09366633],\n",
       "       [0.09564994, 0.09638073, 0.09975319, 0.09866704, 0.11095188,\n",
       "        0.10162285, 0.09764271, 0.09988113, 0.10583416, 0.09361637],\n",
       "       [0.0960714 , 0.09616274, 0.09971743, 0.09873967, 0.11077833,\n",
       "        0.10173065, 0.09751468, 0.10002157, 0.10557509, 0.09368845],\n",
       "       [0.09591351, 0.09602994, 0.0997883 , 0.09900773, 0.11100361,\n",
       "        0.1016857 , 0.09782368, 0.10001057, 0.10524548, 0.09349147],\n",
       "       [0.09575948, 0.09619735, 0.09995307, 0.09856651, 0.11083112,\n",
       "        0.10208079, 0.09732594, 0.10032523, 0.10513687, 0.09382366],\n",
       "       [0.09593226, 0.0958754 , 0.09982686, 0.09894719, 0.11104408,\n",
       "        0.10161886, 0.0974529 , 0.09995244, 0.10529527, 0.09405474],\n",
       "       [0.09600949, 0.09599296, 0.09991827, 0.09846342, 0.11074667,\n",
       "        0.10168184, 0.09756665, 0.10047349, 0.10573367, 0.09341354],\n",
       "       [0.09551225, 0.0964067 , 0.09983276, 0.09878427, 0.11114087,\n",
       "        0.10181035, 0.09755692, 0.09999985, 0.10540853, 0.09354749],\n",
       "       [0.09595942, 0.09639741, 0.09965684, 0.09852249, 0.11125039,\n",
       "        0.10169324, 0.09755049, 0.0999535 , 0.10523696, 0.09377925],\n",
       "       [0.09630512, 0.09623516, 0.09962648, 0.09863856, 0.11092567,\n",
       "        0.10197526, 0.09740109, 0.09990799, 0.10520089, 0.09378376],\n",
       "       [0.09593943, 0.09655643, 0.09970342, 0.09905646, 0.11100398,\n",
       "        0.10130208, 0.09744531, 0.10018302, 0.10541311, 0.09339674],\n",
       "       [0.09586339, 0.09617716, 0.09993608, 0.09874457, 0.11113064,\n",
       "        0.10196628, 0.09738623, 0.09976139, 0.1052455 , 0.09378876],\n",
       "       [0.09604316, 0.09615492, 0.09944163, 0.09882359, 0.11119039,\n",
       "        0.10158807, 0.09771865, 0.10013618, 0.1052975 , 0.09360593],\n",
       "       [0.09621977, 0.09623311, 0.09992595, 0.09865599, 0.11080075,\n",
       "        0.1018366 , 0.09726607, 0.09994133, 0.10551131, 0.09360912],\n",
       "       [0.09594845, 0.09618489, 0.09997101, 0.09873228, 0.11134442,\n",
       "        0.10166269, 0.09748855, 0.09992027, 0.10545548, 0.09329197],\n",
       "       [0.09617423, 0.09622339, 0.09951929, 0.09847342, 0.11084342,\n",
       "        0.10192741, 0.09733217, 0.10051157, 0.10549119, 0.09350391],\n",
       "       [0.09577971, 0.09623908, 0.09960197, 0.09864614, 0.11096381,\n",
       "        0.10192435, 0.09766114, 0.10020329, 0.10521445, 0.09376607],\n",
       "       [0.09574732, 0.09630806, 0.09982754, 0.09902074, 0.11119162,\n",
       "        0.10218052, 0.09746193, 0.09990964, 0.10499104, 0.09336158],\n",
       "       [0.09588224, 0.09619503, 0.09958083, 0.09886137, 0.11131654,\n",
       "        0.10183295, 0.09756421, 0.09975106, 0.10551789, 0.09349788],\n",
       "       [0.09591547, 0.09634194, 0.09956196, 0.09852636, 0.1112336 ,\n",
       "        0.10226705, 0.09716613, 0.10010677, 0.10519185, 0.09368887],\n",
       "       [0.09613906, 0.09644332, 0.09964142, 0.09849939, 0.11110193,\n",
       "        0.10221863, 0.09718   , 0.10005325, 0.10504661, 0.0936764 ],\n",
       "       [0.09617023, 0.09614729, 0.09948524, 0.0988765 , 0.11092752,\n",
       "        0.10182013, 0.09748872, 0.1000653 , 0.1051984 , 0.09382066],\n",
       "       [0.09628841, 0.09614128, 0.09981148, 0.09846597, 0.11099233,\n",
       "        0.10200859, 0.09757742, 0.10022679, 0.10491554, 0.09357219],\n",
       "       [0.09624812, 0.09608092, 0.09978021, 0.09888986, 0.11101392,\n",
       "        0.10141606, 0.09744648, 0.0999648 , 0.10549908, 0.09366056],\n",
       "       [0.09612788, 0.09617321, 0.09979876, 0.09851248, 0.11084235,\n",
       "        0.10173602, 0.09756745, 0.10000673, 0.10557197, 0.09366316],\n",
       "       [0.09608066, 0.09592758, 0.09963166, 0.09838022, 0.11103924,\n",
       "        0.10176775, 0.09779032, 0.10011133, 0.1055994 , 0.09367183],\n",
       "       [0.09576639, 0.09640968, 0.09986296, 0.09865183, 0.11097761,\n",
       "        0.10204347, 0.09759733, 0.099781  , 0.10543918, 0.09347055],\n",
       "       [0.09611668, 0.09618735, 0.09987659, 0.09871632, 0.111551  ,\n",
       "        0.10185465, 0.09733139, 0.0998784 , 0.10483254, 0.09365509],\n",
       "       [0.09587411, 0.09626807, 0.09974226, 0.09830615, 0.11108832,\n",
       "        0.10186275, 0.09765392, 0.09976791, 0.10568225, 0.09375427],\n",
       "       [0.09588592, 0.09624839, 0.09998731, 0.0986826 , 0.11077398,\n",
       "        0.10197011, 0.09742418, 0.10011909, 0.10508722, 0.09382119],\n",
       "       [0.09577591, 0.09617699, 0.09985242, 0.09865513, 0.11069324,\n",
       "        0.10190734, 0.09755767, 0.10022129, 0.10568887, 0.09347113],\n",
       "       [0.09621318, 0.09640523, 0.09985663, 0.0987986 , 0.11109411,\n",
       "        0.10182506, 0.09741464, 0.10005779, 0.10468319, 0.09365157],\n",
       "       [0.09588692, 0.09613942, 0.09980551, 0.09862747, 0.11126195,\n",
       "        0.10200466, 0.09723405, 0.09998976, 0.10550452, 0.09354574],\n",
       "       [0.0963479 , 0.0961992 , 0.09957045, 0.09875137, 0.11093252,\n",
       "        0.10192219, 0.09750028, 0.09963736, 0.10567582, 0.09346291],\n",
       "       [0.09641038, 0.09609182, 0.09953667, 0.09863412, 0.11094224,\n",
       "        0.10163398, 0.09773974, 0.10000238, 0.10525131, 0.09375736],\n",
       "       [0.09568886, 0.09593676, 0.09976838, 0.09897146, 0.11071434,\n",
       "        0.10187656, 0.09757746, 0.10055464, 0.1054813 , 0.09343026],\n",
       "       [0.0962238 , 0.09632207, 0.09975295, 0.09874316, 0.11091222,\n",
       "        0.10187447, 0.09746639, 0.10006846, 0.10490486, 0.09373161],\n",
       "       [0.09575009, 0.09593964, 0.09998492, 0.09849795, 0.11112385,\n",
       "        0.10194387, 0.09744108, 0.10017127, 0.1057039 , 0.09344342],\n",
       "       [0.09606853, 0.09626977, 0.0995117 , 0.09885307, 0.1109335 ,\n",
       "        0.10181582, 0.09760264, 0.09976276, 0.10511655, 0.09406567],\n",
       "       [0.09622892, 0.09629022, 0.09959835, 0.09892026, 0.11073164,\n",
       "        0.10171589, 0.09756932, 0.1002753 , 0.1052946 , 0.09337549],\n",
       "       [0.09621132, 0.09620799, 0.09988799, 0.09883982, 0.11076891,\n",
       "        0.10175303, 0.09735267, 0.09974943, 0.10556563, 0.09366322],\n",
       "       [0.09576891, 0.09622808, 0.09997449, 0.09893943, 0.1110525 ,\n",
       "        0.10180829, 0.09750273, 0.09985717, 0.10530795, 0.09356046],\n",
       "       [0.09581071, 0.09639519, 0.10012862, 0.09859991, 0.11081749,\n",
       "        0.10186339, 0.09758646, 0.10002974, 0.10515888, 0.09360962],\n",
       "       [0.09576023, 0.0960468 , 0.09990674, 0.09844915, 0.1113436 ,\n",
       "        0.1020685 , 0.09739623, 0.10019066, 0.10528092, 0.09355717],\n",
       "       [0.09572702, 0.09616294, 0.09948493, 0.09843627, 0.11133733,\n",
       "        0.10220862, 0.09772605, 0.10033372, 0.10524938, 0.09333373],\n",
       "       [0.09581926, 0.09620407, 0.09985984, 0.09853571, 0.11138071,\n",
       "        0.10216415, 0.09724673, 0.09986658, 0.10525323, 0.09366971],\n",
       "       [0.09593372, 0.096125  , 0.09974212, 0.09841762, 0.11122464,\n",
       "        0.10222837, 0.09750907, 0.10006518, 0.10529989, 0.09345439],\n",
       "       [0.09619508, 0.09605397, 0.09937364, 0.09894881, 0.11129101,\n",
       "        0.10192522, 0.09748676, 0.09999369, 0.10507723, 0.09365459],\n",
       "       [0.09591542, 0.09636114, 0.09974533, 0.09860237, 0.1108729 ,\n",
       "        0.1017096 , 0.09719279, 0.10041907, 0.10577316, 0.09340823],\n",
       "       [0.09597519, 0.09630167, 0.09950432, 0.09886203, 0.11125281,\n",
       "        0.10186432, 0.09764473, 0.10003014, 0.10509777, 0.09346701],\n",
       "       [0.0962975 , 0.09622433, 0.09965193, 0.09923195, 0.11060296,\n",
       "        0.10186859, 0.0974391 , 0.09989941, 0.10508185, 0.09370239],\n",
       "       [0.0960298 , 0.09602968, 0.09963566, 0.09897457, 0.11098152,\n",
       "        0.10168309, 0.09756286, 0.10018564, 0.10522942, 0.09368777],\n",
       "       [0.09600608, 0.09629267, 0.09960432, 0.09888634, 0.11060774,\n",
       "        0.10161853, 0.09743798, 0.10022827, 0.10559135, 0.09372672],\n",
       "       [0.09582744, 0.09596211, 0.09971266, 0.09840012, 0.11110791,\n",
       "        0.10215819, 0.09753896, 0.10022353, 0.10549875, 0.09357033],\n",
       "       [0.09612411, 0.09622035, 0.09977143, 0.09889156, 0.11047664,\n",
       "        0.10178785, 0.09762319, 0.1002547 , 0.1052313 , 0.09361886],\n",
       "       [0.09581433, 0.0964081 , 0.09990218, 0.09861881, 0.11053758,\n",
       "        0.10180183, 0.09755601, 0.10010584, 0.10552015, 0.09373518],\n",
       "       [0.09615046, 0.09615196, 0.09967084, 0.09835665, 0.11099785,\n",
       "        0.10177727, 0.0975824 , 0.10016867, 0.10548201, 0.09366188],\n",
       "       [0.09598095, 0.0965306 , 0.09960996, 0.09874885, 0.11107181,\n",
       "        0.10202809, 0.09733709, 0.100125  , 0.10527189, 0.09329575],\n",
       "       [0.09604919, 0.09635225, 0.09956817, 0.09881708, 0.11100591,\n",
       "        0.10182116, 0.09723394, 0.10008735, 0.10526369, 0.09380125],\n",
       "       [0.09612284, 0.09624661, 0.09977362, 0.09890767, 0.11100021,\n",
       "        0.10175283, 0.09755021, 0.09994896, 0.10542041, 0.09327665],\n",
       "       [0.09568215, 0.09632025, 0.09997645, 0.09864465, 0.11089796,\n",
       "        0.10226295, 0.09741572, 0.09972396, 0.1053496 , 0.09372633],\n",
       "       [0.09618972, 0.09606458, 0.09968181, 0.09862565, 0.1112052 ,\n",
       "        0.10197746, 0.09743656, 0.10036784, 0.10512887, 0.0933223 ],\n",
       "       [0.09591073, 0.09630492, 0.09986521, 0.09878901, 0.11094529,\n",
       "        0.10154904, 0.097426  , 0.10001367, 0.10563931, 0.09355683],\n",
       "       [0.09634713, 0.09656626, 0.09933924, 0.09862792, 0.11080047,\n",
       "        0.10164949, 0.09745106, 0.1000676 , 0.10532938, 0.09382144],\n",
       "       [0.09600502, 0.09642282, 0.09950595, 0.09856637, 0.11094733,\n",
       "        0.10175128, 0.09789744, 0.09983289, 0.1052835 , 0.0937874 ],\n",
       "       [0.09607425, 0.09606096, 0.09973196, 0.09860913, 0.11106252,\n",
       "        0.10197555, 0.09767738, 0.09959455, 0.10562941, 0.09358427],\n",
       "       [0.09587773, 0.09615984, 0.09971067, 0.09892123, 0.11109082,\n",
       "        0.10188533, 0.09755802, 0.09994944, 0.10531556, 0.09353136]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) # ダミーの入力データ(100枚分)\n",
    "t = np.random.rand(100, 10)  # ダミーの正解ラベル(100枚分)\n",
    "\n",
    "grads = net.numerical_gradient(x, t) # 勾配を計算  5分くらいかかった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['W1'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['b1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['W2'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads['b2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 ミニバッチ学習の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "#iters_num = 10000\n",
    "iters_num = 10\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-17 11:57:03.417784 0 start\n",
      "2021-11-17 11:57:03.588130 0 calculating gradient..\n",
      "2021-11-17 11:57:38.746525 0 updating params..\n",
      "2021-11-17 11:57:38.748177 0 recording loss..\n",
      "2021-11-17 11:57:38.750788 1 start\n",
      "2021-11-17 11:57:38.751992 1 calculating gradient..\n",
      "2021-11-17 11:58:18.206202 1 updating params..\n",
      "2021-11-17 11:58:18.207569 1 recording loss..\n",
      "2021-11-17 11:58:18.209202 2 start\n",
      "2021-11-17 11:58:18.210329 2 calculating gradient..\n",
      "2021-11-17 11:58:56.034166 2 updating params..\n",
      "2021-11-17 11:58:56.035545 2 recording loss..\n",
      "2021-11-17 11:58:56.036913 3 start\n",
      "2021-11-17 11:58:56.038012 3 calculating gradient..\n",
      "2021-11-17 11:59:32.658367 3 updating params..\n",
      "2021-11-17 11:59:32.659685 3 recording loss..\n",
      "2021-11-17 11:59:32.661057 4 start\n",
      "2021-11-17 11:59:32.662023 4 calculating gradient..\n",
      "2021-11-17 12:00:10.456674 4 updating params..\n",
      "2021-11-17 12:00:10.458641 4 recording loss..\n",
      "2021-11-17 12:00:10.461041 5 start\n",
      "2021-11-17 12:00:10.462192 5 calculating gradient..\n",
      "2021-11-17 12:00:52.089463 5 updating params..\n",
      "2021-11-17 12:00:52.091182 5 recording loss..\n",
      "2021-11-17 12:00:52.092817 6 start\n",
      "2021-11-17 12:00:52.094166 6 calculating gradient..\n",
      "2021-11-17 12:01:33.940131 6 updating params..\n",
      "2021-11-17 12:01:33.941644 6 recording loss..\n",
      "2021-11-17 12:01:33.943214 7 start\n",
      "2021-11-17 12:01:33.944571 7 calculating gradient..\n",
      "2021-11-17 12:02:18.428286 7 updating params..\n",
      "2021-11-17 12:02:18.430072 7 recording loss..\n",
      "2021-11-17 12:02:18.434629 8 start\n",
      "2021-11-17 12:02:18.436376 8 calculating gradient..\n",
      "2021-11-17 12:03:03.007136 8 updating params..\n",
      "2021-11-17 12:03:03.008710 8 recording loss..\n",
      "2021-11-17 12:03:03.010525 9 start\n",
      "2021-11-17 12:03:03.011872 9 calculating gradient..\n",
      "2021-11-17 12:03:46.873806 9 updating params..\n",
      "2021-11-17 12:03:46.875267 9 recording loss..\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for i in range(iters_num):\n",
    "    print(datetime.now(),i,\"start\")\n",
    "    # ミニバッチの取得\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    print(datetime.now(),i, \"calculating gradient..\")\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = nework.gradient(..) # 高速版\n",
    "    \n",
    "    # パラメータの更新\n",
    "    print(datetime.now(),i, \"updating params..\")\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 学習経過の記録\n",
    "    print(datetime.now(),i,\"recording loss..\")\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "# 10時間以上経っても終わらず。\n",
    "# 10ループなら11.5分程度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0:01:15 / loop\n",
    "- 75sec / loop\n",
    "- 10,000 loopだと\n",
    "  - 750,000 sec\n",
    "  - 10,250 min\n",
    "  - 170.8 hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "#iters_num = 10000\n",
    "iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 100 10\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc__list = []\n",
    "# 1エポックあたりの繰り返し数\n",
    "#iter_per_epoch = max(train_size / batch_size, 1)\n",
    "iter_per_epoch = 10\n",
    "\n",
    "print(train_size, batch_size, iter_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-19 19:26:35.675188 start 0\n",
      "2021-11-19 19:26:35.677078 calculating gradient.. 0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for i in range(iters_num):\n",
    "    print(datetime.now(),\"start\",i)\n",
    "    # ミニバッチの取得\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    print(datetime.now(),\"calculating gradient..\",i)\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = nework.gradient(..) # 高速版\n",
    "    \n",
    "    # パラメータの更新\n",
    "    print(datetime.now(),\"updating params..\",i)\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 学習経過の記録\n",
    "    print(datetime.now(),\"recording loss..\",i)\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1エポックごとに認識精度を計算\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc__list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \",\" +str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6eab3f5b0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(train_acc_list)), train_acc_list)\n",
    "plt.plot(range(len(test_acc__list)), test_acc__list)\n",
    "#range(len(train_acc_list))\n",
    "#len(train_acc_list)\n",
    "#train_acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
